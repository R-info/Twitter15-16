{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "random.seed(33)\n",
    "\n",
    "unique_name = \"BERT_Finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(818, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter16_BERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>656955120626880512</td>\n",
       "      <td>correct predictions in back to the future ii U...</td>\n",
       "      <td>false</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>615689290706595840</td>\n",
       "      <td>.@whitehouse in rainbow colors for #scotusmarr...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>613404935003217920</td>\n",
       "      <td>cops bought the alleged church shooter burger ...</td>\n",
       "      <td>false</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  656955120626880512  correct predictions in back to the future ii U...   \n",
       "1  615689290706595840  .@whitehouse in rainbow colors for #scotusmarr...   \n",
       "2  613404935003217920  cops bought the alleged church shooter burger ...   \n",
       "3  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "4  714598641827246081  an open letter to trump voters from his top st...   \n",
       "\n",
       "        label       tvt  cv_fold        tt        tvt2  \n",
       "0       false  training        1  training  validation  \n",
       "1        true  training        3  training    training  \n",
       "2       false  training        2      test    training  \n",
       "3  unverified  training        3      test    training  \n",
       "4  unverified  training        1      test    training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter16_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['false', 'true', 'unverified', 'non-rumor']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = data['label'].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 2, 2, 1, 2, 3, 3, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d['label'])\n",
    "#     labels.append([1 if j == lab else 0 for j in range(len(labels_str))])\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(531, 768)\n",
      "(185, 768)\n",
      "(102, 768)\n",
      "(531,)\n",
      "(185,)\n",
      "(102,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, n_output),\n",
    "#             nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ce67903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from library.classification import SKLearnClassification\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Twitter16\"\n",
    "\n",
    "logres_model = LogisticRegression(random_state=0, solver='liblinear', multi_class='ovr', max_iter=10000)\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "svm = LinearSVC()\n",
    "\n",
    "models = [\n",
    "    SKLearnClassification(logres_model, \"Logistic Regression\"),\n",
    "    SKLearnClassification(neigh, \"K-Nearest Neighbor\"),\n",
    "    SKLearnClassification(svm, \"Support Vector Machine\"),\n",
    "]\n",
    "# for model in models:\n",
    "#     print(f\"\\n--- {model.model_name.upper()} ---\")\n",
    "#     model.train(train_vectors, train_labels, dataset_name)\n",
    "    \n",
    "#     print(\"Validation Set\")\n",
    "#     preds = model.predict(val_vectors)\n",
    "\n",
    "#     conf_mat = ConfusionMatrix(\n",
    "#         labels=val_labels,\n",
    "#         predictions=preds,\n",
    "#         binary=True\n",
    "#     )\n",
    "#     conf_mat.evaluate()\n",
    "    \n",
    "#     print(\"Test Set\")\n",
    "#     preds = model.predict(test_vectors)\n",
    "\n",
    "#     conf_mat = ConfusionMatrix(\n",
    "#         labels=test_labels,\n",
    "#         predictions=preds,\n",
    "#         binary=False\n",
    "#     )\n",
    "#     conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "#     print(\"--- END ---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd07cc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 54.595\n",
      "Saving after new best accuracy : 62.162\n",
      "Saving after new best accuracy : 63.243\n",
      "Saving after new best accuracy : 64.324\n",
      "Saving after new best accuracy : 81.622\n",
      "Saving after new best accuracy : 84.865\n",
      "Saving after new best accuracy : 85.405\n",
      "-- Epoch 50, Train Loss : 0.0010830542596522719, Test Loss : 0.7806545495986938\n",
      "-- Epoch 100, Train Loss : 0.0002598346763988957, Test Loss : 0.9039313793182373\n",
      "-- Epoch 150, Train Loss : 0.00011631099550868385, Test Loss : 0.9750476479530334\n",
      "-- Epoch 200, Train Loss : 6.579898217751179e-05, Test Loss : 1.025742769241333\n",
      "-- Epoch 250, Train Loss : 4.2096147808479145e-05, Test Loss : 1.0658119916915894\n",
      "-- Epoch 300, Train Loss : 2.9237449780339375e-05, Test Loss : 1.0989055633544922\n",
      "-- Epoch 350, Train Loss : 2.1445138372655492e-05, Test Loss : 1.1270862817764282\n",
      "-- Epoch 400, Train Loss : 1.640715845496743e-05, Test Loss : 1.1517056226730347\n",
      "-- Epoch 450, Train Loss : 1.2926253020850709e-05, Test Loss : 1.1737653017044067\n",
      "-- Epoch 500, Train Loss : 1.042755593516631e-05, Test Loss : 1.1937248706817627\n",
      "-- Epoch 550, Train Loss : 8.575847004976822e-06, Test Loss : 1.2120065689086914\n",
      "-- Epoch 600, Train Loss : 7.143381708374363e-06, Test Loss : 1.2289206981658936\n",
      "-- Epoch 650, Train Loss : 6.028262987456401e-06, Test Loss : 1.2446531057357788\n",
      "-- Epoch 700, Train Loss : 5.18505794389057e-06, Test Loss : 1.2594454288482666\n",
      "-- Epoch 750, Train Loss : 4.452428697732103e-06, Test Loss : 1.2734150886535645\n",
      "-- Epoch 800, Train Loss : 3.906096594619157e-06, Test Loss : 1.2866523265838623\n",
      "-- Epoch 850, Train Loss : 3.4279693181815674e-06, Test Loss : 1.299258828163147\n",
      "-- Epoch 900, Train Loss : 3.0280095870693913e-06, Test Loss : 1.311326026916504\n",
      "-- Epoch 950, Train Loss : 2.6497262410885014e-06, Test Loss : 1.3227673768997192\n",
      "-- Epoch 1000, Train Loss : 2.3533123112429166e-06, Test Loss : 1.3336848020553589\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAFXCAYAAAC1NambAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAApiklEQVR4nO3dfXxU5Z338c8vISaCKPJglQCJbNW7iAg1t1RbWxS7rWjrble32qhg7fISu6JtV1ulT+tKt9671YpuRWzFp9jaWkVb7Vq1umJV3MAigg8r2gSCigiCIPIQ8rv/OGdgGPIwQ2bm5Mp836/XvDLnYc65zmSS71zXdc51zN0RERHJVlnSBRARkbAoOEREJCcKDhERyYmCQ0REcqLgEBGRnCg4REQkJwoOkW4ysxPM7NUi7u9fzezSYu2vnf3/0Mzu6mT582Z2ZDHLJMWl4JBuMbMmMzs56XIUk5m5mX00Ne3u8939iCLtewhwHnBzMfa3l/4duCrpQkjhKDhEOmBmfZIuQzumAA+7+4dJF6QTDwInmtnBSRdECkPBIQVhZpVm9lMzezN+/NTMKuNlg83s92a23szWmdl8MyuLl33bzFaZ2UYze9XMJnaw/QPM7A4zW2NmzWb2XTMri/e73sxGp607xMw+NLOD4unTzGxxvN4zZjYmbd2muAxLgA8yw8PMnoqfvmBmm8zsy2Y2wcxaMrZxmZktMbMPzOwXZvYRM/tDfFyPmdmBaet/Ii7HejN7wcwmdPLWngL8V0aZujqeK8zsJTN7z8zmmllV2vJ/MLPl8e/hQTMbmrbsSDN7NF622syuTNvtPvH7v9HMlplZXWqBu28BFgKf6+Q4JGTurocee/0AmoCT25l/FfAccBAwBHgG+Jd42b8Cs4GK+HECYMARwEpgaLxeLfBXHez3DuABoH+83v8CF8TLbgVmpq37deA/4+fjgHeA8UA5MDk+hsq041kMDAf27WDfDnw0bXoC0JLxnjwHfASojve3KN53FfAn4AfxutXAWmAS0Re5z8bTQzrY9xrg/6ZNZ3M8S+PjGQj8Gbg6XnYS8C7wcaASuAF4Kl7WH3gL+FZc5v7A+HjZD4EtcZnL49/ncxnlnAVcm/TnU4/CPFTjkEKpB65y93fcfQ3wz8C58bLtwCFAjbtv96iPwIEdRP/ARplZhbs3ufvrmRs2s3LgLOAKd9/o7k3AT9K2f3e8POUr8TyAqcDN7r7A3Xe4++3AVuATaevPcveV3r3moBvcfbW7rwLmAwvc/X88+jZ+P9E/fIBziJqeHnb3Nnd/FGgk+qfcngHAxrTpbI7nxvh41gEzgbPj+fXAre6+yN23AlcAx5lZLXAa8La7/8Tdt8Tv84K0bT4dl3kHcCdwdEY5N8ZllV5IwSGFMhRoTptujucB/BuwHPijmb1hZt8BcPflwKVE32jfMbNfpTedpBlMVFPJ3H51/PwJoK+ZjY//CY4l+mcNUAN8K27WWW9m64m+jafvZ2WuB9uO1WnPP2xner+08pyZUZ5PEQVre94j+vafkuvxpP8edvsdufsmotpOdbyNPUI7zdtpzzcDVRnNev2B9Z28XgKm4JBCeZPon1rKiHge8bfXb7n7SOCLwDdTfRnufre7fyp+rQPXtLPtd4lqLZnbXxVvYwfwa6Jv1mcDv3f31Lf0lUTNWAPSHn3d/Zdp2yrmkNErgTszytPP3X/cwfpLgMMzXt/V8QxPe77z90DG78jM+gGDiN7HlcDIbhzXx4AXuvF66cEUHJIPFWZWlfboA/wS+G7cMT0Y+D5wF+zszP2omRmwgaiJqs3MjjCzk+JO9C1E38zbMneWFgwzzay/mdUA30xtP3Y38GWi5pi70+bfAlwY10bMzPqZ2almlv4tviur6d4/1XR3AV8ws8+ZWXn8/k0ws2EdrP8w8Jm06WyO5+tmNszMBgIzgHvi+b8EzjezsfF7/iOiJrUm4PfAIWZ2aXzCQX8zG5/NAcWd78cAj2b5HkhgFBySDw8T/ZNPPX4IXE3UVr8EeJGoc/jqeP3DgMeATcCzwM/c/Qmi/o0fE9Uo3ibqWL+ig31eDHwAvAE8TRQOt6YWxu3xHxA1x/whbX4j8A/AjUTNPsuJTnHNxQ+B2+Omob/P8bW7cfeVwOnAlUQd3yuBy+j4b/MOYJKZ7Ru/PpvjuRv4I9F79Trx78HdHwO+B/yWqCP8r4j7huIa2meBLxD9Ll4DTszysL4APOnub3a5pgTJoj5JEQmFmf0IeMfdf5rFuk3A1+KQKAozW0B0htvSYu1TiqsnXuAkIp1w9yu7Xis57p5Vk5aES01VIiKSEzVViYhITlTjEBGRnCg4REQkJ8F1jpsN9mhoosgxxyRXFhGRUCxcuPBddx+Sj20FFxxRaDQCUFMDjY2JFkZEJAhm1tz1WtkJtqmqb1+YOTPpUoiIlJ4gg2P4cJgzB+rrky6JiEjpCbCpCl54AQ48sOv1REQk/4KscWzdmnQJRERKV5DBsW1b0iUQESldCg4REcmJgkNERHISZHCMHg21tdDQkHRJRERKT5DB4Q7NzTB1qsJDRKTYggyOlM2bYcaMpEshIlJagg4OgBUrki6BiEhpCT44RoxIugQiIqUl6ODQeFUiIsUXZHCYRSPjarwqEZHiC3KsqjvugHPOSboUIiKlKcgahy4AFBFJjoJDRERyouAQEZGcFCw4zGy4mT1hZi+Z2TIzu6SddSaY2QYzWxw/vp/NthUcIiLJKWTneCvwLXdfZGb9gYVm9qi7v5Sx3nx3Py2XDet+HCIiySlYjcPd33L3RfHzjcDLQHU+tq0ah4hIcorSx2FmtcA4YEE7i48zsxfM7A9mdmQHr59qZo1m1ggKDhGRJBU8OMxsP+C3wKXu/n7G4kVAjbsfDdwAzGtvG+4+x93r3L0O4Mc/1rDqIiJJKWhwmFkFUWg0uPt9mcvd/X133xQ/fxioMLPB2Wxbw6qLiCSjkGdVGfAL4GV3v7aDdQ6O18PMjo3LszbbfWhYdRGR4ivkWVWfBM4FXjSzxfG8K4ERAO4+GzgDmGZmrcCHwFnu7rnsRMOqi4gUV8GCw92fBqyLdW4EbuzOfjSsuohIcQV55XiKhlUXESm+YINDw6qLiCQjuGHVq6rglFPgvj3O0RIRkWIIrsZhBq2tSZdCRKR0BRkcO3YkXQoRkdIVZHCoxiEikpzgggMUHCIiSQouONRUJSKSrCCDQzUOEZHkBBkcqnGIiCQnuOAA1ThERJIUXHCoqUpEJFlBBoeaqkREkhNkcKjGISKSnOCCAxQcIiJJCi441FQlIpKsIINDNQ4RkeQoOEREJCfBBQeoqUpEJEnBBce6dbB6NdTWQkND0qURESk9wQVHW1v0s7kZpk5VeIiIFFtwwZFu82aYMSPpUoiIlJaggwNgxYqkSyAiUlqCD44RI5IugYhIaQk6OPr2hZkzky6FiEhpCS44ysujnzU1MGcO1NcnWx4RkVLTJ+kC5Oqgg+Ctt6CpKemSiIiUpuBqHCmp03JFRKS4ggsOs+ingkNEJBnBBUeKhh0REUlGcMGhGoeISLKCC44UBYeISDKCC45UjUNNVSIiyQguOFJU4xARSUZwwaEah4hIsoILjhTVOEREkhFccOisKhGRZAUXHClqqhIRSUZwwaEah4hIsoILjhTVOEREkhFccKjGISKSrOCCI0XBISKSjIIFh5kNN7MnzOwlM1tmZpe0s46Z2SwzW25mS8zs411vN/qppioRkWQU8kZOrcC33H2RmfUHFprZo+7+Uto6pwCHxY/xwE3xzy6pxiEikoyC1Tjc/S13XxQ/3wi8DFRnrHY6cIdHngMGmNkhnW1XNQ4RkWQVpY/DzGqBccCCjEXVwMq06Rb2DJd2qcYhIpKMggeHme0H/Ba41N3f38ttTDWzRjNr3Lgx2oSCQ0QkGQUNDjOrIAqNBne/r51VVgHD06aHxfN24+5z3L3O3ev2339/QE1VIiJJKeRZVQb8AnjZ3a/tYLUHgfPis6s+AWxw97c63270UzUOEZFkFPKsqk8C5wIvmtnieN6VwAgAd58NPAxMApYDm4Hzs924ahwiIskoWHC4+9OAdbGOA1/PZbuqcYiIJEtXjouISE6CCw5dxyEikqzggiNFNQ4RkWQEFxwbN0Y/TzoJamuhoSHR4oiIlJzgguPtt6Of7tDcDFOnKjxERIopuOBw331682aYMSOZsoiIlKLggqM9K1YkXQIRkdLRK4JjxIikSyAiUjqCCw7LuKSwb1+YOTOZsoiIlKLgguOQ+G4dZlBTA3PmQH19smUSESklhRyrqiAGDIA334R774UvfSnp0oiIlJ7gahwpmWdXiYhIcQQbHLpyXEQkGcEFh0bHFRFJVnDBkaLgEBFJRnDBoRqHiEiygguOFAWHiEgyFBwiIpKT4IJDTVUiIskKLjhSFBwiIskILjhU4xARSVZwwZGi4BARSYaCQ0REchJccKipSkQkWcEFR4qCQ0QkGcEFh2ocIiLJCi44UhQcIiLJCC44VOMQEUlWcMGRouAQEUmGgkNERHISXHCoqUpEJFnBBUeKgkNEJBnBBYdqHCIiyQouOFIUHCIiyVBwiIhIToIMjrIyBYeISFIUHCIikhMFh4iI5ETBISIiOVFwiIhIThQcIiKSEwWHiIjkRMEhIiI5KVhwmNmtZvaOmS3tYPkEM9tgZovjx/ez3baCQ0QkOX0KuO3bgBuBOzpZZ767n5brhhUcIiLJKViNw92fAtYVYtsKDhGR5CTdx3Gcmb1gZn8wsyOzfZGCQ0QkOYVsqurKIqDG3TeZ2SRgHnBYeyua2VRgKsCIESMUHCIiCUqsxuHu77v7pvj5w0CFmQ3uYN057l7n7nVDhgxRcIiIJCix4DCzg82i2zKZ2bFxWdZm81oFh4hIcgrWVGVmvwQmAIPNrAX4AVAB4O6zgTOAaWbWCnwInOXuns22FRwiIsmxLP9X9xgjR9b5ypWNtLZCTQ3MnAn19UmXSkSkZzOzhe5el49tZdVUZWb9zKwsfn64mX3RzCryUYBcNTdDa+uu51OnQkNDEiURESlN2fZxPAVUmVk18EfgXKIL/Ious4lq82aYMSOJkoiIlKZsg8PcfTPwJeBn7n4mkPV1F4W2YkXSJRARKR1ZB4eZHQfUAw/F88oLU6TcjRiRdAlEREpHtsFxKXAFcL+7LzOzkcATBStVJ8oySty3b9RBLiIixZHzWVVxJ/l+7v5+YYrUuZEj67ylpZHt23VWlYhItvJ5VlVW13GY2d3AhcAO4L+B/c3senf/t3wUIhcDB8L++0NtLcybV+y9i4hItk1Vo+Iaxt8AfwAOJTqzqvgWLuThl2r51AqdgysikoRsg6Mivm7jb4AH3X07kNiVg0O3N/OPS3QBh4hIErINjpuBJqAf8JSZ1QCJ9HGkVO3QBRwiUoIaGqCyEsxyehwDx+SrCHs95IiZ9XH31nwVJFt1Zt64qxAatEpEwnTRRXDTTUXbXR3Q6G752Fa2Q44cYGbXmllj/PgJUe0jWbqAQ0SSdtFFOX/7x6yooZFv2TZV3QpsBP4+frwPzC1UobLRhsGkSUkWQUR6m5NPLqkA2FvZBsdfufsP3P2N+PHPwMhCFqwrZTjcfrs6yEWkfXtTE3j88aRLHYRsg+NDM/tUasLMPkl0D41kaYRDkdKRa22gBGsCxZLtjZwuBO4wswPi6feAyYUpUo40wqFImIrcOSz5k1WNw91fcPejgTHAGHcfB5xU0JJlSx3kIj1HLrUChUZ+TJsG7l0+FsLCfO0yp3uOu/v7aWNUfTNfhdhrFRUa4VCk0HIJA/UR7J2qKrjrrqwCYI/Hz35W9OJ2557jeTkfuFss+SKIBOnkk/VPvhCqquDnP+/1I6/mVOPIkPzNyrdtU+e4SLpsawcKja5NnJj7t/8PP+z1oQFd1DjMbCPtB4QB+xakRLlS57iUAnUkd0+J1ASKpdPgcPf+xSrIXlPnuIROzUa5mzgRHnss6VKUrO40VSVPt/+Tni6bpiOFRu6dwwqNRIUXHGY48GZFDcyZo6qnJCebK5NLORRy6SMokb6B3qI7Z1UlY7/9eHWfozjj4D+zVJ8zKST1K+xJTURCiMFRVkbljs0aTV26r6EBvvrV6Oy8UqYwkByF11S1cSO16xfz6Gu1GuBQOtfVDW/OOad3h0a2TUUKDclReMHR1oYB1a3NMFW3jy15nYVDbw2GbDuSFQhSIHt9B8Ck7HYHQICaGmhqSqg0UhSl1KSkZiMpEDNb6O51+dhWeH0cmXQBYO/R2zujFQrSS4QfHLoAMDy98YI3XZksJSS8Po50ugCwZ+voOocQQ6OrfgVdhyAlJLzgKC8HYFXZcF0A2FN01EEdWrNTZ/c1UDCI7BRecAwdCsBfD/kf/SEnob1aRChnL3V1w5sE7msgEqLw+jjie3D02bE14YKUgBA7q6dNUwCIFFh4wVEWVZIq2hQceRXSKa8KB5FEhRcccY2jYseWhAsSuJ5+ZpPOUhLpscILDtU4cteTaxO6tkEkOOF1jqdqHAqOjmWe5dQTOq87Op1VoSESnPCCY9MmAB794DiordVYVdDzgqK9s5d0OqtIrxFeU9Xq1QCU4dAcD3QIpfVPqac0PakfQqQkhVfjyByUcfNmmDEjmbIUU/otSJOoUbTX1KRahEhJCi842tMbBzrMbH4q9hlQmc1NCgkRiRUsOMzsVjN7x8yWdrDczGyWmS03syVm9vG93llvGegw/arsYtYq2rvhj66TEJEOFLLGcRvw+U6WnwIcFj+mAtldohyfVbVT6AMdpodFsa7SzqxN6MwmEclBwYLD3Z8C1nWyyunAHR55DhhgZod0ueHhw6PtQ3QTpxAHOix2WGQGhWoTItINSfZxVAMr06Zb4nl7MLOpZtZoZo3vxp3j3+In+F+awgmN9D6LQoeFgkJECiiIznF3n+Pude5eN3jIEAAq2brHCVY9Uqp2Ucg+CwWFiBRRksGxChieNj0sntepdeuiPo5KtnLooT30+r9C1y4yO7MVFCJSREkGx4PAefHZVZ8ANrj7W129qHkFbKOCKrawYkV0/V+PCY9C1i7SaxXqzBaRBBXydNxfAs8CR5hZi5ldYGYXmtmF8SoPA28Ay4FbgIuy2W5bG2yhikqisap6xPV/qcDIZ+0i84I71SpEpIco2JAj7n52F8sd+PrebHsrlTuDAxK8/i/fQ5NrCA8RCUAQneOZtlJJFbvux1H06/9SNYx8hEZ6zUJXZ4tIAIILjkG2jo+wmvOZy1+oZUpFQ/Gu/8tnk1Sqz0JhISKBCW503BqaqaANgFqaucWmxgdRwH++DQ1w7rl7DrCYKzVFiUgvYB7ExRC71Jl5Y+bMmhpoairMDo88El56qXvb0D2yRSRhZrbQ3evysa3gmqraVYje8VSz1N6GRp8+u/ouFBoi0osE11TVrnz3jldXw5tv7t1r1RwlIr1ceDWOsowi53N03FQtY29CY9QodXaLSEkILzhqathesS8OtFbncXTc6uq9O1sq1SS1bFn3yyAiEoDwmqoGDmTFoP/L9sYX6L/gFarbHU83RwceCOvX5/aa8nK4/XbVLkSk5IRX4wDaKqIrx9vaurmhhoaoaSrX0Jg2DVpbFRoiUpLCq3EAbRVVVLGFbd0Jjosuyr1patQoNUmJSMkrzRpHrqFhpn4MEZFYmDWOfboRHLmGhmoZIiK7Ca/GsW4dhz15C33ZzIhP1+Z2M45cQkO1DBGRdoVX42huZp+4qlHxZnN0JyfouqM6l9AYMADee2/vyygi0ouFV+PIbJ/K5k5ODQ3Zh8bQoQoNEZFOhBcc7elqrKrJk7PbzqhRsKrL256LiJS03hEcnY1VVV0NO3Z0vQ11gouIZCW84MhlrKqTT85u3CmFhohI1sILjpoatvYfDMC2wYd0PFZVQ0N2t3ZVaIiI5CS84Bg4kCX/OAeA5dc/3PHZVFOmdL0thYaISM7CCw7gwFefAeBj9R+H2to9r+U4+eRoLKnODB2q0BAR2QvhXcexbh2HLrkBAMOhOeNajmyaqMx09pSIyF4Kr8axahXl27fuPi/9Wo6vfa3rbdx5Z/7LJSJSIsILjm3b2p+/YkVU29iypfPXT5yo4dBFRLrB3D3pMuSkrrLSG9sLj5oaWL268+AoL++670NEpBcys4XuXpePbYVX46iupq28Yvd5FRUwaVLXtY3bby9cuURESkR4wQFR53bm9Ny5nb9GTVQiInkR3llVq1ZR1prRVNVRv0e6xx4rTHlEREpMeDWObEIi07Rp+S+HiEiJCi442sr3yf1FP/tZ/gsiIlKigguO9/wAMs8D6/S8sEGDClgaEZHSE1xw9G/bQEbX+B7Tu7n++gKWRkSk9AQXHPuQQx9Hv346k0pEJM+CC46c+jhuvrlwBRERKVHBBUfZiGq888apXVTbEBHJu+CCg4ED6aI7PKJOcRGRgggvOIC2AVmEgjrFRUQKIsjgyKqlSs1UIiIFEWRwlL23tvMV1EwlIlIwQQYH5eWdL1czlYhIwYQZHDt2dL5czVQiIgUTZHD48JqOF3ZVGxERkW4paHCY2efN7FUzW25m32ln+RQzW2Nmi+NHFjcMh7arZ7Kto6JPndq9QouISKcKFhxmVg78B3AKMAo428xGtbPqPe4+Nn78PJttl51TzxTuYEtFv7SZZdHw6RoJV0SkoApZ4zgWWO7ub7j7NuBXwOn52HBZGdxTVs/Vl28C9+ixY4dCQ0SkCAoZHNXAyrTplnhepr8zsyVmdq+ZDW9vQ2Y21cwazaxxzZo1QHSb8dbWvJdZRES6kHTn+O+AWncfAzwK3N7eSu4+x93r3L1uyJAhAPTpA9u3F6+gIiISKWRwrALSaxDD4nk7uftad98aT/4cOCbbjavGISKSjEIGx38Dh5nZoWa2D3AW8GD6CmZ2SNrkF4GXs9lwQwO8/z7MmgW1tdG0iIgUR59CbdjdW83sH4FHgHLgVndfZmZXAY3u/iAw3cy+CLQC64ApXW133brojNu2tmi6uXnXGbi67k9EpPDMPYshynuQyso637atcY/5NTXQ1FT88oiIhMDMFrp7XT62lXTneM62dXDn2BUrilsOEZFSFVxw7NPBnWNHjChuOURESlVwwVFdDX377j6vb1+YOTOZ8oiIlJrggmPgQJgzByoro+mammhaHeMiIsVRsLOqCqm+HubOhS1b4Omnky6NiEhpCa7GkVJVFQWHiIgUl4JDRERyEnRwfPhh0qUQESk9QfZxgGocIr3F9u3baWlpYYv+oPOiqqqKYcOGUVFRUbB9KDhEJFEtLS3079+f2tpazCzp4gTN3Vm7di0tLS0ceuihBdtPkE1VDQ1wxx3RuFUa5FAkbFu2bGHQoEEKjTwwMwYNGlTw2ltwNY7UIIebN0fTGuRQJHwKjfwpxnsZXI1j1apdoZGyeTPMmJFMeUQkbGvXrmXs2LGMHTuWgw8+mOrq6p3T2zoaHC/W2NjI9OnTc9pfbW0t7777bneKnLjgahwa5FCktDU0RF8UV6yIxqibObN7rQ2DBg1i8eLFAPzwhz9kv/3245/+6Z92Lm9tbaVPn/b/VdbV1VFXl5cBZ4MSXI1DgxyKlK6GhqhpurkZ3Hc1Vee7n3PKlClceOGFjB8/nssvv5znn3+e4447jnHjxnH88cfz6quvAvDkk09y2mmnAVHofPWrX2XChAmMHDmSWbNmZb2/pqYmTjrpJMaMGcPEiRNZEX8T/s1vfsPo0aM5+uij+fSnPw3AsmXLOPbYYxk7dixjxozhtddey+/BZyG4Gkd1NaxevXtzlQY5FOkdLr0U4i//7XruOdi6dfd5mzfDBRfALbe0/5qxY+GnP829LC0tLTzzzDOUl5fz/vvvM3/+fPr06cNjjz3GlVdeyW9/+9s9XvPKK6/wxBNPsHHjRo444gimTZuW1WmxF198MZMnT2by5MnceuutTJ8+nXnz5nHVVVfxyCOPUF1dzfr16wGYPXs2l1xyCfX19Wzbto0dO3bkfnDdFFyNIzXI4aBB0fTQoRrkUKRUZIZGV/O748wzz6S8vByADRs2cOaZZzJ69Gi+8Y1vsGzZsnZfc+qpp1JZWcngwYM56KCDWL16dVb7evbZZ/nKV74CwLnnnsvT8SB8n/zkJ5kyZQq33HLLzoA47rjj+NGPfsQ111xDc3Mz++67b3cPNWfB1TggComqKjjjDPjDH2DMmKRLJCL50FXNoLY2ap7KVFMDTz6Z37L069dv5/Pvfe97nHjiidx///00NTUxYcKEdl9TmRq2GygvL6e1tbVbZZg9ezYLFizgoYce4phjjmHhwoV85StfYfz48Tz00ENMmjSJm2++mZNOOqlb+8lVcDWOlGefjX6OHatrOURKxcyZydyPZ8OGDVRXVwNw22235X37xx9/PL/61a8AaGho4IQTTgDg9ddfZ/z48Vx11VUMGTKElStX8sYbbzBy5EimT5/O6aefzpIlS/Jenq4EGRwNDXDjjdHzQnaQiUjPUl8fNU3X1IBZ8e7Hc/nll3PFFVcwbty4btciAMaMGcOwYcMYNmwY3/zmN7nhhhuYO3cuY8aM4c477+T6668H4LLLLuOoo45i9OjRHH/88Rx99NH8+te/ZvTo0YwdO5alS5dy3nnndbs8uTJ3L/pOu6Ours7ffbexw+pqU1PRiyQi3fDyyy/zsY99LOli9CrtvadmttDd83LucJA1jo6u2dC1HCIihRdkcHR0zYau5RARKbwgg2PmTMg8A03XcoiIFEeQwVFfv6tzHIrXQSYiIoEGB8D550dnVXzve1GHuEJDRKQ4gg2Ou++Ofv7Lv+g6DhGRYgryyvHUQGepM4l1Tw4R2Vtr165l4sSJALz99tuUl5czZMgQAJ5//nn26Whk1diTTz7JPvvsw/HHH7/Hsttuu43GxkZuTG9b7wWCrHHMmKF7coiUrIaGqJmhrCwvzQ2pYdUXL17MhRdeyDe+8Y2d012FBkTB8cwzz3SrDKEJMjh0HYdIiSrSuOoLFy7kM5/5DMcccwyf+9zneOuttwCYNWsWo0aNYsyYMZx11lk0NTUxe/ZsrrvuOsaOHcv8+fOz2v61117L6NGjGT16ND+NB+j64IMPOPXUUzn66KMZPXo099xzDwDf+c53du4z/T4hSQqyqWrEiPYHOtN1HCKB6wHjqrs7F198MQ888ABDhgzhnnvuYcaMGdx66638+Mc/5i9/+QuVlZWsX7+eAQMGcOGFF+5x86fOLFy4kLlz57JgwQLcnfHjx/OZz3yGN954g6FDh/LQQw8B0fhYa9eu5f777+eVV17BzHYOrZ60IGscSQ10JiIJK8K46lu3bmXp0qV89rOfZezYsVx99dW0tLQA0RhT9fX13HXXXR3eFbArTz/9NH/7t39Lv3792G+//fjSl77E/PnzOeqoo3j00Uf59re/zfz58znggAM44IADqKqq4oILLuC+++6jb+Y/voQEWeOor4c//xlmz45qq+XlMHmyOsZFgtcDxlV3d4488kieTQ3Bneahhx7iqaee4ne/+x0zZ87kxRdfzMs+AQ4//HAWLVrEww8/zHe/+10mTpzI97//fZ5//nkef/xx7r33Xm688Ub+9Kc/5W2feyvIGkdDA9x++66zqnbsiKZ1Sq5IL1eE5obKykrWrFmzMzi2b9/OsmXLaGtrY+XKlZx44olcc801bNiwgU2bNtG/f382btyY9fZPOOEE5s2bx+bNm/nggw+4//77OeGEE3jzzTfp27cv55xzDpdddhmLFi1i06ZNbNiwgUmTJnHdddfxwgsv5O04uyPIGkdnZ1Wp1iHSi6X+wGfMiM6GGTEiCo08/uGXlZVx7733Mn36dDZs2EBrayuXXnophx9+OOeccw4bNmzA3Zk+fToDBgzgC1/4AmeccQYPPPAAN9xww857aaTcdtttzJs3b+f0c889x5QpUzj22GMB+NrXvsa4ceN45JFHuOyyyygrK6OiooKbbrqJjRs3cvrpp7NlyxbcnWuvvTZvx9kdQQ6rvmhRI+0V2wza2opfJhHZexpWPf80rHo7Ojp7auDA4pZDRKQUBRkcM2dCRcWe8zduVD+HiEihBRkc9fWw//57zt+2TVePi4gUWpDBAbBuXfvzdfW4SHhC62vtyYrxXgYbHB31Z6ifQyQsVVVVrF27VuGRB+7O2rVrqaqqKuh+gjwdF2DLlvbnd1QTEZGeadiwYbS0tLBmzZqki9IrVFVVMWzYsILuI9jg+OCD9ue7R6flplRVwc9/rus7RHqqiooKDj300KSLITkI8jqOxsbG3cJBRES6Uod7Y17+cwbbxzFoUNIlEBEpTcEGx/XXJ10CEZHSFFxTlZltBF6Npo4cBVX7JlogEZEgNOH+bl6aqkLsHH81X+OthM7MGvVeRPRe7KL3Yhe9F7uYWWO+thVsU5WIiCRDwSEiIjkJMTjmJF2AHkTvxS56L3bRe7GL3otd8vZeBNc5LiIiyQqxxiEiIgkKKjjM7PNm9qqZLTez7yRdnkIys+Fm9oSZvWRmy8zsknj+QDN71Mxei38eGM83M5sVvzdLzOzjyR5B/plZuZn9j5n9Pp4+1MwWxMd8j5ntE8+vjKeXx8trEy14npnZADO718xeMbOXzey4Uv1cmNk34r+PpWb2SzOrKqXPhZndambvmNnStHk5fxbMbHK8/mtmNrmr/QYTHGZWDvwHcAowCjjbzEYlW6qCagW+5e6jgE8AX4+P9zvA4+5+GPB4PA3R+3JY/JgK3FT8IhfcJcDLadPXANe5+0eB94AL4vkXAO/F86+L1+tNrgf+093/D3A00XtScp8LM6sGpgN17j4aKAfOorQ+F7cBn8+Yl9NnwcwGAj8AxgPHAj9IhU2H3D2IB3Ac8Eja9BXAFUmXq4jH/wDwWaKLHw+J5x1CdF0LwM3A2Wnr71yvNzyAYfEfwUnA7wED3gX6ZH4+gEeA4+LnfeL1LOljyNP7cADwl8zjKcXPBVANrAQGxr/n3wOfK7XPBVALLN3bzwJwNnBz2vzd1mvvEUyNg10fkpSWeF6vF1epxwELgI+4+1vxoreBj8TPe/v781PgcqAtnh4ErHf31ng6/Xh3vhfx8g3x+r3BocAaYG7cbPdzM+tHCX4u3H0V8O/ACuAtot/zQkrzc5Eu189Czp+RkIKjJJnZfsBvgUvd/f30ZR59Pej1p8WZ2WnAO+6+MOmy9AB9gI8DN7n7OOADdjVFACX1uTgQOJ0oTIcC/diz2aakFeqzEFJwrAKGp00Pi+f1WmZWQRQaDe5+Xzx7tZkdEi8/BHgnnt+b359PAl80sybgV0TNVdcDA8wsNWxO+vHufC/i5QcAa4tZ4AJqAVrcfUE8fS9RkJTi5+Jk4C/uvsbdtwP3EX1WSvFzkS7Xz0LOn5GQguO/gcPiMyb2IeoEezDhMhWMmRnwC+Bld782bdGDQOqsh8lEfR+p+efFZ058AtiQVl0Nmrtf4e7D3L2W6Pf+J3evB54AzohXy3wvUu/RGfH6veIbuLu/Daw0syPiWROBlyjBzwVRE9UnzKxv/PeSei9K7nORIdfPwiPAX5vZgXEt7q/jeR1LumMnx06gScD/Aq8DM5IuT4GP9VNEVcwlwOL4MYmoTfZx4DXgMWBgvL4RnXX2OvAi0ZkmiR9HAd6XCcDv4+cjgeeB5cBvgMp4flU8vTxePjLpcuf5PRgLNMafjXnAgaX6uQD+GXgFWArcCVSW0ucC+CVR/852otroBXvzWQC+Gr8vy4Hzu9qvrhwXEZGchNRUJSIiPYCCQ0REcqLgEBGRnCg4REQkJwoOERHJiYJDJIOZ7TCzxWmPvI3EbGa16SOZioSoT9eriJScD919bNKFEOmpVOMQyZKZNZnZ/zOzF83seTP7aDy/1sz+FN/j4HEzGxHP/4iZ3W9mL8SP4+NNlZvZLfF9JP5oZvsmdlAie0HBIbKnfTOaqr6ctmyDux8F3Eg0Yi/ADcDt7j4GaABmxfNnAf/l7kcTjSe1LJ5/GPAf7n4ksB74u4IejUie6cpxkQxmtsnd92tnfhNwkru/EQ9A+ba7DzKzd4nuf7A9nv+Wuw82szXAMHffmraNWuBRj26yg5l9G6hw96uLcGgieaEah0huvIPnudia9nwH6muUwCg4RHLz5bSfz8bPnyEatRegHpgfP38cmAY775d+QLEKKVJI+qYjsqd9zWxx2vR/unvqlNwDzWwJUa3h7HjexUR35LuM6O5858fzLwHmmNkFRDWLaUQjmYoETX0cIlmK+zjq3P3dpMsikiQ1VYmISE5U4xARkZyoxiEiIjlRcIiISE4UHCIikhMFh4iI5ETBISIiOVFwiIhITv4/m0PEoKyaRWIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 31.41 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([185])\n",
      "185 vs 185\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 93.182 %\n",
      "- Recall : 80.392 %\n",
      "- F1 : 0.86316\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 97.059 %\n",
      "- Recall : 94.286 %\n",
      "- F1 : 0.95652\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 80.769 %\n",
      "- Recall : 85.714 %\n",
      "- F1 : 0.83168\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 76.364 %\n",
      "- Recall : 84.0 %\n",
      "- F1 : 0.8\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 85.405 %\n",
      "- Precision : 86.843 %\n",
      "- Recall : 86.098 %\n",
      "- F1 : 0.86469\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,false,,,true,,,unverified,,,non-rumor,,,\n",
      "Twitter16_4LayerNet_BERT_Finetuned Validation, 85.405, 86.843, 86.098, 0.86469, 93.182, 80.392, 0.86316, 97.059, 94.286, 0.95652, 80.769, 85.714, 0.83168, 76.364, 84.0, 0.8, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([102])\n",
      "102 vs 102\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 86.957 %\n",
      "- Recall : 74.074 %\n",
      "- F1 : 0.8\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 100.0 %\n",
      "- Recall : 88.462 %\n",
      "- F1 : 0.93878\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 87.5 %\n",
      "- Recall : 84.0 %\n",
      "- F1 : 0.85714\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 71.875 %\n",
      "- Recall : 95.833 %\n",
      "- F1 : 0.82143\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 85.294 %\n",
      "- Precision : 86.583 %\n",
      "- Recall : 85.592 %\n",
      "- F1 : 0.86085\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,false,,,true,,,unverified,,,non-rumor,,,\n",
      "Twitter16_4LayerNet_BERT_Finetuned Test, 85.294, 86.583, 85.592, 0.86085, 86.957, 74.074, 0.8, 100.0, 88.462, 0.93878, 87.5, 84.0, 0.85714, 71.875, 95.833, 0.82143, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "start = time.time()\n",
    "model_name = f\"Twitter16_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55461251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
