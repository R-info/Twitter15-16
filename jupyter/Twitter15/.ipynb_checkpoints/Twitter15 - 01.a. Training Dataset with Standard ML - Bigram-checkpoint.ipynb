{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feff3561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8a6e983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>691809004356501505</td>\n",
       "      <td>america is a nation of second chances â€”@potus ...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693204708933160960</td>\n",
       "      <td>brandon marshall visits and offers advice, sup...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>551099691702956032</td>\n",
       "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "1  714598641827246081  an open letter to trump voters from his top st...   \n",
       "2  691809004356501505  america is a nation of second chances â€”@potus ...   \n",
       "3  693204708933160960  brandon marshall visits and offers advice, sup...   \n",
       "4  551099691702956032  rip elly may clampett: so sad to learn #beverl...   \n",
       "\n",
       "        label       tvt  cv_fold        tt        tvt2  \n",
       "0  unverified  training        1  training  validation  \n",
       "1  unverified  training        1      test    training  \n",
       "2   non-rumor  training        2  training  validation  \n",
       "3   non-rumor  training        1  training    training  \n",
       "4        true  training        3  training    training  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter15_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af92ba46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>unverified</th>\n",
       "      <th>non-rumor</th>\n",
       "      <th>true</th>\n",
       "      <th>false</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca kkk</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kkk grand</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grand wizard</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wizard endorses</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>endorses @hillaryclinton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      token  unverified  non-rumor  true  false\n",
       "0                    ca kkk           1          0     0      0\n",
       "1                 kkk grand           1          0     0      0\n",
       "2              grand wizard           1          0     0      0\n",
       "3           wizard endorses           1          0     0      0\n",
       "4  endorses @hillaryclinton           1          0     0      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_data = pd.read_excel('../../data/processed/twitter15_ngram_distribution.xlsx', sheet_name='bigram')\n",
    "bigram_data.columns = [\"token\", \"unverified\", \"non-rumor\", \"true\", \"false\"]\n",
    "bigram_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d048e008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'to trump'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vector_base = bigram_data['token'].tolist()\n",
    "print(len(bigram_vector_base))\n",
    "bigram_vector_base[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63153167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>label_rnr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>691809004356501505</td>\n",
       "      <td>america is a nation of second chances â€”@potus ...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>non-rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693204708933160960</td>\n",
       "      <td>brandon marshall visits and offers advice, sup...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>non-rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>551099691702956032</td>\n",
       "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "1  714598641827246081  an open letter to trump voters from his top st...   \n",
       "2  691809004356501505  america is a nation of second chances â€”@potus ...   \n",
       "3  693204708933160960  brandon marshall visits and offers advice, sup...   \n",
       "4  551099691702956032  rip elly may clampett: so sad to learn #beverl...   \n",
       "\n",
       "        label       tvt  cv_fold        tt        tvt2    label_rnr  \n",
       "0  unverified  training        1  training  validation      rumours  \n",
       "1  unverified  training        1      test    training      rumours  \n",
       "2   non-rumor  training        2  training  validation  non-rumours  \n",
       "3   non-rumor  training        1  training    training  non-rumours  \n",
       "4        true  training        3  training    training      rumours  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_rnr = []\n",
    "for i, d in data.iterrows():\n",
    "    if d['label'] == \"non-rumor\":\n",
    "        label_rnr.append(\"non-rumours\")\n",
    "    else:\n",
    "        label_rnr.append(\"rumours\")\n",
    "        \n",
    "data['label_rnr'] = pd.Series(label_rnr)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b95fb4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unverified', 'non-rumor', 'true', 'false']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = data['label'].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6ce7b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 0, 0],\n",
       " [1, 0, 0, 0],\n",
       " [0, 1, 0, 0],\n",
       " [0, 1, 0, 0],\n",
       " [0, 0, 1, 0],\n",
       " [0, 1, 0, 0],\n",
       " [1, 0, 0, 0],\n",
       " [0, 0, 1, 0],\n",
       " [1, 0, 0, 0],\n",
       " [0, 0, 0, 1]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d['label'])\n",
    "    labs = [1 if idx == lab else 0 for idx in range(len(labels_str))]\n",
    "    labels.append(labs)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fc83a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "def text2bigrams(text):\n",
    "    bigrams = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    bigrams = [t for t in bigrams if t not in string.punctuation]\n",
    "    bigrams = [t for t in bigrams if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(bigrams)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def bigrams_vectors_generation(texts):\n",
    "    bigram_vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(bigram_vector_base) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in bigram_vector_base:\n",
    "                idx = bigram_vector_base.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        bigram_vectors.append(init_vec)\n",
    "    \n",
    "    return bigram_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97281e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 13843)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "vectors = bigrams_vectors_generation(texts)\n",
    "vectors = np.array(vectors)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "189f900d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ca kkk', 'kkk grand', 'grand wizard', 'wizard endorses', 'endorses @hillaryclinton', '@hillaryclinton #neverhillary', '#neverhillary #trump2016'], ['an open', 'open letter', 'letter to', 'to trump', 'trump voters', 'voters from', 'from his', 'his top', 'top strategist-turned-defector', 'strategist-turned-defector via', 'via @xojanedotcom'], ['america is', 'is a', 'a nation', 'nation of', 'of second', 'second chances', 'chances @potus', '@potus on', 'on new', 'new reforms', 'reforms to', 'to solitary', 'solitary confinement'], ['brandon marshall', 'marshall visits', 'visits and', 'and offers', 'offers advice', 'advice support', 'support to', 'to brother', 'brother of', 'of fallen', 'fallen hero', 'hero zaevion', 'zaevion dobson'], ['rip elly', 'elly may', 'may clampett', 'clampett so', 'so sad', 'sad to', 'to learn', 'learn #beverlyhillbillies', '#beverlyhillbillies star', 'star donna', 'donna douglas', 'douglas has', 'has passed', 'passed away']]\n",
      "(1490, 13842)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/storage/Work/DataScience/.venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "raw_texts = data['tweet_text'].tolist()\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "texts = [tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8')) for text in raw_texts]\n",
    "texts = [[t for t in text if t not in string.punctuation] for text in texts]\n",
    "texts = [[t for t in text if t not in ['URL', 'â€˜', 'â€™']] for text in texts]\n",
    "\n",
    "tokens = []\n",
    "\n",
    "for i, text in enumerate(texts):\n",
    "    bigrms = nltk.bigrams(text)\n",
    "    bigrms = map(' '.join, bigrms)\n",
    "    bigrms = [b for b in bigrms]\n",
    "    tokens.append(bigrms)\n",
    "print(tokens[:5])\n",
    "    \n",
    "corpus = tokens\n",
    "\n",
    "def identity_tokenizer(text):\n",
    "    return text\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=identity_tokenizer, stop_words=\"english\", lowercase=False)\n",
    "vectors = vectorizer.fit_transform(corpus)\n",
    "vectors = vectors.toarray()\n",
    "print(vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cccd2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f3f387c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RANDOM FOREST ---\n",
      "---> execution time : 6.1 seconds\n",
      "Validation Set\n",
      "348 vs 348\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 52.174 %\n",
      "- Recall : 53.933 %\n",
      "- F1 : 0.53039\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 46.875 %\n",
      "- Recall : 86.207 %\n",
      "- F1 : 0.60729\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 98.0 %\n",
      "- Recall : 55.682 %\n",
      "- F1 : 0.71014\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 100.0 %\n",
      "- Recall : 54.762 %\n",
      "- F1 : 0.70769\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 62.644 %\n",
      "- Precision : 74.262 %\n",
      "- Recall : 62.646 %\n",
      "- F1 : 0.67961\n",
      "\n",
      "- Average Confidence : 80.75 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Anonymous, 62.644, 74.262, 62.646, 0.67961, 52.174, 53.933, 0.53039, 46.875, 86.207, 0.60729, 98.0, 55.682, 0.71014, 100.0, 54.762, 0.70769, \n",
      "Test Set\n",
      "143 vs 143\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 55.263 %\n",
      "- Recall : 60.0 %\n",
      "- F1 : 0.57534\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 53.226 %\n",
      "- Recall : 91.667 %\n",
      "- F1 : 0.67347\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 100.0 %\n",
      "- Recall : 72.222 %\n",
      "- F1 : 0.83871\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 94.118 %\n",
      "- Recall : 44.444 %\n",
      "- F1 : 0.60377\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 67.133 %\n",
      "- Precision : 75.652 %\n",
      "- Recall : 67.083 %\n",
      "- F1 : 0.7111\n",
      "\n",
      "- Average Confidence : 81.12 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Anonymous, 67.133, 75.652, 67.083, 0.7111, 55.263, 60.0, 0.57534, 53.226, 91.667, 0.67347, 100.0, 72.222, 0.83871, 94.118, 44.444, 0.60377, \n",
      "--- END ---\n",
      "\n",
      "\n",
      "--- K-NEAREST NEIGHBOR ---\n",
      "---> execution time : 0.01 seconds\n",
      "Validation Set\n",
      "348 vs 348\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 46.835 %\n",
      "- Recall : 83.146 %\n",
      "- F1 : 0.59919\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 60.976 %\n",
      "- Recall : 28.736 %\n",
      "- F1 : 0.39062\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 95.161 %\n",
      "- Recall : 67.045 %\n",
      "- F1 : 0.78667\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 67.816 %\n",
      "- Recall : 70.238 %\n",
      "- F1 : 0.69006\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 62.356 %\n",
      "- Precision : 67.697 %\n",
      "- Recall : 62.291 %\n",
      "- F1 : 0.64882\n",
      "\n",
      "- Average Confidence : 64.37 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Anonymous, 62.356, 67.697, 62.291, 0.64882, 46.835, 83.146, 0.59919, 60.976, 28.736, 0.39062, 95.161, 67.045, 0.78667, 67.816, 70.238, 0.69006, \n",
      "Test Set\n",
      "143 vs 143\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 42.424 %\n",
      "- Recall : 80.0 %\n",
      "- F1 : 0.55446\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 57.895 %\n",
      "- Recall : 30.556 %\n",
      "- F1 : 0.4\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 96.0 %\n",
      "- Recall : 66.667 %\n",
      "- F1 : 0.78689\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 66.667 %\n",
      "- Recall : 61.111 %\n",
      "- F1 : 0.63768\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 59.441 %\n",
      "- Precision : 65.746 %\n",
      "- Recall : 59.583 %\n",
      "- F1 : 0.62513\n",
      "\n",
      "- Average Confidence : 63.64 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Anonymous, 59.441, 65.746, 59.583, 0.62513, 42.424, 80.0, 0.55446, 57.895, 30.556, 0.4, 96.0, 66.667, 0.78689, 66.667, 61.111, 0.63768, \n",
      "--- END ---\n",
      "\n",
      "\n",
      "--- SUPPORT VECTOR MACHINE ---\n",
      "---> execution time : 0.07 seconds\n",
      "Validation Set\n",
      "348 vs 348\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 85.714 %\n",
      "- Recall : 67.416 %\n",
      "- F1 : 0.75472\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 54.412 %\n",
      "- Recall : 85.057 %\n",
      "- F1 : 0.66368\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 89.744 %\n",
      "- Recall : 79.545 %\n",
      "- F1 : 0.84337\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 90.625 %\n",
      "- Recall : 69.048 %\n",
      "- F1 : 0.78378\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 75.287 %\n",
      "- Precision : 80.124 %\n",
      "- Recall : 75.267 %\n",
      "- F1 : 0.7762\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Anonymous, 75.287, 80.124, 75.267, 0.7762, 85.714, 67.416, 0.75472, 54.412, 85.057, 0.66368, 89.744, 79.545, 0.84337, 90.625, 69.048, 0.78378, \n",
      "Test Set\n",
      "143 vs 143\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 77.778 %\n",
      "- Recall : 60.0 %\n",
      "- F1 : 0.67742\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 58.929 %\n",
      "- Recall : 91.667 %\n",
      "- F1 : 0.71739\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 93.939 %\n",
      "- Recall : 86.111 %\n",
      "- F1 : 0.89855\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 88.889 %\n",
      "- Recall : 66.667 %\n",
      "- F1 : 0.7619\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 76.224 %\n",
      "- Precision : 79.884 %\n",
      "- Recall : 76.111 %\n",
      "- F1 : 0.77952\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Anonymous, 76.224, 79.884, 76.111, 0.77952, 77.778, 60.0, 0.67742, 58.929, 91.667, 0.71739, 93.939, 86.111, 0.89855, 88.889, 66.667, 0.7619, \n",
      "--- END ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from library.classification import SKLearnClassification\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Phemernr\"\n",
    "\n",
    "random_forest = RandomForestClassifier(class_weight=\"balanced\")\n",
    "neigh = KNeighborsClassifier(n_neighbors=5, weights=\"distance\")\n",
    "svm = LinearSVC(class_weight=\"balanced\")\n",
    "\n",
    "models = [\n",
    "    SKLearnClassification(random_forest, \"Random Forest\"),\n",
    "    SKLearnClassification(neigh, \"K-Nearest Neighbor\"),\n",
    "    SKLearnClassification(svm, \"Support Vector Machine\"),\n",
    "]\n",
    "for model in models:\n",
    "    print(f\"\\n--- {model.model_name.upper()} ---\")\n",
    "    if model.model_name == \"Support Vector Machine\":\n",
    "        y = [l.tolist().index(max(l)) for l in train_labels]\n",
    "        model.train(train_vectors, y, dataset_name)\n",
    "    else:\n",
    "        model.train(train_vectors, train_labels, dataset_name)\n",
    "    \n",
    "    print(\"Validation Set\")\n",
    "    preds = model.predict(val_vectors)\n",
    "    if model.model_name == \"Support Vector Machine\":\n",
    "        preds = np.array([[1 if p == idx else 0 for idx in range(len(labels_str))] for p in preds])\n",
    "#     print(preds)\n",
    "\n",
    "    conf_mat = ConfusionMatrix(\n",
    "        labels=val_labels,\n",
    "        predictions=preds,\n",
    "        binary=False\n",
    "    )\n",
    "    conf_mat.evaluate(labels_str)\n",
    "    \n",
    "    print(\"Test Set\")\n",
    "    preds = model.predict(test_vectors)\n",
    "    if model.model_name == \"Support Vector Machine\":\n",
    "        preds = np.array([[1 if p == idx else 0 for idx in range(len(labels_str))] for p in preds])\n",
    "\n",
    "    conf_mat = ConfusionMatrix(\n",
    "        labels=test_labels,\n",
    "        predictions=preds,\n",
    "        binary=False\n",
    "    )\n",
    "    conf_mat.evaluate(labels_str)\n",
    "\n",
    "    print(\"--- END ---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1f3a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
