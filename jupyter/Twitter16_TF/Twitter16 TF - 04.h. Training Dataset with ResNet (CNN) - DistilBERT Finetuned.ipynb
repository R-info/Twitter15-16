{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "# random.seed(33)\n",
    "\n",
    "dataset_name = \"Twitter16-TF\"\n",
    "unique_name = \"DistilBERT_Finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(412, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter16-TF_DistilBERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "first = vectors[0]\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>656955120626880512</td>\n",
       "      <td>correct predictions in back to the future ii U...</td>\n",
       "      <td>False</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>615689290706595840</td>\n",
       "      <td>.@whitehouse in rainbow colors for #scotusmarr...</td>\n",
       "      <td>True</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>613404935003217920</td>\n",
       "      <td>cops bought the alleged church shooter burger ...</td>\n",
       "      <td>False</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>614467824313106432</td>\n",
       "      <td>god put a rainbow over the white house ðŸŒˆ URL\\r</td>\n",
       "      <td>True</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>622891631293935616</td>\n",
       "      <td>#wakeupamericaðŸ‡ºðŸ‡¸ who needs a #gun registry whe...</td>\n",
       "      <td>False</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  656955120626880512  correct predictions in back to the future ii U...   \n",
       "1  615689290706595840  .@whitehouse in rainbow colors for #scotusmarr...   \n",
       "2  613404935003217920  cops bought the alleged church shooter burger ...   \n",
       "3  614467824313106432     god put a rainbow over the white house ðŸŒˆ URL\\r   \n",
       "4  622891631293935616  #wakeupamericaðŸ‡ºðŸ‡¸ who needs a #gun registry whe...   \n",
       "\n",
       "   label        tvt2  \n",
       "0  False    training  \n",
       "1   True    testting  \n",
       "2  False  validation  \n",
       "3   True  validation  \n",
       "4  False    training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter16-tf_dataset.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4698ab17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = data['label'].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "maritime-bradley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 1, 0, 1, 1, 0, 0, 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d['label'])\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "quality-burst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(275, 768)\n",
      "(98, 768)\n",
      "(39, 768)\n",
      "(275,)\n",
      "(98,)\n",
      "(39,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e860c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.lin1 = nn.Linear(in_planes, planes)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.lin2 = nn.Linear(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Linear(in_planes, planes),\n",
    "                nn.BatchNorm1d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = self.bn2(self.lin2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.lin1 = nn.Linear(in_planes, planes)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.lin2 = nn.Linear(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "        self.lin3 = nn.Linear(planes, planes)\n",
    "        self.bn3 = nn.BatchNorm1d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Linear(in_planes, planes),\n",
    "                nn.BatchNorm1d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = F.leaky_relu(self.bn2(self.lin2(out)), 0.1)\n",
    "        out = self.bn3(self.lin3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, n_input=768, num_classes=1):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 512\n",
    "\n",
    "        self.lin1 = nn.Linear(n_input, self.in_planes)\n",
    "        self.bn1 = nn.BatchNorm1d(self.in_planes)\n",
    "        self.layer1 = self._make_layer(block, 512, num_blocks[0])\n",
    "        self.layer2 = self._make_layer(block, 256, num_blocks[1])\n",
    "        self.layer3 = self._make_layer(block, 128, num_blocks[2])\n",
    "        self.layer4 = self._make_layer(block, 64, num_blocks[3])\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks):\n",
    "        strides = [1] * num_blocks\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet10(n_input=768, n_output=1, block=BasicBlock):\n",
    "    return ResNet(block, [1, 1, 1, 1], n_input, n_output)\n",
    "\n",
    "    \n",
    "def ResNet18(n_input=768, n_output=1, block=BasicBlock):\n",
    "    return ResNet(block, [2, 2, 2, 2], n_input, n_output)\n",
    "\n",
    "\n",
    "def ResNet34(n_input=768, n_output=1, block=BasicBlock):\n",
    "    return ResNet(block, [3, 4, 6, 3], n_input, n_output)\n",
    "\n",
    "\n",
    "def ResNet50(n_input=768, n_output=1, block=Bottleneck):\n",
    "    return ResNet(block, [3, 4, 6, 3], n_input, n_output)\n",
    "\n",
    "\n",
    "def ResNet101(n_input=768, n_output=1, block=Bottleneck):\n",
    "    return ResNet(block, [3, 4, 23, 3], n_input, n_output)\n",
    "\n",
    "\n",
    "def ResNet152(n_input=768, n_output=1, block=Bottleneck):\n",
    "    return ResNet(block, [3, 8, 36, 3], n_input, n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e05091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CNNBasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(CNNBasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.conv1(x)), 0.1)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class CNNBottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes):\n",
    "        super(CNNBottleneck, self).__init__()\n",
    "        self.lin1 = nn.Linear(in_planes, planes)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.lin2 = nn.Linear(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.lin3 = nn.Linear(planes, planes)\n",
    "        self.bn3 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Linear(in_planes, planes),\n",
    "                nn.BatchNorm1d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = F.leaky_relu(self.bn2(self.lin2(out)), 0.1)\n",
    "        out = self.bn3(self.lin3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class CNNResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=1):\n",
    "        super(CNNResNet, self).__init__()\n",
    "        self.in_planes = 24\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 24, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(24)\n",
    "        self.layer1 = self._make_layer(block, 24, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 48, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 64, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(64 * 24 * 32, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.conv1(x)), 0.1)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def CNNResNet10(n_output: int):\n",
    "    return CNNResNet(CNNBasicBlock, [1, 1, 1, 1], n_output)\n",
    "\n",
    "    \n",
    "def CNNResNet18(n_output: int):\n",
    "    return CNNResNet(CNNBasicBlock, [2, 2, 2, 2], n_output)\n",
    "\n",
    "\n",
    "def CNNResNet34(n_output: int):\n",
    "    return CNNResNet(CNNBasicBlock, [3, 4, 6, 3], n_output)\n",
    "\n",
    "\n",
    "def CNNResNet50(n_output: int):\n",
    "    return CNNResNet(CNNBottleneck, [3, 4, 6, 3], n_output)\n",
    "\n",
    "\n",
    "def CNNResNet101(n_output: int):\n",
    "    return CNNResNet(CNNBottleneck, [3, 4, 23, 3], n_output)\n",
    "\n",
    "\n",
    "def CNNResNet152(n_output: int):\n",
    "    return CNNResNet(CNNBottleneck, [3, 8, 36, 3], n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class ResNetClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        model,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        n_features: int = 4,\n",
    "        lr: float = 0.0002,\n",
    "        beta1: float = 0.5,\n",
    "        device: str = None,\n",
    "        model_type: str = \"mlp\"\n",
    "    ):\n",
    "        super(ResNetClassifier, self).__init__()\n",
    "        self.model = model\n",
    "        self.model_type = model_type\n",
    "        self.criterion = criterion()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.model(input)\n",
    "        return x\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def save_model(self, saves: str):\n",
    "        print(f\"Saving model...\")\n",
    "        state = {\n",
    "            'net': self.model.state_dict()\n",
    "        }\n",
    "        if not os.path.isdir('models'):\n",
    "            os.mkdir('models')\n",
    "        torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        current_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "\n",
    "                if self.model_type == \"cnn\":\n",
    "                    outputs = self.model(inputs.unsqueeze(1))\n",
    "                elif self.model_type == \"mlp\":\n",
    "                    outputs = self.model(inputs)\n",
    "\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "#                 for i, output in enumerate(outputs.tolist()):\n",
    "#                     if targets[i,0].tolist() == round(output[0]):\n",
    "#                         correct += 1\n",
    "\n",
    "#             train_acc = round(100*correct/total, 4)\n",
    "#             train_accs.append(train_acc)\n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                \n",
    "                if self.model_type == 'mlp':\n",
    "                    outputs = self.model(inputs)\n",
    "                else:\n",
    "#                     outputs = self.model(inputs.reshape(inputs.shape[0], 1, 24, 32))\n",
    "                    outputs = self.model(inputs.unsqueeze(1))\n",
    "\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                if self.model_type == 'mlp':\n",
    "                    preds = self.predict(test_x)\n",
    "                else:\n",
    "                    preds = self.predict(test_x.reshape(test_x.shape[0], 1, 24, 32))\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61ccef0e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification Twitter16-TF_ResNet10_CNN_DistilBERT_Finetuned\n",
      "Exec Time : 2.14 seconds\n",
      "\n",
      "---- Validation Set ----\n",
      "Predictions : torch.Size([98])\n",
      "98 vs 98\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class False Evaluation\n",
      "- Precision : 91.071 %\n",
      "- Recall : 100.0 %\n",
      "- F1 : 0.95327\n",
      "\n",
      "Class True Evaluation\n",
      "- Precision : 100.0 %\n",
      "- Recall : 89.362 %\n",
      "- F1 : 0.94382\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 94.898 %\n",
      "- Precision : 95.536 %\n",
      "- Recall : 94.681 %\n",
      "- F1 : 0.95107\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,False,,,True,,,\n",
      "Twitter16-TF_ResNet10_CNN_DistilBERT_Finetuned Validation, 94.898, 95.536, 94.681, 0.95107, 91.071, 100.0, 0.95327, 100.0, 89.362, 0.94382, \n",
      "\n",
      "---- Test Set ----\n",
      "Predictions : torch.Size([39])\n",
      "39 vs 39\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class False Evaluation\n",
      "- Precision : 100.0 %\n",
      "- Recall : 100.0 %\n",
      "- F1 : 1.0\n",
      "\n",
      "Class True Evaluation\n",
      "- Precision : 100.0 %\n",
      "- Recall : 100.0 %\n",
      "- F1 : 1.0\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 100.0 %\n",
      "- Precision : 100.0 %\n",
      "- Recall : 100.0 %\n",
      "- F1 : 1.0\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,False,,,True,,,\n",
      "Twitter16-TF_ResNet10_CNN_DistilBERT_Finetuned Test, 100.0, 100.0, 100.0, 1.0, 100.0, 100.0, 1.0, 100.0, 100.0, 1.0, \n"
     ]
    }
   ],
   "source": [
    "model_name = f\"{dataset_name}_ResNet10_CNN_{unique_name}\"\n",
    "start = time.time()\n",
    "print(f\"Multiclass Classification {model_name}\")\n",
    "model = ResNetClassifier(CNNResNet10(n_output=4), train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss, n_features=16, model_type=\"cnn\") #, device=\"cpu\")\n",
    "# model.train_eval(torch.Tensor(train_vectors.reshape(train_vectors.shape[0], 24, 32)),\n",
    "#                 torch.Tensor(train_labels),\n",
    "#                 torch.Tensor(val_vectors.reshape(val_vectors.shape[0], 24, 32)),\n",
    "#                 torch.Tensor(val_labels),\n",
    "#                 saves=model_name,\n",
    "#                 n_iter=1000,\n",
    "#                 batch_size=1024)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\n---- Validation Set ----\")\n",
    "preds = model.predict(val_vectors.reshape(val_vectors.shape[0], 1, 24, 32))\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\n---- Test Set ----\")\n",
    "preds = model.predict(test_vectors.reshape(test_vectors.shape[0], 1, 24, 32))\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c746093f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification Twitter16-TF_ResNet18_CNN_DistilBERT_Finetuned\n",
      "Using cuda\n",
      "Saving after new best accuracy : 52.041\n",
      "Saving after new best accuracy : 69.388\n",
      "Saving after new best accuracy : 78.571\n",
      "Saving after new best accuracy : 84.694\n",
      "Saving after new best accuracy : 88.776\n",
      "Saving after new best accuracy : 90.816\n",
      "Saving after new best accuracy : 92.857\n",
      "Saving after new best accuracy : 93.878\n",
      "Saving after new best accuracy : 94.898\n",
      "-- Epoch 50, Train Loss : 5.46293958905153e-05, Test Loss : 0.3109132647514343\n",
      "-- Epoch 100, Train Loss : 2.5478057068539783e-05, Test Loss : 0.35130932927131653\n",
      "-- Epoch 150, Train Loss : 1.5160566363192629e-05, Test Loss : 0.3602723777294159\n",
      "-- Epoch 200, Train Loss : 1.0228388418909162e-05, Test Loss : 0.36722755432128906\n",
      "-- Epoch 250, Train Loss : 7.45587567507755e-06, Test Loss : 0.37298065423965454\n",
      "-- Epoch 300, Train Loss : 5.720856279367581e-06, Test Loss : 0.37790733575820923\n",
      "-- Epoch 350, Train Loss : 4.549259301711572e-06, Test Loss : 0.38227763772010803\n",
      "-- Epoch 400, Train Loss : 3.7222305309114745e-06, Test Loss : 0.3861851692199707\n",
      "-- Epoch 450, Train Loss : 3.111486876150593e-06, Test Loss : 0.389688104391098\n",
      "-- Epoch 500, Train Loss : 2.6463799258635845e-06, Test Loss : 0.39287716150283813\n",
      "-- Epoch 550, Train Loss : 2.27663235818909e-06, Test Loss : 0.3958067297935486\n",
      "-- Epoch 600, Train Loss : 1.992709258047398e-06, Test Loss : 0.39851701259613037\n",
      "-- Epoch 650, Train Loss : 1.7534318885736866e-06, Test Loss : 0.4010411202907562\n",
      "-- Epoch 700, Train Loss : 1.5596689308949863e-06, Test Loss : 0.40339380502700806\n",
      "-- Epoch 750, Train Loss : 1.3940807548351586e-06, Test Loss : 0.40561169385910034\n",
      "-- Epoch 800, Train Loss : 1.2549345456136507e-06, Test Loss : 0.4077180027961731\n",
      "-- Epoch 850, Train Loss : 1.1391955467843218e-06, Test Loss : 0.40971603989601135\n",
      "-- Epoch 900, Train Loss : 1.0355940958106657e-06, Test Loss : 0.41161513328552246\n",
      "-- Epoch 950, Train Loss : 9.484643896939815e-07, Test Loss : 0.4134184420108795\n",
      "-- Epoch 1000, Train Loss : 8.704377592039236e-07, Test Loss : 0.41514450311660767\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 77.44 seconds\n",
      "\n",
      "---- Validation Set ----\n",
      "Predictions : torch.Size([98])\n",
      "98 vs 98\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class False Evaluation\n",
      "- Precision : 91.071 %\n",
      "- Recall : 100.0 %\n",
      "- F1 : 0.95327\n",
      "\n",
      "Class True Evaluation\n",
      "- Precision : 100.0 %\n",
      "- Recall : 89.362 %\n",
      "- F1 : 0.94382\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 94.898 %\n",
      "- Precision : 95.536 %\n",
      "- Recall : 94.681 %\n",
      "- F1 : 0.95107\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,False,,,True,,,\n",
      "Twitter16-TF_ResNet18_CNN_DistilBERT_Finetuned Validation, 94.898, 95.536, 94.681, 0.95107, 91.071, 100.0, 0.95327, 100.0, 89.362, 0.94382, \n",
      "\n",
      "---- Test Set ----\n",
      "Predictions : torch.Size([39])\n",
      "39 vs 39\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class False Evaluation\n",
      "- Precision : 95.238 %\n",
      "- Recall : 100.0 %\n",
      "- F1 : 0.97561\n",
      "\n",
      "Class True Evaluation\n",
      "- Precision : 100.0 %\n",
      "- Recall : 94.737 %\n",
      "- F1 : 0.97297\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 97.436 %\n",
      "- Precision : 97.619 %\n",
      "- Recall : 97.368 %\n",
      "- F1 : 0.97493\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,False,,,True,,,\n",
      "Twitter16-TF_ResNet18_CNN_DistilBERT_Finetuned Test, 97.436, 97.619, 97.368, 0.97493, 95.238, 100.0, 0.97561, 100.0, 94.737, 0.97297, \n"
     ]
    }
   ],
   "source": [
    "model_name = f\"{dataset_name}_ResNet18_CNN_{unique_name}\"\n",
    "start = time.time()\n",
    "print(f\"Multiclass Classification {model_name}\")\n",
    "model = ResNetClassifier(CNNResNet18(n_output=4), train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss, n_features=16, model_type=\"cnn\") #, device=\"cpu\")\n",
    "model.train_eval(torch.Tensor(train_vectors.reshape(train_vectors.shape[0], 24, 32)),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors.reshape(val_vectors.shape[0], 24, 32)),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=1024)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\n---- Validation Set ----\")\n",
    "preds = model.predict(val_vectors.reshape(val_vectors.shape[0], 1, 24, 32))\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\n---- Test Set ----\")\n",
    "preds = model.predict(test_vectors.reshape(test_vectors.shape[0], 1, 24, 32))\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28d251e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
