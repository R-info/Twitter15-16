{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Twitter15-RNR\"\n",
    "unique_name = \"BERT_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "terms_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter15-RNR_BERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>691809004356501505</td>\n",
       "      <td>america is a nation of second chances â€”@potus ...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693204708933160960</td>\n",
       "      <td>brandon marshall visits and offers advice, sup...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>551099691702956032</td>\n",
       "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "1  714598641827246081  an open letter to trump voters from his top st...   \n",
       "2  691809004356501505  america is a nation of second chances â€”@potus ...   \n",
       "3  693204708933160960  brandon marshall visits and offers advice, sup...   \n",
       "4  551099691702956032  rip elly may clampett: so sad to learn #beverl...   \n",
       "\n",
       "        label       tvt  cv_fold        tt        tvt2      tvt2_1  \\\n",
       "0  unverified  training        1  training    training  validation   \n",
       "1  unverified  training        1      test    training    testting   \n",
       "2   non-rumor  training        2  training  validation  validation   \n",
       "3   non-rumor  training        1  training    testting    testting   \n",
       "4        true  training        3  training  validation    training   \n",
       "\n",
       "       tvt2_2    tvt2_3  \n",
       "0    training  training  \n",
       "1    training  training  \n",
       "2  validation  testting  \n",
       "3    training  training  \n",
       "4  validation  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter15_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rumour', 'non-rumour']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = ['rumour', 'non-rumour']\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [0], [1], [1], [0], [1], [0], [0], [0], [0]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "#     lab = labels_str.index(d['label'])\n",
    "    if d['label'] in ['true', 'false', 'unverified']:\n",
    "        lab = 0\n",
    "    else:\n",
    "        lab = 1\n",
    "    labels.append([lab])\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"paul walker's\", 'us to', 'to watch', 'plan to', 'steps to', 'of the day', 'paul walker', 'want to', 'in ukraine', 'woman who']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_terms = []\n",
    "with open(\"../../data/processed/twitter15-rnr_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        vector_terms.append(t.strip())\n",
    "\n",
    "print(vector_terms[:10])\n",
    "len(vector_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2unigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(text)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def text2trigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    trigrams = nltk.trigrams(text)\n",
    "    trigrams = map(' '.join, trigrams)\n",
    "    trigrams = [bgr for bgr in trigrams]\n",
    "    \n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def bigrams_vectors_generation(texts):\n",
    "    bigram_vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(bigram_vector_base) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in bigram_vector_base:\n",
    "                idx = bigram_vector_base.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        bigram_vectors.append(init_vec)\n",
    "    \n",
    "    return bigram_vectors\n",
    "\n",
    "\n",
    "def custom_vectors_generation(texts, vector_terms):\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "        trigrams = text2trigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(vector_terms) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in vector_terms:\n",
    "                idx = vector_terms.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        for tgr in trigrams:\n",
    "            if tgr in vector_terms:\n",
    "                idx = vector_terms.index(tgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        vectors.append(init_vec)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 1519, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "terms_vectors = custom_vectors_generation(texts, vector_terms)\n",
    "\n",
    "vectors = np.concatenate([vectors, terms_vectors], axis=1)\n",
    "vectors = vectors.reshape(vectors.shape[0], vectors.shape[1], 1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1004, 1519, 1)\n",
      "(355, 1519, 1)\n",
      "(131, 1519, 1)\n",
      "(1004, 1)\n",
      "(355, 1)\n",
      "(131, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv1d(n_input, 512, 1, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 128, 1, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=1, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, n_output),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        binary: bool = False,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                \n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x, binary=binary)\n",
    "                if binary:\n",
    "                    preds = np.array([p[0] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([v[0] for v in test_y])\n",
    "                else:\n",
    "                    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y])\n",
    "                \n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=label_target,\n",
    "                    predictions=preds,\n",
    "                    binary=binary\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x, binary=False):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            \n",
    "            if binary:\n",
    "                return preds\n",
    "            else:\n",
    "                _, preds = torch.max(preds, dim = 1)\n",
    "                return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 85.915\n",
      "Saving after new best accuracy : 86.197\n",
      "-- Epoch 50, Train Loss : 0.0015478560235351324, Test Loss : 0.5961716771125793\n",
      "-- Epoch 100, Train Loss : 0.00032996144727803767, Test Loss : 0.7212249040603638\n",
      "-- Epoch 150, Train Loss : 0.00013515349564841017, Test Loss : 0.7969893217086792\n",
      "-- Epoch 200, Train Loss : 7.220270344987512e-05, Test Loss : 0.8516949415206909\n",
      "-- Epoch 250, Train Loss : 4.4559608795680106e-05, Test Loss : 0.8946669697761536\n",
      "-- Epoch 300, Train Loss : 3.0093865461822134e-05, Test Loss : 0.9301717877388\n",
      "-- Epoch 350, Train Loss : 2.161802513001021e-05, Test Loss : 0.9604756832122803\n",
      "-- Epoch 400, Train Loss : 1.6237550426012604e-05, Test Loss : 0.9870075583457947\n",
      "-- Epoch 450, Train Loss : 1.2609904842975084e-05, Test Loss : 1.0106228590011597\n",
      "-- Epoch 500, Train Loss : 7.263788575073704e-06, Test Loss : 1.0669769048690796\n",
      "-- Epoch 550, Train Loss : 5.056286681792699e-06, Test Loss : 1.1074779033660889\n",
      "-- Epoch 600, Train Loss : 3.826137685791764e-06, Test Loss : 1.1400537490844727\n",
      "-- Epoch 650, Train Loss : 3.023657995981921e-06, Test Loss : 1.168054223060608\n",
      "-- Epoch 700, Train Loss : 2.4614619178464636e-06, Test Loss : 1.192718744277954\n",
      "-- Epoch 750, Train Loss : 2.0308049215600477e-06, Test Loss : 1.2153429985046387\n",
      "-- Epoch 800, Train Loss : 1.7194695942635008e-06, Test Loss : 1.235620379447937\n",
      "-- Epoch 850, Train Loss : 1.4813093685006606e-06, Test Loss : 1.2547328472137451\n",
      "-- Epoch 900, Train Loss : 1.2810946259378397e-06, Test Loss : 1.2723009586334229\n",
      "-- Epoch 950, Train Loss : 1.090737725917279e-06, Test Loss : 1.2888996601104736\n",
      "-- Epoch 1000, Train Loss : 9.492909498476365e-07, Test Loss : 1.304500699043274\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 21.53 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([355, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 57\n",
      "False Positive : 19\n",
      "False Negative : 30\n",
      "True Negative : 249\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 75.0 %\n",
      "- Recall : 65.517 %\n",
      "- F1 : 0.69939\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 89.247 %\n",
      "- Recall : 92.91 %\n",
      "- F1 : 0.91042\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 86.197 %\n",
      "- Precision : 82.124 %\n",
      "- Recall : 79.214 %\n",
      "- F1 : 0.80643\n",
      "- Average Confidence : 24.4 %\n",
      "Model, Combined,,,,non-rumour,,,rumour,,,\n",
      "Twitter15-RNR_1DCNN_BERT_Finetuned_with_TopTermsVectors Validation, 86.197, 82.124, 79.214, 0.80643, 75.0, 65.517, 0.69939, 89.247, 92.91, 0.91042, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([131, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 22\n",
      "False Positive : 2\n",
      "False Negative : 9\n",
      "True Negative : 98\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 91.667 %\n",
      "- Recall : 70.968 %\n",
      "- F1 : 0.8\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 91.589 %\n",
      "- Recall : 98.0 %\n",
      "- F1 : 0.94686\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 91.603 %\n",
      "- Precision : 91.628 %\n",
      "- Recall : 84.484 %\n",
      "- F1 : 0.87911\n",
      "- Average Confidence : 25.79 %\n",
      "Model, Combined,,,,non-rumour,,,rumour,,,\n",
      "Twitter15-RNR_1DCNN_BERT_Finetuned_with_TopTermsVectors Test, 91.603, 91.628, 84.484, 0.87911, 91.667, 70.968, 0.8, 91.589, 98.0, 0.94686, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "binary = True\n",
    "\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_1DCNN_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=1, criterion=nn.BCELoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                binary=binary,\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in val_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in test_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b4d368",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
