{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# random.seed(33)\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Twitter15-RNR\"\n",
    "unique_name = \"DistilBERT_Finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter15-RNR_DistilBERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>691809004356501505</td>\n",
       "      <td>america is a nation of second chances â€”@potus ...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693204708933160960</td>\n",
       "      <td>brandon marshall visits and offers advice, sup...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>551099691702956032</td>\n",
       "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "1  714598641827246081  an open letter to trump voters from his top st...   \n",
       "2  691809004356501505  america is a nation of second chances â€”@potus ...   \n",
       "3  693204708933160960  brandon marshall visits and offers advice, sup...   \n",
       "4  551099691702956032  rip elly may clampett: so sad to learn #beverl...   \n",
       "\n",
       "        label       tvt  cv_fold        tt      tvt2  \n",
       "0  unverified  training        1  training  training  \n",
       "1  unverified  training        1      test  training  \n",
       "2   non-rumor  training        2  training  training  \n",
       "3   non-rumor  training        1  training  training  \n",
       "4        true  training        3  training  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter15_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5f76a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rumour', 'non-rumour']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = ['rumour', 'non-rumour']\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "maritime-bradley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 0, 1, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "#     lab = labels_str.index(d['label'])\n",
    "    if d['label'] in ['true', 'false', 'unverified']:\n",
    "        lab = 0\n",
    "    else:\n",
    "        lab = 1\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1017, 768)\n",
      "(327, 768)\n",
      "(146, 768)\n",
      "(1017,)\n",
      "(327,)\n",
      "(146,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1\n",
    "    ):\n",
    "        super(NNModel, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(128, n_output)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "    \n",
    "\n",
    "class NNClassifier:\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = NNModel(n_input, n_output)\n",
    "\n",
    "        self.criterion = criterion()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)\n",
    "\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        print(f\"loading model from {filepath}...\")\n",
    "#         print(checkpoint[key])\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def save_model(self, saves: str):\n",
    "        print(f\"Saving model...\")\n",
    "        state = {\n",
    "            'net': self.model.state_dict()\n",
    "        }\n",
    "        if not os.path.isdir('models'):\n",
    "            os.mkdir('models')\n",
    "        torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        current_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "#                 for i, output in enumerate(outputs.tolist()):\n",
    "#                     if targets[i,0].tolist() == round(output[0]):\n",
    "#                         correct += 1\n",
    "\n",
    "#             train_acc = round(100*correct/total, 4)\n",
    "#             train_accs.append(train_acc)\n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d69d25f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 87.462\n",
      "-- Epoch 50, Train Loss : 0.0004485207609832287, Test Loss : 1.060583233833313\n",
      "-- Epoch 100, Train Loss : 0.00012489951768657193, Test Loss : 1.2956243753433228\n",
      "-- Epoch 150, Train Loss : 0.00014776961688767187, Test Loss : 1.4380946159362793\n",
      "-- Epoch 200, Train Loss : 1.8523942344472744e-05, Test Loss : 1.5432994365692139\n",
      "-- Epoch 250, Train Loss : 9.937656386682647e-06, Test Loss : 1.613158106803894\n",
      "-- Epoch 300, Train Loss : 2.1501452010852518e-05, Test Loss : 1.6736139059066772\n",
      "-- Epoch 350, Train Loss : 2.8509336061688373e-05, Test Loss : 1.726280689239502\n",
      "-- Epoch 400, Train Loss : 2.381646481808275e-05, Test Loss : 1.761722445487976\n",
      "-- Epoch 450, Train Loss : 1.2497588045334851e-05, Test Loss : 1.793473243713379\n",
      "-- Epoch 500, Train Loss : 6.303470627244678e-06, Test Loss : 1.8155086040496826\n",
      "-- Epoch 550, Train Loss : 1.0864600540116953e-05, Test Loss : 1.8305765390396118\n",
      "-- Epoch 600, Train Loss : 7.330048106268805e-06, Test Loss : 1.8455692529678345\n",
      "-- Epoch 650, Train Loss : 1.0615084988785384e-05, Test Loss : 1.8513336181640625\n",
      "-- Epoch 700, Train Loss : 5.6854212289181305e-06, Test Loss : 1.8593589067459106\n",
      "-- Epoch 750, Train Loss : 5.107717754526675e-06, Test Loss : 1.874110460281372\n",
      "-- Epoch 800, Train Loss : 1.426777907909127e-05, Test Loss : 1.8839656114578247\n",
      "-- Epoch 850, Train Loss : 4.829455974686425e-06, Test Loss : 1.8833590745925903\n",
      "-- Epoch 900, Train Loss : 1.0562210832176788e-05, Test Loss : 1.8754743337631226\n",
      "-- Epoch 950, Train Loss : 3.5394206179262255e-06, Test Loss : 1.8715893030166626\n",
      "-- Epoch 1000, Train Loss : 7.885639661253663e-06, Test Loss : 1.8757076263427734\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 27.68 seconds\n",
      "loading model from ../../data/models/Twitter15-RNR_4LayerNet_L2Reg_DistilBERT_Finetuned.pth...\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([327])\n",
      "327 vs 327\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 88.931 %\n",
      "- Recall : 95.102 %\n",
      "- F1 : 0.91913\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 81.538 %\n",
      "- Recall : 64.634 %\n",
      "- F1 : 0.72109\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 87.462 %\n",
      "- Precision : 85.235 %\n",
      "- Recall : 79.868 %\n",
      "- F1 : 0.82464\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,rumour,,,non-rumour,,,\n",
      "Twitter15-RNR_4LayerNet_L2Reg_DistilBERT_Finetuned Validation, 87.462, 85.235, 79.868, 0.82464, 88.931, 95.102, 0.91913, 81.538, 64.634, 0.72109, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([146])\n",
      "146 vs 146\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 89.565 %\n",
      "- Recall : 91.964 %\n",
      "- F1 : 0.90749\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 70.968 %\n",
      "- Recall : 64.706 %\n",
      "- F1 : 0.67692\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 85.616 %\n",
      "- Precision : 80.266 %\n",
      "- Recall : 78.335 %\n",
      "- F1 : 0.79289\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,rumour,,,non-rumour,,,\n",
      "Twitter15-RNR_4LayerNet_L2Reg_DistilBERT_Finetuned Test, 85.616, 80.266, 78.335, 0.79289, 89.565, 91.964, 0.90749, 70.968, 64.706, 0.67692, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_L2Reg_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=2, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc76bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
