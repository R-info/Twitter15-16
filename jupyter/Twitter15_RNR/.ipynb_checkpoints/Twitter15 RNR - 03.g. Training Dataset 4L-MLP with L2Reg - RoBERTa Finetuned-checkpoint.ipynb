{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# random.seed(33)\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Twitter15-RNR\"\n",
    "unique_name = \"RoBERTa_Finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter15-RNR_RoBERTa_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>691809004356501505</td>\n",
       "      <td>america is a nation of second chances â€”@potus ...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693204708933160960</td>\n",
       "      <td>brandon marshall visits and offers advice, sup...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>551099691702956032</td>\n",
       "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "1  714598641827246081  an open letter to trump voters from his top st...   \n",
       "2  691809004356501505  america is a nation of second chances â€”@potus ...   \n",
       "3  693204708933160960  brandon marshall visits and offers advice, sup...   \n",
       "4  551099691702956032  rip elly may clampett: so sad to learn #beverl...   \n",
       "\n",
       "        label       tvt  cv_fold        tt      tvt2  \n",
       "0  unverified  training        1  training  training  \n",
       "1  unverified  training        1      test  training  \n",
       "2   non-rumor  training        2  training  training  \n",
       "3   non-rumor  training        1  training  training  \n",
       "4        true  training        3  training  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter15_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5f76a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rumour', 'non-rumour']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = ['rumour', 'non-rumour']\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "maritime-bradley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 0, 1, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "#     lab = labels_str.index(d['label'])\n",
    "    if d['label'] in ['true', 'false', 'unverified']:\n",
    "        lab = 0\n",
    "    else:\n",
    "        lab = 1\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1017, 768)\n",
      "(327, 768)\n",
      "(146, 768)\n",
      "(1017,)\n",
      "(327,)\n",
      "(146,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1\n",
    "    ):\n",
    "        super(NNModel, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(128, n_output)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "    \n",
    "\n",
    "class NNClassifier:\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = NNModel(n_input, n_output)\n",
    "\n",
    "        self.criterion = criterion()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)\n",
    "\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        print(f\"loading model from {filepath}...\")\n",
    "#         print(checkpoint[key])\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def save_model(self, saves: str):\n",
    "        print(f\"Saving model...\")\n",
    "        state = {\n",
    "            'net': self.model.state_dict()\n",
    "        }\n",
    "        if not os.path.isdir('models'):\n",
    "            os.mkdir('models')\n",
    "        torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        current_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "#                 for i, output in enumerate(outputs.tolist()):\n",
    "#                     if targets[i,0].tolist() == round(output[0]):\n",
    "#                         correct += 1\n",
    "\n",
    "#             train_acc = round(100*correct/total, 4)\n",
    "#             train_accs.append(train_acc)\n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d69d25f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 74.924\n",
      "Saving after new best accuracy : 90.826\n",
      "-- Epoch 50, Train Loss : 0.0003456733247730881, Test Loss : 0.8712621927261353\n",
      "-- Epoch 100, Train Loss : 0.00010418574856885243, Test Loss : 1.0374394655227661\n",
      "-- Epoch 150, Train Loss : 4.8373562094639055e-05, Test Loss : 1.129402756690979\n",
      "-- Epoch 200, Train Loss : 2.4972747269202955e-05, Test Loss : 1.192218542098999\n",
      "-- Epoch 250, Train Loss : 2.9507436011044774e-05, Test Loss : 1.2389675378799438\n",
      "-- Epoch 300, Train Loss : 2.7467386644275393e-05, Test Loss : 1.269438624382019\n",
      "-- Epoch 350, Train Loss : 2.3460258034901926e-05, Test Loss : 1.2934160232543945\n",
      "-- Epoch 400, Train Loss : 1.0461384135851404e-05, Test Loss : 1.3151226043701172\n",
      "-- Epoch 450, Train Loss : 9.652727840148145e-06, Test Loss : 1.3249776363372803\n",
      "-- Epoch 500, Train Loss : 1.0264038792229258e-05, Test Loss : 1.337162733078003\n",
      "-- Epoch 550, Train Loss : 6.6450056692701764e-06, Test Loss : 1.346274733543396\n",
      "-- Epoch 600, Train Loss : 5.977058890493936e-06, Test Loss : 1.3530066013336182\n",
      "-- Epoch 650, Train Loss : 5.5533539580210345e-06, Test Loss : 1.3557875156402588\n",
      "-- Epoch 700, Train Loss : 6.4252956235577585e-06, Test Loss : 1.3593770265579224\n",
      "-- Epoch 750, Train Loss : 7.401186167044216e-06, Test Loss : 1.3585028648376465\n",
      "-- Epoch 800, Train Loss : 7.614159812874277e-06, Test Loss : 1.359372615814209\n",
      "-- Epoch 850, Train Loss : 7.048447059787577e-06, Test Loss : 1.3635621070861816\n",
      "-- Epoch 900, Train Loss : 4.52383187621308e-06, Test Loss : 1.3656831979751587\n",
      "-- Epoch 950, Train Loss : 3.6913507983626914e-06, Test Loss : 1.3685294389724731\n",
      "-- Epoch 1000, Train Loss : 5.241933990873804e-06, Test Loss : 1.3642970323562622\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 27.09 seconds\n",
      "loading model from ../../data/models/Twitter15-RNR_4LayerNet_L2Reg_RoBERTa_Finetuned.pth...\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([327])\n",
      "327 vs 327\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 91.188 %\n",
      "- Recall : 97.143 %\n",
      "- F1 : 0.94071\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 89.394 %\n",
      "- Recall : 71.951 %\n",
      "- F1 : 0.7973\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 90.826 %\n",
      "- Precision : 90.291 %\n",
      "- Recall : 84.547 %\n",
      "- F1 : 0.87325\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,rumour,,,non-rumour,,,\n",
      "Twitter15-RNR_4LayerNet_L2Reg_RoBERTa_Finetuned Validation, 90.826, 90.291, 84.547, 0.87325, 91.188, 97.143, 0.94071, 89.394, 71.951, 0.7973, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([146])\n",
      "146 vs 146\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 93.913 %\n",
      "- Recall : 96.429 %\n",
      "- F1 : 0.95154\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 87.097 %\n",
      "- Recall : 79.412 %\n",
      "- F1 : 0.83077\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 92.466 %\n",
      "- Precision : 90.505 %\n",
      "- Recall : 87.92 %\n",
      "- F1 : 0.89194\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,rumour,,,non-rumour,,,\n",
      "Twitter15-RNR_4LayerNet_L2Reg_RoBERTa_Finetuned Test, 92.466, 90.505, 87.92, 0.89194, 93.913, 96.429, 0.95154, 87.097, 79.412, 0.83077, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_L2Reg_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=2, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc76bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
