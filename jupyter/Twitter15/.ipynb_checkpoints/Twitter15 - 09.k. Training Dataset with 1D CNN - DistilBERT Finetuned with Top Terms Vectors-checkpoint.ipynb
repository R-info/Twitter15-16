{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Twitter15-Multi\"\n",
    "unique_name = \"DistilBERT_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "bigram_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter15_DistilBERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>691809004356501505</td>\n",
       "      <td>america is a nation of second chances â€”@potus ...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693204708933160960</td>\n",
       "      <td>brandon marshall visits and offers advice, sup...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>551099691702956032</td>\n",
       "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "1  714598641827246081  an open letter to trump voters from his top st...   \n",
       "2  691809004356501505  america is a nation of second chances â€”@potus ...   \n",
       "3  693204708933160960  brandon marshall visits and offers advice, sup...   \n",
       "4  551099691702956032  rip elly may clampett: so sad to learn #beverl...   \n",
       "\n",
       "        label       tvt  cv_fold        tt        tvt2      tvt2_1  \\\n",
       "0  unverified  training        1  training    training  validation   \n",
       "1  unverified  training        1      test    training    testting   \n",
       "2   non-rumor  training        2  training  validation  validation   \n",
       "3   non-rumor  training        1  training    testting    testting   \n",
       "4        true  training        3  training  validation    training   \n",
       "\n",
       "       tvt2_2    tvt2_3  \n",
       "0    training  training  \n",
       "1    training  training  \n",
       "2  validation  testting  \n",
       "3    training  training  \n",
       "4  validation  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter15_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unverified', 'non-rumor', 'true', 'false']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = data['label'].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 2, 1, 0, 2, 0, 3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d['label'])\n",
    "    labs = [1 if idx == lab else 0 for idx in range(len(labels_str))]\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#ferguson pd', 'bathroom policy', 'institutional racism', 'want to', 'bag charge', 'ios 8', 'can be', 'clinton campaign', 'new transgender', 'protest at']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_terms = []\n",
    "with open(\"../../data/processed/twitter15-multi_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        vector_terms.append(t.strip())\n",
    "\n",
    "print(vector_terms[:10])\n",
    "len(vector_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2unigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(text)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def text2trigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    trigrams = nltk.trigrams(text)\n",
    "    trigrams = map(' '.join, trigrams)\n",
    "    trigrams = [bgr for bgr in trigrams]\n",
    "    \n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def custom_vectors_generation(texts, vector_terms):\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "        trigrams = text2trigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(vector_terms) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in vector_terms:\n",
    "                idx = vector_terms.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        for tgr in trigrams:\n",
    "            if tgr in vector_terms:\n",
    "                idx = vector_terms.index(tgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        vectors.append(init_vec)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 1519, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "terms_vectors = custom_vectors_generation(texts, vector_terms)\n",
    "\n",
    "vectors = np.concatenate([vectors, terms_vectors], axis=1)\n",
    "vectors = vectors.reshape(vectors.shape[0], vectors.shape[1], 1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1004, 1519, 1)\n",
      "(355, 1519, 1)\n",
      "(131, 1519, 1)\n",
      "(1004,)\n",
      "(355,)\n",
      "(131,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv1d(n_input, 512, 1, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 128, 1, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=1, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, n_output)\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 81.69\n",
      "Saving after new best accuracy : 82.535\n",
      "Saving after new best accuracy : 82.817\n",
      "Saving after new best accuracy : 83.099\n",
      "Saving after new best accuracy : 83.38\n",
      "Saving after new best accuracy : 83.662\n",
      "Saving after new best accuracy : 83.944\n",
      "Saving after new best accuracy : 84.225\n",
      "Saving after new best accuracy : 84.507\n",
      "Saving after new best accuracy : 84.789\n",
      "-- Epoch 50, Train Loss : 0.00516693270765245, Test Loss : 0.6195369362831116\n",
      "-- Epoch 100, Train Loss : 0.0012898353161290288, Test Loss : 0.7223543524742126\n",
      "-- Epoch 150, Train Loss : 0.0005737200262956321, Test Loss : 0.7855699062347412\n",
      "-- Epoch 200, Train Loss : 0.00032241617736872286, Test Loss : 0.8314607739448547\n",
      "-- Epoch 250, Train Loss : 0.00020637260604416952, Test Loss : 0.8678038716316223\n",
      "-- Epoch 300, Train Loss : 0.00014326842938316986, Test Loss : 0.897997260093689\n",
      "-- Epoch 350, Train Loss : 0.00010140078302356414, Test Loss : 0.9279141426086426\n",
      "-- Epoch 400, Train Loss : 6.430438224924728e-05, Test Loss : 0.9763563275337219\n",
      "-- Epoch 450, Train Loss : 4.871384226134978e-05, Test Loss : 1.0073314905166626\n",
      "-- Epoch 500, Train Loss : 3.848966662189923e-05, Test Loss : 1.0323700904846191\n",
      "-- Epoch 550, Train Loss : 3.122731595794903e-05, Test Loss : 1.0538458824157715\n",
      "-- Epoch 600, Train Loss : 2.585599031590391e-05, Test Loss : 1.0731258392333984\n",
      "-- Epoch 650, Train Loss : 2.1749762709077913e-05, Test Loss : 1.0904299020767212\n",
      "-- Epoch 700, Train Loss : 1.853059438872151e-05, Test Loss : 1.1064374446868896\n",
      "-- Epoch 750, Train Loss : 1.595384901520447e-05, Test Loss : 1.1212917566299438\n",
      "-- Epoch 800, Train Loss : 1.3867270808987087e-05, Test Loss : 1.1351985931396484\n",
      "-- Epoch 850, Train Loss : 1.2136821624153526e-05, Test Loss : 1.1483274698257446\n",
      "-- Epoch 900, Train Loss : 1.0695408036554e-05, Test Loss : 1.160731554031372\n",
      "-- Epoch 950, Train Loss : 9.486224826105172e-06, Test Loss : 1.172553300857544\n",
      "-- Epoch 1000, Train Loss : 8.444862487522187e-06, Test Loss : 1.1838740110397339\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 42.81 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([355])\n",
      "355 vs 355\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 89.231 %\n",
      "- Recall : 74.359 %\n",
      "- F1 : 0.81119\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 79.545 %\n",
      "- Recall : 80.46 %\n",
      "- F1 : 0.8\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 89.362 %\n",
      "- Recall : 90.323 %\n",
      "- F1 : 0.8984\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 82.407 %\n",
      "- Recall : 91.753 %\n",
      "- F1 : 0.86829\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 84.789 %\n",
      "- Precision : 85.136 %\n",
      "- Recall : 84.223 %\n",
      "- F1 : 0.84677\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Twitter15-Multi_4LayerNet_DistilBERT_Finetuned_with_TopTermsVectors Validation, 84.789, 85.136, 84.223, 0.84677, 89.231, 74.359, 0.81119, 79.545, 80.46, 0.8, 89.362, 90.323, 0.8984, 82.407, 91.753, 0.86829, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([131])\n",
      "131 vs 131\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 81.081 %\n",
      "- Recall : 83.333 %\n",
      "- F1 : 0.82192\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 76.667 %\n",
      "- Recall : 74.194 %\n",
      "- F1 : 0.7541\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 85.294 %\n",
      "- Recall : 85.294 %\n",
      "- F1 : 0.85294\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 80.0 %\n",
      "- Recall : 80.0 %\n",
      "- F1 : 0.8\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 80.916 %\n",
      "- Precision : 80.76 %\n",
      "- Recall : 80.705 %\n",
      "- F1 : 0.80732\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Twitter15-Multi_4LayerNet_DistilBERT_Finetuned_with_TopTermsVectors Test, 80.916, 80.76, 80.705, 0.80732, 81.081, 83.333, 0.82192, 76.667, 74.194, 0.7541, 85.294, 85.294, 0.85294, 80.0, 80.0, 0.8, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b4d368",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
