{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# random.seed(33)\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Twitter15-RNR\"\n",
    "unique_name = \"BERT_Finetuned_with_BigramVectors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter15-RNR_BERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>691809004356501505</td>\n",
       "      <td>america is a nation of second chances â€”@potus ...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693204708933160960</td>\n",
       "      <td>brandon marshall visits and offers advice, sup...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>551099691702956032</td>\n",
       "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "1  714598641827246081  an open letter to trump voters from his top st...   \n",
       "2  691809004356501505  america is a nation of second chances â€”@potus ...   \n",
       "3  693204708933160960  brandon marshall visits and offers advice, sup...   \n",
       "4  551099691702956032  rip elly may clampett: so sad to learn #beverl...   \n",
       "\n",
       "        label       tvt  cv_fold        tt        tvt2  \n",
       "0  unverified  training        1  training  validation  \n",
       "1  unverified  training        1      test    training  \n",
       "2   non-rumor  training        2  training  validation  \n",
       "3   non-rumor  training        1  training    testting  \n",
       "4        true  training        3  training    testting  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter15_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5f76a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rumour', 'non-rumour']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = ['rumour', 'non-rumour']\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "maritime-bradley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 0, 1, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "#     lab = labels_str.index(d['label'])\n",
    "    if d['label'] in ['true', 'false', 'unverified']:\n",
    "        lab = 0\n",
    "    else:\n",
    "        lab = 1\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70210870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>unverified</th>\n",
       "      <th>non-rumor</th>\n",
       "      <th>true</th>\n",
       "      <th>false</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca kkk</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kkk grand</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grand wizard</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wizard endorses</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>endorses @hillaryclinton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      token  unverified  non-rumor  true  false\n",
       "0                    ca kkk           1          0     0      0\n",
       "1                 kkk grand           1          0     0      0\n",
       "2              grand wizard           1          0     0      0\n",
       "3           wizard endorses           1          0     0      0\n",
       "4  endorses @hillaryclinton           1          0     0      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_data = pd.read_excel('../../data/processed/twitter15_ngram_distribution.xlsx', sheet_name='bigram')\n",
    "bigram_data.columns = [\"token\", \"unverified\", \"non-rumor\", \"true\", \"false\"]\n",
    "bigram_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f0ada7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bigram_vector_base = bigram_data['token'].tolist()\n",
    "bigram_vector_base = []\n",
    "with open(\"../../data/processed/twitter15_best_bigrams.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        bigram_vector_base.append(t)\n",
    "len(bigram_vector_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56789dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    bigrams = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    bigrams = [t for t in bigrams if t not in string.punctuation]\n",
    "    bigrams = [t for t in bigrams if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(bigrams)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def bigrams_vectors_generation(texts):\n",
    "    bigram_vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(bigram_vector_base) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in bigram_vector_base:\n",
    "                idx = bigram_vector_base.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        bigram_vectors.append(init_vec)\n",
    "    \n",
    "    return bigram_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c7f6c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 6869)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "bigram_vectors = bigrams_vectors_generation(texts)\n",
    "\n",
    "vectors = np.concatenate([vectors, bigram_vectors], axis=1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 6869)\n",
      "(334, 6869)\n",
      "(156, 6869)\n",
      "(1000,)\n",
      "(334,)\n",
      "(156,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1\n",
    "    ):\n",
    "        super(NNModel, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(128, n_output)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "    \n",
    "\n",
    "class NNClassifier:\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = NNModel(n_input, n_output)\n",
    "\n",
    "        self.criterion = criterion()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)\n",
    "\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        print(f\"loading model from {filepath}...\")\n",
    "#         print(checkpoint[key])\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def save_model(self, saves: str):\n",
    "        print(f\"Saving model...\")\n",
    "        state = {\n",
    "            'net': self.model.state_dict()\n",
    "        }\n",
    "        if not os.path.isdir('models'):\n",
    "            os.mkdir('models')\n",
    "        torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        current_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "#                 for i, output in enumerate(outputs.tolist()):\n",
    "#                     if targets[i,0].tolist() == round(output[0]):\n",
    "#                         correct += 1\n",
    "\n",
    "#             train_acc = round(100*correct/total, 4)\n",
    "#             train_accs.append(train_acc)\n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d69d25f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 86.826\n",
      "Saving after new best accuracy : 87.725\n",
      "Saving after new best accuracy : 88.024\n",
      "Saving after new best accuracy : 88.323\n",
      "-- Epoch 50, Train Loss : 0.0005664430354954675, Test Loss : 0.8771072030067444\n",
      "-- Epoch 100, Train Loss : 0.00010714696327340789, Test Loss : 1.0678622722625732\n",
      "-- Epoch 150, Train Loss : 5.52312376385089e-05, Test Loss : 1.1875885725021362\n",
      "-- Epoch 200, Train Loss : 2.2602200715482468e-05, Test Loss : 1.2630962133407593\n",
      "-- Epoch 250, Train Loss : 4.297088707971852e-05, Test Loss : 1.3232192993164062\n",
      "-- Epoch 300, Train Loss : 1.592983107912005e-05, Test Loss : 1.3645707368850708\n",
      "-- Epoch 350, Train Loss : 1.415015049133217e-05, Test Loss : 1.3940261602401733\n",
      "-- Epoch 400, Train Loss : 1.5270576113834977e-05, Test Loss : 1.4216265678405762\n",
      "-- Epoch 450, Train Loss : 9.635997002988006e-06, Test Loss : 1.443003535270691\n",
      "-- Epoch 500, Train Loss : 5.107401761961228e-06, Test Loss : 1.4576785564422607\n",
      "-- Epoch 550, Train Loss : 6.767501872673165e-06, Test Loss : 1.464882493019104\n",
      "-- Epoch 600, Train Loss : 5.2212626542313956e-06, Test Loss : 1.4698147773742676\n",
      "-- Epoch 650, Train Loss : 6.1191954046080355e-06, Test Loss : 1.4842690229415894\n",
      "-- Epoch 700, Train Loss : 1.184065024517622e-05, Test Loss : 1.4864423274993896\n",
      "-- Epoch 750, Train Loss : 6.587093594134785e-06, Test Loss : 1.4917895793914795\n",
      "-- Epoch 800, Train Loss : 4.173911293037236e-06, Test Loss : 1.496761679649353\n",
      "-- Epoch 850, Train Loss : 9.693229230833822e-06, Test Loss : 1.5038402080535889\n",
      "-- Epoch 900, Train Loss : 6.127949745859951e-06, Test Loss : 1.510805606842041\n",
      "-- Epoch 950, Train Loss : 5.12246538164618e-06, Test Loss : 1.5010327100753784\n",
      "-- Epoch 1000, Train Loss : 2.926819320236973e-06, Test Loss : 1.503021001815796\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 34.04 seconds\n",
      "loading model from ../../data/models/Twitter15-RNR_4LayerNet_L2Reg_BERT_Finetuned_with_BigramVectors.pth...\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([334])\n",
      "334 vs 334\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 90.347 %\n",
      "- Recall : 94.355 %\n",
      "- F1 : 0.92308\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 81.333 %\n",
      "- Recall : 70.93 %\n",
      "- F1 : 0.75776\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 88.323 %\n",
      "- Precision : 85.84 %\n",
      "- Recall : 82.643 %\n",
      "- F1 : 0.84211\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,rumour,,,non-rumour,,,\n",
      "Twitter15-RNR_4LayerNet_L2Reg_BERT_Finetuned_with_BigramVectors Validation, 88.323, 85.84, 82.643, 0.84211, 90.347, 94.355, 0.92308, 81.333, 70.93, 0.75776, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([156])\n",
      "156 vs 156\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 87.218 %\n",
      "- Recall : 98.305 %\n",
      "- F1 : 0.9243\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 91.304 %\n",
      "- Recall : 55.263 %\n",
      "- F1 : 0.68852\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 87.821 %\n",
      "- Precision : 89.261 %\n",
      "- Recall : 76.784 %\n",
      "- F1 : 0.82554\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,rumour,,,non-rumour,,,\n",
      "Twitter15-RNR_4LayerNet_L2Reg_BERT_Finetuned_with_BigramVectors Test, 87.821, 89.261, 76.784, 0.82554, 87.218, 98.305, 0.9243, 91.304, 55.263, 0.68852, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_L2Reg_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=2, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc76bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
