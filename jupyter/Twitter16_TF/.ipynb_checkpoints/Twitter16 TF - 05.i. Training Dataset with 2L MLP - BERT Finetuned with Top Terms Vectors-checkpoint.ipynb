{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Twitter16-TF\"\n",
    "unique_name = \"BERT_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "terms_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(412, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter16-TF_BERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>656955120626880512</td>\n",
       "      <td>correct predictions in back to the future ii U...</td>\n",
       "      <td>False</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>615689290706595840</td>\n",
       "      <td>.@whitehouse in rainbow colors for #scotusmarr...</td>\n",
       "      <td>True</td>\n",
       "      <td>testting</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>613404935003217920</td>\n",
       "      <td>cops bought the alleged church shooter burger ...</td>\n",
       "      <td>False</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>614467824313106432</td>\n",
       "      <td>god put a rainbow over the white house ðŸŒˆ URL\\r</td>\n",
       "      <td>True</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>622891631293935616</td>\n",
       "      <td>#wakeupamericaðŸ‡ºðŸ‡¸ who needs a #gun registry whe...</td>\n",
       "      <td>False</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  656955120626880512  correct predictions in back to the future ii U...   \n",
       "1  615689290706595840  .@whitehouse in rainbow colors for #scotusmarr...   \n",
       "2  613404935003217920  cops bought the alleged church shooter burger ...   \n",
       "3  614467824313106432     god put a rainbow over the white house ðŸŒˆ URL\\r   \n",
       "4  622891631293935616  #wakeupamericaðŸ‡ºðŸ‡¸ who needs a #gun registry whe...   \n",
       "\n",
       "   label        tvt2    tvt2_1    tvt2_2    tvt2_3  \n",
       "0  False    training  training  training  training  \n",
       "1   True    testting  testting  training  testting  \n",
       "2  False  validation  training  training  training  \n",
       "3   True  validation  training  training  training  \n",
       "4  False    training  testting  training  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter16-tf_dataset.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_type = \"label\"\n",
    "labels_str = data[label_type].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [1], [0], [1], [0], [1], [1], [0], [0], [1]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d[label_type])\n",
    "    labels.append([lab])\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mass shootings', 'charlie hebdo', 'lindt cafe', 'he was', '#charliehebdo attackers', 'will be', 'a rainbow', 'parliament hill', 'is not', 'red cross']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "474"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_terms = []\n",
    "with open(\"../../data/processed/twitter16-tf_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        vector_terms.append(t.strip())\n",
    "\n",
    "print(vector_terms[:10])\n",
    "len(vector_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2unigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(text)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def text2trigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    trigrams = nltk.trigrams(text)\n",
    "    trigrams = map(' '.join, trigrams)\n",
    "    trigrams = [bgr for bgr in trigrams]\n",
    "    \n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def bigrams_vectors_generation(texts):\n",
    "    bigram_vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(bigram_vector_base) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in bigram_vector_base:\n",
    "                idx = bigram_vector_base.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        bigram_vectors.append(init_vec)\n",
    "    \n",
    "    return bigram_vectors\n",
    "\n",
    "\n",
    "def custom_vectors_generation(texts, vector_terms):\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "        trigrams = text2trigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(vector_terms) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in vector_terms:\n",
    "                idx = vector_terms.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        for tgr in trigrams:\n",
    "            if tgr in vector_terms:\n",
    "                idx = vector_terms.index(tgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        vectors.append(init_vec)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(412, 1243)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "terms_vectors = custom_vectors_generation(texts, vector_terms)\n",
    "\n",
    "vectors = np.concatenate([vectors, terms_vectors], axis=1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(278, 1243)\n",
      "(95, 1243)\n",
      "(39, 1243)\n",
      "(278, 1)\n",
      "(95, 1)\n",
      "(39, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, n_output),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        binary: bool = False,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x, binary=binary)\n",
    "                if binary:\n",
    "                    preds = np.array([p[0] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([v[0] for v in test_y])\n",
    "                else:\n",
    "                    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y])\n",
    "                \n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=label_target,\n",
    "                    predictions=preds,\n",
    "                    binary=binary\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x, binary=False):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            \n",
    "            if binary:\n",
    "                return preds\n",
    "            else:\n",
    "                _, preds = torch.max(preds, dim = 1)\n",
    "                return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 89.474\n",
      "Saving after new best accuracy : 91.579\n",
      "-- Epoch 50, Train Loss : 0.0035703550092875957, Test Loss : 0.3928177058696747\n",
      "-- Epoch 100, Train Loss : 0.0007956611225381494, Test Loss : 0.48739054799079895\n",
      "-- Epoch 150, Train Loss : 0.0003250358859077096, Test Loss : 0.5461475253105164\n",
      "-- Epoch 200, Train Loss : 0.00017715276044327766, Test Loss : 0.5866897106170654\n",
      "-- Epoch 250, Train Loss : 0.00011115033703390509, Test Loss : 0.6180028915405273\n",
      "-- Epoch 300, Train Loss : 7.598901720484719e-05, Test Loss : 0.6436601281166077\n",
      "-- Epoch 350, Train Loss : 5.508142930921167e-05, Test Loss : 0.6654992699623108\n",
      "-- Epoch 400, Train Loss : 4.1662522562546656e-05, Test Loss : 0.6845094561576843\n",
      "-- Epoch 450, Train Loss : 3.079979069298133e-05, Test Loss : 0.7060152292251587\n",
      "-- Epoch 500, Train Loss : 1.8572374756331556e-05, Test Loss : 0.7476319670677185\n",
      "-- Epoch 550, Train Loss : 1.3433317690214608e-05, Test Loss : 0.7792643904685974\n",
      "-- Epoch 600, Train Loss : 1.0582475624687504e-05, Test Loss : 0.803573727607727\n",
      "-- Epoch 650, Train Loss : 8.696279110154137e-06, Test Loss : 0.8233102560043335\n",
      "-- Epoch 700, Train Loss : 7.325751084863441e-06, Test Loss : 0.8400277495384216\n",
      "-- Epoch 750, Train Loss : 6.280703473748872e-06, Test Loss : 0.8545477986335754\n",
      "-- Epoch 800, Train Loss : 5.451572178571951e-06, Test Loss : 0.8674407601356506\n",
      "-- Epoch 850, Train Loss : 4.781964435096597e-06, Test Loss : 0.8791847825050354\n",
      "-- Epoch 900, Train Loss : 4.2289975681342185e-06, Test Loss : 0.8897417187690735\n",
      "-- Epoch 950, Train Loss : 3.770158400584478e-06, Test Loss : 0.8999271392822266\n",
      "-- Epoch 1000, Train Loss : 3.3814321795944124e-06, Test Loss : 0.9089969396591187\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAFXCAYAAAC1NambAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAsiElEQVR4nO3de3xU9Z3/8dcnCUm4yd1WgiS6an8FxFBZqVbrJVhbenG3W7cqWFxtWcJWvHSxWnpxXenW7q73CqKLWk291FZlC9ZV1BXrNVi04mVFDBKsiigpcod8fn+cMzCGJDOTzJnJmXk/H488mHPJme9Mhrzz/X7O+R5zd0RERNJVku8GiIhIvCg4REQkIwoOERHJiIJDREQyouAQEZGMKDhERCQjCg6RbjKzY8zstRw+37+Z2Xm5er52nv8SM7u9k+3PmtnoXLZJckvBId1iZk1mNjHf7cglM3MzOyix7O5L3f1TOXruYcC3gBty8Xxd9B/ApfluhERHwSHSATMry3cb2nEmsNjdt+S7IZ1YCBxvZp/Md0MkGgoOiYSZVZjZVWb2dvh1lZlVhNuGmtnvzGyDmX1gZkvNrCTc9n0zW2tmG83sNTOr6+D4A8zsl2a2zsxWm9kPzawkfN4NZjYmad9hZrbFzPYNl79iZsvD/Z40s7FJ+zaFbXgR2NQ2PMzs8fDhC2b2kZl908yOM7PmNseYZWYvmtkmM/svM/uEmT0Qvq6HzWxQ0v6fDduxwcxeMLPjOnlrvwT8b5s2pXo9F5vZy2b2oZndbGaVSdu/Y2Yrw5/DQjMbnrRttJk9FG5718x+kPS05eH7v9HMVpjZ+MQGd98KLANO6uR1SJy5u7701eUvoAmY2M76S4GngX2BYcCTwL+G2/4NmAf0Cr+OAQz4FLAGGB7uVwP8VQfP+0vgfqB/uN//AWeH2xYAc5L2/Sfg9+HjccB7wASgFJgavoaKpNezHNgf6N3BcztwUNLycUBzm/fkaeATQFX4fM+Hz10JPAL8JNy3ClgPTCL4Q+7EcHlYB8+9DvjrpOV0Xs9L4esZDPwBuCzcdgLwPvAZoAK4Fng83NYf+DPwvbDN/YEJ4bZLgK1hm0vDn+fTbdp5DXBFvj+f+ormSz0Oicpk4FJ3f8/d1wH/ApwRbtsB7AdUu/sOD2oEDuwi+AU2ysx6uXuTu7/R9sBmVgqcClzs7hvdvQn4z6Tj/yrcnnB6uA5gGnCDuz/j7rvc/VZgG/DZpP2vcfc13r3hoGvd/V13XwssBZ5x9z968Nf4vQS/8AGmEAw9LXb3Vnd/CGgk+KXcnoHAxqTldF7PdeHr+QCYA5wWrp8MLHD35919G3AxcKSZ1QBfAd5x9/90963h+/xM0jGfCNu8C7gNOKxNOzeGbZUCpOCQqAwHVictrw7XAfw7sBL4HzNbZWYXAbj7SuA8gr9o3zOzO5OHTpIMJeiptD1+Vfj4UaCPmU0IfwnWEvyyBqgGvhcO62wwsw0Ef40nP8+aTF9sO95NerylneV+Se05pU17jiYI1vZ8SPDXf0Kmryf55/Cxn5G7f0TQ26kKj7FXaCd5J+nxZqCyzbBef2BDJ98vMabgkKi8TfBLLWFkuI7wr9fvufuBwNeACxK1DHf/lbsfHX6vA5e3c+z3CXotbY+/NjzGLuBugr+sTwN+5+6Jv9LXEAxjDUz66uPudyQdK5dTRq8BbmvTnr7u/rMO9n8ROKTN96d6PfsnPd79c6DNz8jM+gJDCN7HNcCB3XhdnwZe6Mb3Sw+m4JBs6GVmlUlfZcAdwA/DwvRQ4MfA7bC7mHuQmRnQQjBE1WpmnzKzE8Ii+laCv8xb2z5ZUjDMMbP+ZlYNXJA4fuhXwDcJhmN+lbT+RmB62BsxM+trZl82s+S/4lN5l+79Uk12O/BVMzvJzErD9+84MxvRwf6LgWOTltN5Pf9kZiPMbDAwG7grXH8H8A9mVhu+5z8lGFJrAn4H7Gdm54UnHPQ3swnpvKCw+H448FCa74HEjIJDsmExwS/5xNclwGUEY/UvAn8iKA5fFu5/MPAw8BHwFHC9uz9KUN/4GUGP4h2CwvrFHTznOcAmYBXwBEE4LEhsDMfjNxEMxzyQtL4R+A5wHcGwz0qCU1wzcQlwazg09PcZfu/HuPsa4GTgBwSF7zXALDr+v/lLYJKZ9Q6/P53X8yvgfwjeqzcIfw7u/jDwI+A3BIXwvyKsDYU9tBOBrxL8LF4Hjk/zZX0VeMzd3065p8SSBTVJEYkLM/sp8J67X5XGvk3At8OQyAkze4bgDLeXcvWckls98QInEemEu/8g9V754+5pDWlJfGmoSkREMqKhKhERyYh6HCIikhEFh4iIZCR2xfGhQ4d6TU1NvpshIpI9b70F69ZF+hRNwPvulo1jxS44ampqaGxszHczREQy19AAZ50F27fn/KnHp94lbbELDhGRWMhjSERNNQ4Rke6aMQPMPv41ZUpBhgYoOEREMtNeSMydm+9W7a2uDtx3fy0Lbq6VFRqqEhHpyIwZPTMUktXVwcM5m1EGUHCIiAR6ek0iDwHREQWHiBSniRNhyZJ8t2JvlZVw000weXK+W9Ih1ThEpPC1V5foCaFRX/+xOgTusGVLjw4NUI9DRApRT+xN1NfD9dfnuxVZoR6HiMRbQwNUVPSc3kRlJdx++949iQIJDVBwiEjctB12yuf1Eu2FRAyGmrpLQ1Ui0rP1lFNiY1C0zhX1OESkZ2nbo8hXaLQtXBdBTyJd6nGISH71hB5FD7pGIg7U4xCR3Mp3j6K9uoRCIyPqcYhI9PJ5eqx6E1mnHoeIZF/bXkUuQ6NtbUKhkXXqcYhI9+Vrnied6ZQX6nGISNck9ypydS1F2/qEznTKC/U4RCR9ua5VqEfRIyk4RKRzuQwLBUUsaKhKRD6u7dxPUYaGhp5iST0OEcltcVunx8aegkOkmOViGErDTwVHQ1UixWbixOiHoZKvpdDwU8FRcIgUg+RTZ6MIi7a1igK694TsTUNVIoUq6rqFahVFS8EhUmiirFsoLAQNVYkUhuRTaLMdGsn1CoWGEHFwmNkXzew1M1tpZhe1s32kmT1qZn80sxfNbFKU7REpOInaRban/EgOC9UrpI3IhqrMrBT4BXAi0Aw8Z2YL3f3lpN1+CNzt7nPNbBSwGKiJqk0iBSOK4SgNQ0maouxxHAGsdPdV7r4duBM4uc0+DuwTPh4AvB1he0TiLYrhqLo6DUNJxqIMjipgTdJyc7gu2SXAFDNrJuhtnNPegcxsmpk1mlnjunXromirSM+V7eGo5FNnFRbSBfkujp8G3OLuI4BJwG1mtleb3H2+u4939/HDhg3LeSNF8iIRGNm6tWqibqEL8qSbojwddy2wf9LyiHBdsrOBLwK4+1NmVgkMBd6LsF0iPduMGdkLC9UtJAJR9jieAw42swPMrBw4FVjYZp+3gDoAM/s0UAloLEqKU2IqkGyERqJ3odCQCEQWHO6+E/gu8CDwCsHZUyvM7FIz+1q42/eA75jZC8AdwJnu7lG1SaRHSgxJdbfgnVy70Cm0EqFIrxx398UERe/kdT9Oevwy8Lko2yDSY2VrSErDUZJj+S6OixSfbBW9NRwleaK5qkRypaEBzjgj+GXfVWVlcMstOitK8krBIZILo0fDyy+n3q8jCgzpQTRUJRKlxLBUV0MjUfDesUOhIT2GehwiUehu4XvUKFixInvtEcki9ThEsqmhAUpKuh4aZWVBD0OhIT2Yehwi2dKdGWtVw5AYUY9DpLsSvYyuhEZpqWoYEjvqcYh0R3d6GfX1usJbYknBIdJVVVXwdhduIaPCt8SchqpEMtXQEJxim2loJE6tVWhIzKnHIZKJrgxNlZbCrbeqhiEFQ8Ehkq6uDE1pAkIpQBqqEkmlK0NTibOlFBpSgNTjEOlMV4am1MuQAqfgEOlIpkNTZnDbbaplSMFTcIi0Z9Ag2LAh/f2HD4e1ayNrjkhPohqHSLJEPSOT0KirU2hIUVGPQyQh03qGhqakSCk4RCDzGy1paEqKmIaqRKqqMgsNDU1JkVNwSPHK9PoMM12bIYKGqqRYZVrPGDgQPvwwsuaIxIl6HFJcJk4Meg6ZhMbw4QoNkSQKDilsDQ1QURGERaaBAapniLRDwSGFJzkspkyB7du7dpz6etUzRNoRu+BYtgxqaoLfDSK7zZixp1fRnbCAPUVw3Z1PpF2xLI6vXg3TpgWPde1VEZsxA+bOze4xdX2GSEqx63EkbN4Ms2fnuxWSc8nDUNkODdUzRNIS2+AAeOutfLdAciJbNYuOJG7pqnqGSFpiOVSVMHJkvlsgkWlogLPOyn5IJNN9M0S6JLY9jj59YM6cfLdCsi5xnUUUPQsIzpRyD74UGiJdEsvgqK6G+fNVGC8YyWdEZXqdRTqSw0JnSol0W+yGqnr1gqamfLdCui3KoajKSrjpJv1lIRKR2AWHe75bIN3SlXt4p0NhIZIzsRyqkpiJcigqMQy1ZYtCQyRH1OOQ6ETVu6ivV61CJI9i1+NQcPRwyddcZDM0VOAW6THU45DsiGL6D11nIdIjxS44pIfJ9nCUitwiPZ6GqiRzUQxHqcgtEhux7HG0tkJJ7CKvAGR7OEpDUSKxFMtfv7t25bsFRSTbs9EmJhTUlB8isRXLHseuXcEV5BKhhgaYOjV7Ka3ehUjBiGWPY+fOfLeggDU0QFlZMMlgNkIjUbtQaIgUjFj2OBQcEchmD0NnRokUtNj1OA5nGf0PrdFNx7Mlmz2MujqdGSVSBGIXHAClzeFNxxUeXZfNwNBwlEhRMY/ZhRHjzbwxsVBdrTnWM5WtISkVu0VixcyWufv4bBwrljWO3XTT8cyMHg0vv9y9Y2iCQZGiF8uhqt100/H0JG7H2p3QSAxHKTREil58g0M3HU8tcR+M7kwLosAQkTZiGRxrSqp5YqpuOt6hhoZgTpbuXOmtwBCRDkQaHGb2RTN7zcxWmtlFHezz92b2spmtMLNfpTrmTsoY2drESbdO1klVbSWfKdXVkx4UGCKSQmRnVZlZKfB/wIlAM/AccJq7v5y0z8HA3cAJ7v6hme3r7u91dtxxVubLCa4A1ElVSbpb+FbRW6SgZfOsqih7HEcAK919lbtvB+4ETm6zz3eAX7j7hwCpQgPAaN39WCdVEfQyulP4Vg9DRDIU5em4VcCapOVmYEKbfQ4BMLM/AKXAJe7++84OauzpIRX9SVXd6WXoOgwR6aJ8F8fLgIOB44DTgBvNbGDbncxsmpk1mlmjASXsKu6TqhJnS3UlNEaN0lXeItItUQbHWmD/pOUR4bpkzcBCd9/h7m8S1EQObnsgd5/v7uMT43Mj9t3B/GI9qaqqqmtnS5WWBvfBWLEi+20SkaISZXA8BxxsZgeYWTlwKrCwzT73EfQ2MLOhBENXq1Id+NabdhRfaCR6GW+/nfn31tcHUwoX3ZsmIlGIrMbh7jvN7LvAgwT1iwXuvsLMLgUa3X1huO0LZvYysAuY5e7rUx572/aomt0zVVV1PTBU9BaRLIt0rip3XwwsbrPux0mPHbgg/Epb69YiCY6u3uN7+HBY23ZUUEQkO/JdHO+SogiOrtYy6usVGiISqVgGx9EXHlW49+JIXJeR6dBU4mwpDU2JSMRiGRy9P3y7MG/kNHFiMF1IJsx0tpSI5JRu5NRTdKUAPmqUAkNE0hKXKUeiVyhzjgwalFloqJchInkU7+CI+5wjiXrGhg3pf8+oUdDaqmsyRCRv4hsccZ9zZMaMzOoZ6mWISA8Ry3uOb+6/L33mXhHfv7onTszsrny6LkNEepBY9jgePf2m+IbG6NGZhUZdnUJDRHqUWAYH22N6AWBVVfoz2iaGpjSLrYj0MLEcqoplcAwalH4RfOBA+PDDKFsjItJlsexx3NWwg5qaGF3/l0loDB+u0BCRHi2WwVHOdlavjsnF45mExqhRqmeISI8X2+AA2LwZZs/Oc2M6k0lo1NXpVFsRiYVYBwf04IvHMwmN+noVwUUkNmIZHFdyPm9Sw2k09MyLx9MNjcSZU5rRVkRiJJZnVRlQw2puZBp/nATQg67pSDc0dOaUiMRULHscCX3ZzNGLe1CRQ6EhIkUg1sEB9JwiR1WVQkNEikL8g6MnFDlGj05vWnSFhogUgHgHR0+YIXfixPSmEVFoiEiBiGVwOAR3/5s/P7+THc6Ykd6EhQoNESkgsTurage9eKxmCse/uSC/DWlogLlzU++n0BCRAhO7HodbCSW7esAkh2eemXofM4WGiBSc+AUHRunOPAfH6NGwc2fq/W67Lfq2iIjkWOyCAyy/PY50i+H19fG92ZSISCdiFxxuRsmuHfl58nSL4XV1mkZERApW/IIDozQfPY50i+GjRmnCQhEpaPELDjPK8hEc6RTDS0s1NbqIFLzYBUflrk3Ubnyc5rIanpiRo7s4TZyYXjH81lujb4uISJ7FLjhKcAwYsWs14+ZOiz480q1rqBguIkUireAws75mVhI+PsTMvmZmvaJtWmp92UzN/Ahnx023rqFiuIgUEXP31DuZLQOOAQYBfwCeA7a7e87/xB5v5o1Jy60YJd4azZP16pV6iGrUKNU1RKTHM7Nl7j4+G8dKd6jK3H0z8HXgenc/BRidjQZ019ulEc2Om05dQ8VwESlCaQeHmR1JcKu9ReG60mialL5N9KFpWgSz4zY0pFfXUDFcRIpQusFxHnAxcK+7rzCzA4FHI2tVJ3ZRggPNpdX8sX4+R18fwWhZOqfe1tWpGC4iRSmtGsfHviEokvdz979E06TOHdLnk/7ClhZ6+5ZonmDixNS9DdU1RCRmcl7jMLNfmdk+ZtYXeAl42cxmZaMBGSspoYJtkGHgpSWdISrVNUSkyKU7VDUq7GH8DfAAcABwRlSN6pRZMFi1I4L5qqZPT72P6hoiUuTSDY5e4XUbfwMsdPcdhDfiyzW3sMnbtmX3wA0N8NFHne+juoaISNrBcQPQBPQFHjezaiAvNQ7MAGjdkuXgSFUQLy3V5IUiIqQZHO5+jbtXufskD6wGjo+4be3qv/FtAGxcbdBLyIYZM1Jfs6EhKhERIP0rxwcAPwE+H676X+BSd2+JsG3t+tiV4336wPz53R8+CnsxHerbN/UwlohID5aPK8cXABuBvw+//gLcnI0GdMvmzTC7m3NVzZiRep8bbujec4iIFJB0exzL3b021bpcaDtXFWbQ2o25qlL1NurqVNsQkdjLR49ji5kdndSAzwERXYGXoZHdmKtq4sTOt6sgLiKyl7I095sO/DKsdQB8CEyNpkkZ6NMH5nRxrqp0LvZTQVxEZC8ZTTliZvsAuPtfzOw8d78qqoZ15DDr5S+wk3Ul+/LaP17R9bmqeveGrVs73l5env1rRURE8iQfQ1VAEBhJc1RdkI0GZOp1Dgbg263zOenWyV07I3fGjM5DA2DBgi4cWESk8HXn1rEpqsrR8LDJFWzr+klV8+Z1vr28XFeIi4h0oDvBkZcpR1rDvKok6DG89VaGB2hoSD1BonobIiId6rQ4bmYbaT8gDOgdSYtS8DA4KgjqDxmfVPXtb3e+vb5evQ0RkU50Ghzu3j9XDUlXa9JQVcYnVTU0pC6IX3999xooIlLgujNUlZKZfdHMXjOzlWZ2USf7/Z2ZuZmlrPgPKdkAwLWcw7u9a5hMBtXxVNOma4hKRCSlyILDzEqBXwBfAkYBp5nZqHb26w+cCzyTznH39zXB9wH91q+GadPSm+wwnWnTNUQlIpJSlD2OI4CV7r7K3bcDdwInt7PfvwKXAynOjw15m+lF0j216txzO99eX5/W04uIFLsog6MKWJO03Byu283MPgPs7+6LuvVM6ZxatX5959tV2xARSUukNY7OmFkJcAXwvTT2nWZmjWbW2O4OqU6tSjWUNWRIqiaIiEgoyuBYC+yftDwiXJfQHxgDPGZmTcBngYXtFcjdfb67j3f38VibJqdzalWqovjVV3e+XUREdosyOJ4DDjazA8ysHDgVWJjY6O4t7j7U3WvcvQZ4Gviau7ffqwjtrKpmJ6XBxSXV1alv5JSqKN63r4riIiIZSHd23Iy5+04z+y7wIFAKLHD3FWZ2KdDo7gs7P0L7WgcN5o3mXpT+9Wc46Nk7Un9DqqK4btIkIpKRyIIDwN0XA4vbrPtxB/sel84xzWAbFfTdnubMtamK4uptiIhkJG/F8a5KBEfJ9jTO3lVRXEQk62IXHCUlsJVKSnak0eNINUyloriISMZiFxyb1nzAeBoZufIRmstqeGJGJ72KzoapVBQXEemS2AVH3/dX05utGDBi12rGzZ3WfnikGqZSUVxEpEsyunVsTzDebK/zdZtLqxmxs+njK4cO7bzHEbPXLSLSHXm7dWxPNXxXO1OOdBYaKoqLiHRZQQTH26VtphxJNUyloriISJfFLjha2zR5E31omtZmypFUZ1OpKC4i0mWxC47Nw6ppYR+coLbxx/r5HH19myDQMJWISGRiFxz9Rg5mXv8Lg7Oqtry+d2homEpEJFKxCw6A7WV9ggebN++9MdVNnTRMJSLSLfELjg8+4LstlwWPR4/eu4exenXH36thKhGRbot0ksNIrF7NoNbw9rFr1wb3HIc9PQmzjq/R0DCViEi3xa/H0drJPccbGjq/sE/DVCIi3Ra/4GhP4p7jqU7DFRGRbiuM4Ejcc1yn4YqIRC5+wVHShXuOg+obIiJZEr/gqK7m/fL9gsdDh+6553iq6zdU3xARyYrYBccHDOZz9hQAs/znNBAGQmf1DQ1TiYhkTeyCY/VqOG7bAwD8fP1ZHHNGeDOnzuobGqYSEcma2N2PY4gd6G/xDn3ZsnvdZutDH2/nKvKEmL1GEZFsy+b9OGJ3AWAVa+nL9o+t6zQ0REQkq2I3VFXeJjRSUn1DRCSrYhcc2ynP7BtU3xARyar4BcewKrbRK/1v0Gm4IiJZFbvg6NcPSkssvZ0tzf1ERCRtsQsO1q6lrDXNOofOphIRybr4Bcf2DIrj1dXRtUNEpEjFLzjKMyiOpzOHlYiIZCR+wTFgAGkPQKkwLiKSdfELjpYWVPIWEcmf+AVHujUO1TdERCIRv+BIt8ah+oaISCRiFxwfDaiiNZ3BKtU3REQiEbvgeH39YEi/PC4iIlkWu+BobSV1f0MTG4qIRCZ2wZEWTWwoIhKZWAbHLko730H1DRGRyMQuOEpKYB7TOq5y1NfnsjkiIkUndsFRXQ1zPnk9v6CeVpLK5GZBaFx/fR5bJyJS+GIXHIMHwwMPwDlcz8J7HXMPZsFtbVVoiIjkQOyCA/ZcA5jJRLkiIpIdCg4REclILIOjoiL4d9u2/LZDRKQYxTI41OMQEckfBYeIiGREwSEiIhmJZXD89rfBvxdeCDU10NCQ1+aIiBSV2AXHBx/A9Ol7llevhmnTFB4iIrkSu+BYuxY2b/74us2bYfbs/LRHRKTYxC44OqprvPVWbtshIlKsYhccHd05duTI3LZDRKRYxS44qqqgT5+Pr+vTR7cYFxHJlUiDw8y+aGavmdlKM7uone0XmNnLZvaimS0xs+pUxxw8GObPh9LwlhzV1cGybsEhIpIbkQWHmZUCvwC+BIwCTjOzUW12+yMw3t3HAvcAP0/n2JMnw0EHwTe/CU1NCg0RkVyKssdxBLDS3Ve5+3bgTuDk5B3c/VF3T5wj9TQwIt2Dl5frAkARkXyIMjiqgDVJy83huo6cDTyQ7sErKhQcIiL5UJbvBgCY2RRgPHBsB9unAdMARoanT5WXa3ZcEZF8iLLHsRbYP2l5RLjuY8xsIjAb+Jq7txsF7j7f3ce7+/hhw4YBGqoSEcmXKIPjOeBgMzvAzMqBU4GFyTuY2TjgBoLQeC/dAzc0wNNPw+OPa64qEZFciyw43H0n8F3gQeAV4G53X2Fml5rZ18Ld/h3oB/zazJab2cIODrfbBx8Ec1Nt3Rosa64qEZHcMnfPdxsyUlEx3rdvb9xrfXV1cGquiIjszcyWufv4bBwrdleOa64qEZH8il1waK4qEZH8il1waK4qEZH8il1wJOaq2mefYFlzVYmI5FaPuAAwU5Mnw8qVcMklsGoVlMQu/kRE4iu2v3J79w7+TZyWKyIiuRH74Gh7G1kREYlWLIOjoSEYpgKordXFfyIiuRS7GkfiyvFET2Pt2mAZVCAXEcmF2PU41q7de3hq82aYPTs/7RERKTaxCw5dOS4ikl+xCw5dOS4ikl+xCw5dOS4ikl+xC47EleP77RcsDx2qK8dFRHIpdsEBQUg8/njw+IorFBoiIrkUy+CAPRcAbtmS33aIiBSb2AbHokXBv//4j7p9rIhILsUyOBoa4Lzz9izr9rEiIrkTy+CYPXvvISpdBCgikhuxm3IEOr7YTxcBisTPjh07aG5uZqumus6KyspKRowYQa9evSJ7jlgGx8iRwfBUe+tFJF6am5vp378/NTU1mFm+mxNr7s769etpbm7mgAMOiOx5YjlUNWeOLgIUKRRbt25lyJAhCo0sMDOGDBkSee8tlsExeTJMnbpnubQ0WNb1HCLxpNDInly8l7EMjoYGuPXWPcu7dgXLOqtKRDK1fv16amtrqa2t5ZOf/CRVVVW7l7d3NKtqqLGxkZkzZ2b0fDU1Nbz//vvdaXLexTI4Zs/W1OoixaqhIbh2q6QkO9dwDRkyhOXLl7N8+XKmT5/O+eefv3u5vLycnTt3dvi948eP55prruleA2IolsGhs6pEilNDQ3DN1urV4B7dNVxnnnkm06dPZ8KECVx44YU8++yzHHnkkYwbN46jjjqK1157DYDHHnuMr3zlKwBccsklnHXWWRx33HEceOCBGQVKU1MTJ5xwAmPHjqWuro63wl9mv/71rxkzZgyHHXYYn//85wFYsWIFRxxxBLW1tYwdO5bXX389uy8+DTqrSkR6jPPOg+XLO97+9NOwbdvH123eDGefDTfe2P731NbCVVdl3pbm5maefPJJSktL+ctf/sLSpUspKyvj4Ycf5gc/+AG/+c1v9vqeV199lUcffZSNGzfyqU99ivr6+rROiz3nnHOYOnUqU6dOZcGCBcycOZP77ruPSy+9lAcffJCqqio2bNgAwLx58zj33HOZPHky27dvZ9euXZm/uG6KZY9DZ1WJFKe2oZFqfXeccsoplJaWAtDS0sIpp5zCmDFjOP/881mxYkW73/PlL3+ZiooKhg4dyr777su7776b1nM99dRTnH766QCcccYZPPHEEwB87nOf48wzz+TGG2/cHRBHHnkkP/3pT7n88stZvXo1vRMT9+VQLHsckyfDH/4A8+YF3VWdVSVSGFL1DGpq2h9tqK6Gxx7Lblv69u27+/GPfvQjjj/+eO69916ampo47rjj2v2eioqK3Y9LS0s7rY+kY968eTzzzDMsWrSIww8/nGXLlnH66aczYcIEFi1axKRJk7jhhhs44YQTuvU8mYpljyNxVpV7sKyzqkSKQ75GG1paWqiqqgLglltuyfrxjzrqKO68804AGhoaOOaYYwB44403mDBhApdeeinDhg1jzZo1rFq1igMPPJCZM2dy8skn8+KLL2a9PanEMjh0VpVIcZo8ObhxW3U1mAX/5uJGbhdeeCEXX3wx48aN63YvAmDs2LGMGDGCESNGcMEFF3Dttddy8803M3bsWG677TauvvpqAGbNmsWhhx7KmDFjOOqoozjssMO4++67GTNmDLW1tbz00kt861vf6nZ7MmWe+LM9JsaPH+/PP99Ie802g9bW3LdJRLrulVde4dOf/nS+m1FQ2ntPzWyZu4/PxvFj2ePo6OypwYNz2w4RkWIUy+CYMwfaO8Nt40bVOUREohbL4Jg8GfbZZ+/127erziEiErVYBgfABx+0v15Xj4uIRCu2wdFRnUNXj4uIRCu2wTFpUmbrRUQkO2J55TjA4sWZrRcRac/69eupq6sD4J133qG0tJRhw4YB8Oyzz1JeXt7p9z/22GOUl5dz1FFH7bXtlltuobGxkeuuuy77Dc+j2PY42pt2oLP1IlIgsjyveqpp1VN57LHHePLJJ7vVhriJbXCEc4+lvV5ECkCO5lVftmwZxx57LIcffjgnnXQSf/7znwG45pprGDVqFGPHjuXUU0+lqamJefPmceWVV1JbW8vSpUvTOv4VV1zBmDFjGDNmDFeFE3Rt2rSJL3/5yxx22GGMGTOGu+66C4CLLrpo93P+8z//c1ZfZ1fFdqiqo5mE8zDDsIhkSw+YV93dOeecc7j//vsZNmwYd911F7Nnz2bBggX87Gc/480336SiooINGzYwcOBApk+fTr9+/dL+pb5s2TJuvvlmnnnmGdydCRMmcOyxx7Jq1SqGDx/OokWLgGB+rPXr13Pvvffy6quvYma7p1bPt9j2OKqrO96miwBFClQO5lXftm0bL730EieeeCK1tbVcdtllNDc3A8EcU5MnT+b222+nrKxrf3c/8cQT/O3f/i19+/alX79+fP3rX2fp0qUceuihPPTQQ3z/+99n6dKlDBgwgAEDBlBZWcnZZ5/Nb3/7W/q0neExT2Lb45gzB6ZMaX/buedqinWRWOoB86q7O6NHj+app57aa9uiRYt4/PHH+e///m/mzJnDn/70p6w8J8AhhxzC888/z+LFi/nhD39IXV0dP/7xj3n22WdZsmQJ99xzD9dddx2PPPJI1p6zq2Lb4+gsGNavz107RCSHcjCvekVFBevWrdsdHDt27GDFihW0trayZs0ajj/+eC6//HJaWlr46KOP6N+/Pxs3bkz7+Mcccwz33XcfmzdvZtOmTdx7770cc8wxvP322/Tp04cpU6Ywa9Ysnn/+eT766CNaWlqYNGkSV155JS+88ELWXmd3xLbHISJFKPEX4+zZwTQRI0cGoZHFIYaSkhLuueceZs6cSUtLCzt37uS8887jkEMOYcqUKbS0tODuzJw5k4EDB/LVr36Vb3zjG9x///1ce+21u++lkXDLLbdw33337V5++umnOfPMMzniiCMA+Pa3v824ceN48MEHmTVrFiUlJfTq1Yu5c+eyceNGTj75ZLZu3Yq7c8UVV2TtdXZHLKdVb2xsBIIzqDqaRv322zVcJRIHmlY9+zSteic6u/fGuefmrh0iIsUk1sHR2ZlVqnOIiEQj1sGRqh42cWJu2iEiUkxiHRypahhLlig8ROIgbrXWniwX72WsgwNgyJDOty9ZAmVluihQpKeqrKxk/fr1Co8scHfWr19PZWVlpM8T67OqIAiEji4E7Eh9PVx/fZYbJiJdsmPHDpqbm9m6dWu+m1IQKisrGTFiBL3a3F87m2dVxT44AHr3hlx95urq4OGHc/NcIiLZks3gKIgLAG+6KfNeR1ctWQJmuXkuEZHsOfzwbB0p9jUOCIrk4X1YREQkYgURHBAMHyk8RESiF7sah5ltBF7reI+hg2FkjQaURESSNeH+flZ+L8axxvFatgo8cWdmjXovAnov9tB7sYfeiz3MrDH1XukpmKEqERHJDQWHiIhkJI7BMT/fDehB9F7sofdiD70Xe+i92CNr70XsiuMiIpJfcexxiIhIHsUqOMzsi2b2mpmtNLOL8t2eKJnZ/mb2qJm9bGYrzOzccP1gM3vIzF4P/x0UrjczuyZ8b140s8/k9xVkn5mVmtkfzex34fIBZvZM+JrvMrPycH1FuLwy3F6T14ZnmZkNNLN7zOxVM3vFzI4s1s+FmZ0f/v94yczuMLPKYvlcmNkCM3vPzF5KWpfx58DMpob7v25mU9N57tgEh5mVAr8AvgSMAk4zs1H5bVWkdgLfc/dRwGeBfwpf70XAEnc/GFgSLkPwvhwcfk0D5ua+yZE7F3glafly4Ep3Pwj4EDg7XH828GG4/spwv0JyNfB7d/9/wGEE70nRfS7MrAqYCYx39zFAKXAqxfO5uAX4Ypt1GX0OzGww8BNgAnAE8JNE2HTK3WPxBRwJPJi0fDFwcb7blcPXfz9wIsHFj/uF6/YjuK4F4AbgtKT9d+9XCF/AiPA/wgnA7wAD3gfK2n4+gAeBI8PHZeF+lu/XkKX3YQDwZtvXU4yfC6AKWAMMDn/OvwNOKqbPBVADvNTVzwFwGnBD0vqP7dfRV2x6HOz5kCQ0h+sKXtilHgc8A3zC3f8cbnoH+ET4uNDfn6uAC4HEneaHABvcfWe4nPx6d78X4faWcP9CcACwDrg5HLa7ycz6UoSfC3dfC/wH8BbwZ4Kf8zKK83ORkOnnoEufjzgFR1Eys37Ab4Dz3P0vyds8+BOh4E+LM7OvAO+5+7J8t6UHKAM+A8x193HAJvYMRwBF9bkYBJxMEKbDgb7sPXRTtKL8HMQpONYC+yctjwjXFSwz60UQGg3u/ttw9btmtl+4fT/gvXB9Ib8/nwO+ZmZNwJ0Ew1VXAwPNLDFtTvLr3f1ehNsHAOtz2eAINQPN7v5MuHwPQZAU4+diIvCmu69z9x3Abwk+K8X4uUjI9HPQpc9HnILjOeDg8IyJcoIi2MI8tykyZmbAfwGvuPsVSZsWAokzH6YS1D4S678Vnj3xWaAlqcsaa+5+sbuPcPcagp/7I+4+GXgU+Ea4W9v3IvEefSPcvyD+Anf3d4A1ZvapcFUd8DJF+LkgGKL6rJn1Cf+/JN6LovtcJMn0c/Ag8AUzGxT24L4Qrutcvos7GRaCJgH/B7wBzM53eyJ+rUcTdDNfBJaHX5MIxmSXAK8DDwODw/2N4KyzN4A/EZxpkvfXEcH7chzwu/DxgcCzwErg10BFuL4yXF4Zbj8w3+3O8ntQCzSGn437gEHF+rkA/gV4FXgJuA2oKJbPBXAHQW1nB0FP9OyufA6As8L3ZCXwD+k8t64cFxGRjMRpqEpERHoABYeIiGREwSEiIhlRcIiISEYUHCIikhEFh0gbZrbLzJYnfWVtJmYzq0mezVQkjspS7yJSdLa4e22+GyHSU6nHIZImM2sys5+b2Z/M7FkzOyhcX2Nmj4T3OVhiZiPD9Z8ws3vN7IXw66jwUKVmdmN4H4n/MbPeeXtRIl2g4BDZW+82Q1XfTNrW4u6HAtcRzNgLcC1wq7uPBRqAa8L11wD/6+6HEcwntSJcfzDwC3cfDWwA/i7SVyOSZbpyXKQNM/vI3fu1s74JOMHdV4UTUL7j7kPM7H2CeyDsCNf/2d2Hmtk6YIS7b0s6Rg3wkAc32sHMvg/0cvfLcvDSRLJCPQ6RzHgHjzOxLenxLlRrlJhRcIhk5ptJ/z4VPn6SYNZegMnA0vDxEqAedt8vfUCuGikSJf2lI7K33ma2PGn59+6eOCV3kJm9SNBrOC1cdw7BHflmEdyd7x/C9ecC883sbIKeRT3BbKYisaYah0iawhrHeHd/P99tEcknDVWJiEhG1OMQEZGMqMchIiIZUXCIiEhGFBwiIpIRBYeIiGREwSEiIhlRcIiISEb+P4ymmAzrPpdSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 11.21 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([95, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 43\n",
      "False Positive : 3\n",
      "False Negative : 5\n",
      "True Negative : 44\n",
      "\n",
      "Class True Evaluation\n",
      "- Precision : 93.478 %\n",
      "- Recall : 89.583 %\n",
      "- F1 : 0.91489\n",
      "\n",
      "Class False Evaluation\n",
      "- Precision : 89.796 %\n",
      "- Recall : 93.617 %\n",
      "- F1 : 0.91667\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 91.579 %\n",
      "- Precision : 91.637 %\n",
      "- Recall : 91.6 %\n",
      "- F1 : 0.91618\n",
      "- Average Confidence : 15.69 %\n",
      "Model, Combined,,,,True,,,False,,,\n",
      "Twitter16-TF_2LMLP_BERT_Finetuned_with_TopTermsVectors Validation, 91.579, 91.637, 91.6, 0.91618, 93.478, 89.583, 0.91489, 89.796, 93.617, 0.91667, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([39, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 18\n",
      "False Positive : 0\n",
      "False Negative : 1\n",
      "True Negative : 20\n",
      "\n",
      "Class True Evaluation\n",
      "- Precision : 100.0 %\n",
      "- Recall : 94.737 %\n",
      "- F1 : 0.97297\n",
      "\n",
      "Class False Evaluation\n",
      "- Precision : 95.238 %\n",
      "- Recall : 100.0 %\n",
      "- F1 : 0.97561\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 97.436 %\n",
      "- Precision : 97.619 %\n",
      "- Recall : 97.368 %\n",
      "- F1 : 0.97493\n",
      "- Average Confidence : 16.25 %\n",
      "Model, Combined,,,,True,,,False,,,\n",
      "Twitter16-TF_2LMLP_BERT_Finetuned_with_TopTermsVectors Test, 97.436, 97.619, 97.368, 0.97493, 100.0, 94.737, 0.97297, 95.238, 100.0, 0.97561, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "binary = True\n",
    "\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_2LMLP_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=1, criterion=nn.BCELoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                binary=binary,\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in val_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in test_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55461251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
