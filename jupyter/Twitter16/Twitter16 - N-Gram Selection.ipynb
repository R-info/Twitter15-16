{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feff3561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8a6e983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>656955120626880512</td>\n",
       "      <td>correct predictions in back to the future ii U...</td>\n",
       "      <td>false</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>615689290706595840</td>\n",
       "      <td>.@whitehouse in rainbow colors for #scotusmarr...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>613404935003217920</td>\n",
       "      <td>cops bought the alleged church shooter burger ...</td>\n",
       "      <td>false</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  656955120626880512  correct predictions in back to the future ii U...   \n",
       "1  615689290706595840  .@whitehouse in rainbow colors for #scotusmarr...   \n",
       "2  613404935003217920  cops bought the alleged church shooter burger ...   \n",
       "3  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "4  714598641827246081  an open letter to trump voters from his top st...   \n",
       "\n",
       "        label       tvt  cv_fold        tt        tvt2      tvt2_1    tvt2_2  \\\n",
       "0       false  training        1  training  validation    training  training   \n",
       "1        true  training        3  training    training  validation  training   \n",
       "2       false  training        2      test    training    training  training   \n",
       "3  unverified  training        3      test    training    training  training   \n",
       "4  unverified  training        1      test    training  validation  training   \n",
       "\n",
       "       tvt2_3  \n",
       "0  validation  \n",
       "1    training  \n",
       "2    training  \n",
       "3    training  \n",
       "4    training  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter16_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63153167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "      <th>label_rnr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>656955120626880512</td>\n",
       "      <td>correct predictions in back to the future ii U...</td>\n",
       "      <td>false</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>615689290706595840</td>\n",
       "      <td>.@whitehouse in rainbow colors for #scotusmarr...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>613404935003217920</td>\n",
       "      <td>cops bought the alleged church shooter burger ...</td>\n",
       "      <td>false</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  656955120626880512  correct predictions in back to the future ii U...   \n",
       "1  615689290706595840  .@whitehouse in rainbow colors for #scotusmarr...   \n",
       "2  613404935003217920  cops bought the alleged church shooter burger ...   \n",
       "3  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "4  714598641827246081  an open letter to trump voters from his top st...   \n",
       "\n",
       "        label       tvt  cv_fold        tt        tvt2      tvt2_1    tvt2_2  \\\n",
       "0       false  training        1  training  validation    training  training   \n",
       "1        true  training        3  training    training  validation  training   \n",
       "2       false  training        2      test    training    training  training   \n",
       "3  unverified  training        3      test    training    training  training   \n",
       "4  unverified  training        1      test    training  validation  training   \n",
       "\n",
       "       tvt2_3 label_rnr  \n",
       "0  validation   rumours  \n",
       "1    training   rumours  \n",
       "2    training   rumours  \n",
       "3    training   rumours  \n",
       "4    training   rumours  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_rnr = []\n",
    "for i, d in data.iterrows():\n",
    "    if d['label'] in [\"unverified\", \"true\", \"false\"]:\n",
    "        label_rnr.append(\"rumours\")\n",
    "    else:\n",
    "        label_rnr.append(\"non-rumours\")\n",
    "        \n",
    "data['label_rnr'] = pd.Series(label_rnr)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b95fb4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['false', 'true', 'unverified', 'non-rumor']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels_str = ['rumour', 'non-rumour']\n",
    "label_type = \"label\"\n",
    "labels_str = data[label_type].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6ce7b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 2, 2, 1, 2, 3, 3, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d[label_type])\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fc83a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2unigrams(text):\n",
    "    texts = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    texts = [t for t in texts if t not in string.punctuation]\n",
    "    texts = [t for t in texts if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    unigrams = texts\n",
    "    \n",
    "    return unigrams\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    texts = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    texts = [t for t in texts if t not in string.punctuation]\n",
    "    texts = [t for t in texts if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(texts)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def text2trigrams(text):\n",
    "    texts = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    texts = [t for t in texts if t not in string.punctuation]\n",
    "    texts = [t for t in texts if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    trigrams = nltk.trigrams(texts)\n",
    "    trigrams = map(' '.join, trigrams)\n",
    "    trigrams = [bgr for bgr in trigrams]\n",
    "    \n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def bigrams_vectors_generation(texts):\n",
    "    bigram_vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(bigram_vector_base) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in bigram_vector_base:\n",
    "                idx = bigram_vector_base.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        bigram_vectors.append(init_vec)\n",
    "    \n",
    "    return bigram_vectors\n",
    "\n",
    "\n",
    "def custom_vectors_generation(texts, vector_terms):\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "        trigrams = text2trigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(vector_terms) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in vector_terms:\n",
    "                idx = vector_terms.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        for tgr in trigrams:\n",
    "            if tgr in vector_terms:\n",
    "                idx = vector_terms.index(tgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        vectors.append(init_vec)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97281e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "# vectors = bigrams_vectors_generation(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31e1c006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.collocations import *\n",
    "\n",
    "top_n = 2000\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "\n",
    "finder2 = BigramCollocationFinder.from_words([])\n",
    "finder3 = TrigramCollocationFinder.from_words([])\n",
    "\n",
    "# generating bigram and trigram\n",
    "for text in texts:\n",
    "    unigrams = text2unigrams(text)\n",
    "    bigrams = text2bigrams(text)\n",
    "    trigrams = text2trigrams(text)\n",
    "    \n",
    "    for ngrm in unigrams:\n",
    "        if ngrm not in finder2.word_fd:\n",
    "            finder2.word_fd[ngrm] = 0\n",
    "        finder2.word_fd[ngrm] += 1\n",
    "        finder2.N += 1\n",
    "        \n",
    "        if ngrm not in finder3.word_fd:\n",
    "            finder3.word_fd[ngrm] = 0\n",
    "        finder3.word_fd[ngrm] += 1\n",
    "        finder3.N += 1\n",
    "    \n",
    "    for ngrm in bigrams:\n",
    "        term = tuple([i for i in ngrm.split()])\n",
    "        \n",
    "        if term not in finder2.ngram_fd:\n",
    "            finder2.ngram_fd[term] = 0\n",
    "            \n",
    "        finder2.ngram_fd[term] += 1\n",
    "\n",
    "    for ngrm in trigrams:\n",
    "        term = tuple([i for i in ngrm.split()])\n",
    "        \n",
    "        if term not in finder3.ngram_fd:\n",
    "            finder3.ngram_fd[term] = 0\n",
    "            \n",
    "        finder3.ngram_fd[term] += 1\n",
    "        \n",
    "# only bigrams that appear 3+ times\n",
    "finder2.apply_freq_filter(3)\n",
    "finder3.apply_freq_filter(3)\n",
    "\n",
    "combined = []\n",
    "for res in finder2.score_ngrams(bigram_measures.pmi):\n",
    "    combined.append(res)\n",
    "for res in finder3.score_ngrams(trigram_measures.pmi):\n",
    "    combined.append(res)\n",
    "combined = sorted(combined, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "703b0f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501 275\n",
      "('1991', 'book', 'quotes') - 22.928836235477128\n",
      "('kissing', 'islands', 'greenland') - 22.928836235477128\n",
      "('confiscates', 'several', 'thousand') - 22.758911234034812\n",
      "('fda', 'confiscates', 'several') - 22.758911234034812\n",
      "('niagara', 'falls', 'turned') - 22.606908140589766\n",
      "('several', 'thousand', 'chickens') - 22.34387373475597\n",
      "('drive', 'destruction', 'company') - 21.86994254642356\n",
      "('cpl', 'nathan', 'cirillo') - 21.536518812698368\n",
      "('blacks', '1991', 'book') - 21.513798736198282\n",
      "('signers', 'stock', 'sinks') - 21.469404616839828\n"
     ]
    }
   ],
   "source": [
    "print(len(finder2.ngram_fd), len(finder3.ngram_fd))\n",
    "count = 0\n",
    "for k, v in combined:\n",
    "    print(f\"{k} - {v}\")\n",
    "    count += 1\n",
    "    if count >= 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e3377a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "term_vector_base = [\" \".join(c[0]) for c in combined[:top_n]]\n",
    "vectors = custom_vectors_generation(texts, term_vector_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66934ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "777"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectors[102])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e2b1180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6362816335444546\n",
      "22.928836235477128\n",
      "501\n",
      "275\n"
     ]
    }
   ],
   "source": [
    "min_score = 100\n",
    "max_score = 0\n",
    "n_2gram = 0\n",
    "n_3gram = 0\n",
    "for k, v in combined[:top_n]:\n",
    "    min_score = min(min_score, v)\n",
    "    max_score = max(max_score, v)\n",
    "    \n",
    "    if len(k) == 2:\n",
    "        n_2gram += 1\n",
    "    \n",
    "    if len(k) == 3:\n",
    "        n_3gram += 1\n",
    "        \n",
    "print(min_score)\n",
    "print(max_score)\n",
    "print(n_2gram)\n",
    "print(n_3gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cccd2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81824aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- START ---\n",
      "---> execution time : 0.01 seconds\n",
      "Validation Set\n",
      "192 vs 192\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 75.0 %\n",
      "- Recall : 65.217 %\n",
      "- F1 : 0.69767\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 78.431 %\n",
      "- Recall : 72.727 %\n",
      "- F1 : 0.75472\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 83.871 %\n",
      "- Recall : 56.522 %\n",
      "- F1 : 0.67532\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 48.571 %\n",
      "- Recall : 75.556 %\n",
      "- F1 : 0.5913\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 67.708 %\n",
      "- Precision : 71.468 %\n",
      "- Recall : 67.505 %\n",
      "- F1 : 0.6943\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,false,,,true,,,unverified,,,non-rumor,,,\n",
      "Anonymous, 67.708, 71.468, 67.505, 0.6943, 75.0, 65.217, 0.69767, 78.431, 72.727, 0.75472, 83.871, 56.522, 0.67532, 48.571, 75.556, 0.5913, \n",
      "--- END ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from library.classification import SKLearnClassification\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "svm = LinearSVC()\n",
    "\n",
    "model = SKLearnClassification(svm, \"Support Vector Machine\")\n",
    "print(f\"\\n--- START ---\")\n",
    "model.train(train_vectors, train_labels, \"Twitter16\")\n",
    "\n",
    "print(\"Validation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False\n",
    ")\n",
    "conf_mat.evaluate(labels_str)\n",
    "\n",
    "print(\"--- END ---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33a6804c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens : 776\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "coefs = model.model.coef_\n",
    "if type(coefs) == csr_matrix:\n",
    "    coefs.toarray().tolist()[0]\n",
    "else:\n",
    "    coefs.tolist()\n",
    "coefs_and_features = list(zip(coefs[0], term_vector_base))\n",
    "\n",
    "# Most predictive overall\n",
    "# coefs_and_features = sorted(coefs_and_features, key=lambda x: x[0], reverse=True)\n",
    "coefs_and_features = sorted(coefs_and_features, key=lambda x: abs(x[0]), reverse=True)\n",
    "print(f\"Total tokens : {len(coefs_and_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c865ec2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 777)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bc37609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.4564242351941268, 'el chapo'),\n",
       " (1.4564242075211555, '#opkkk #hoodsoff'),\n",
       " (1.4065789857626652, 'mass shootings'),\n",
       " (1.3107817682706258, 'red cross'),\n",
       " (1.227858430496503, 'burger king'),\n",
       " (1.128577166985884, 'the future'),\n",
       " (1.0968672625996452, 'new cnn'),\n",
       " (1.0923181104601813, 'new orleans'),\n",
       " (1.0923180613055532, 'poll @hillaryclinton'),\n",
       " (1.0776436428644736, 'that he')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs_and_features[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d07ca187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 'who have'),\n",
       " (0.0, 'is now'),\n",
       " (0.0, 'escaped the'),\n",
       " (0.0, 'the sports'),\n",
       " (0.0, 'on donald'),\n",
       " (0.0, 'house is'),\n",
       " (0.0, 'hostages in'),\n",
       " (0.0, 'in shooting'),\n",
       " (0.0, 'of this'),\n",
       " (0.0, 'at a')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs_and_features[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bbd1712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['el chapo', '#opkkk #hoodsoff', 'mass shootings', 'red cross', 'burger king', 'the future', 'new cnn', 'new orleans', 'poll @hillaryclinton', 'that he']\n"
     ]
    }
   ],
   "source": [
    "n_best = 750\n",
    "best_tokens = []\n",
    "\n",
    "# for cf in coefs_and_features[-n_best:]:\n",
    "#     best_tokens.append(cf[1])\n",
    "\n",
    "for cf in coefs_and_features[:n_best]:\n",
    "    best_tokens.append(cf[1])\n",
    "    \n",
    "print(best_tokens[:10])\n",
    "    \n",
    "with open(\"../../data/processed/twitter16-multi_best_terms.txt\", \"w\") as f:\n",
    "    for token in best_tokens:\n",
    "        f.write(token + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a333226",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
