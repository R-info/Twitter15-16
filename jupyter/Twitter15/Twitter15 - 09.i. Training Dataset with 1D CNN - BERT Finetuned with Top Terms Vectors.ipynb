{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Twitter15-Multi\"\n",
    "unique_name = \"BERT_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "bigram_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter15_BERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>691809004356501505</td>\n",
       "      <td>america is a nation of second chances â€”@potus ...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693204708933160960</td>\n",
       "      <td>brandon marshall visits and offers advice, sup...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>551099691702956032</td>\n",
       "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "1  714598641827246081  an open letter to trump voters from his top st...   \n",
       "2  691809004356501505  america is a nation of second chances â€”@potus ...   \n",
       "3  693204708933160960  brandon marshall visits and offers advice, sup...   \n",
       "4  551099691702956032  rip elly may clampett: so sad to learn #beverl...   \n",
       "\n",
       "        label       tvt  cv_fold        tt        tvt2      tvt2_1  \\\n",
       "0  unverified  training        1  training    training  validation   \n",
       "1  unverified  training        1      test    training    testting   \n",
       "2   non-rumor  training        2  training  validation  validation   \n",
       "3   non-rumor  training        1  training    testting    testting   \n",
       "4        true  training        3  training  validation    training   \n",
       "\n",
       "       tvt2_2    tvt2_3  \n",
       "0    training  training  \n",
       "1    training  training  \n",
       "2  validation  testting  \n",
       "3    training  training  \n",
       "4  validation  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter15_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unverified', 'non-rumor', 'true', 'false']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = data['label'].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 2, 1, 0, 2, 0, 3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d['label'])\n",
    "    labs = [1 if idx == lab else 0 for idx in range(len(labels_str))]\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#ferguson pd', 'bathroom policy', 'institutional racism', 'want to', 'bag charge', 'ios 8', 'can be', 'clinton campaign', 'new transgender', 'protest at']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_terms = []\n",
    "with open(\"../../data/processed/twitter15-multi_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        vector_terms.append(t.strip())\n",
    "\n",
    "print(vector_terms[:10])\n",
    "len(vector_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2unigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(text)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def text2trigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    trigrams = nltk.trigrams(text)\n",
    "    trigrams = map(' '.join, trigrams)\n",
    "    trigrams = [bgr for bgr in trigrams]\n",
    "    \n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def custom_vectors_generation(texts, vector_terms):\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "        trigrams = text2trigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(vector_terms) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in vector_terms:\n",
    "                idx = vector_terms.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        for tgr in trigrams:\n",
    "            if tgr in vector_terms:\n",
    "                idx = vector_terms.index(tgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        vectors.append(init_vec)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 1519, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "terms_vectors = custom_vectors_generation(texts, vector_terms)\n",
    "\n",
    "vectors = np.concatenate([vectors, terms_vectors], axis=1)\n",
    "vectors = vectors.reshape(vectors.shape[0], vectors.shape[1], 1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1004, 1519, 1)\n",
      "(355, 1519, 1)\n",
      "(131, 1519, 1)\n",
      "(1004,)\n",
      "(355,)\n",
      "(131,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv1d(n_input, 512, 1, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 128, 1, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=1, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, n_output)\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 82.254\n",
      "Saving after new best accuracy : 82.535\n",
      "Saving after new best accuracy : 82.817\n",
      "Saving after new best accuracy : 83.099\n",
      "-- Epoch 50, Train Loss : 0.004340821644291282, Test Loss : 0.9587355256080627\n",
      "-- Epoch 100, Train Loss : 0.0010022103670053184, Test Loss : 1.1436976194381714\n",
      "-- Epoch 150, Train Loss : 0.0004265185125404969, Test Loss : 1.2611258029937744\n",
      "-- Epoch 200, Train Loss : 0.00023780449555488303, Test Loss : 1.3365052938461304\n",
      "-- Epoch 250, Train Loss : 0.0001519026845926419, Test Loss : 1.3938941955566406\n",
      "-- Epoch 300, Train Loss : 0.00010541009032749571, Test Loss : 1.4408615827560425\n",
      "-- Epoch 350, Train Loss : 7.729947901680134e-05, Test Loss : 1.4807512760162354\n",
      "-- Epoch 400, Train Loss : 5.898967538087163e-05, Test Loss : 1.5155658721923828\n",
      "-- Epoch 450, Train Loss : 4.637990605260711e-05, Test Loss : 1.5465461015701294\n",
      "-- Epoch 500, Train Loss : 3.7336076275096275e-05, Test Loss : 1.5745247602462769\n",
      "-- Epoch 550, Train Loss : 3.0632202651759144e-05, Test Loss : 1.600083351135254\n",
      "-- Epoch 600, Train Loss : 2.552441492298385e-05, Test Loss : 1.6236521005630493\n",
      "-- Epoch 650, Train Loss : 2.1547936739807483e-05, Test Loss : 1.6455665826797485\n",
      "-- Epoch 700, Train Loss : 1.8390385776001494e-05, Test Loss : 1.6660680770874023\n",
      "-- Epoch 750, Train Loss : 1.5848801922402345e-05, Test Loss : 1.6853649616241455\n",
      "-- Epoch 800, Train Loss : 1.376570025968249e-05, Test Loss : 1.7036226987838745\n",
      "-- Epoch 850, Train Loss : 1.203665215143701e-05, Test Loss : 1.7209539413452148\n",
      "-- Epoch 900, Train Loss : 1.060424528986914e-05, Test Loss : 1.7374862432479858\n",
      "-- Epoch 950, Train Loss : 9.386863894178532e-06, Test Loss : 1.7533169984817505\n",
      "-- Epoch 1000, Train Loss : 8.34754473544308e-06, Test Loss : 1.768510341644287\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 43.38 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([355])\n",
      "355 vs 355\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 82.609 %\n",
      "- Recall : 73.077 %\n",
      "- F1 : 0.77551\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 71.698 %\n",
      "- Recall : 87.356 %\n",
      "- F1 : 0.78756\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 86.17 %\n",
      "- Recall : 87.097 %\n",
      "- F1 : 0.86631\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 94.186 %\n",
      "- Recall : 83.505 %\n",
      "- F1 : 0.88525\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 83.099 %\n",
      "- Precision : 83.666 %\n",
      "- Recall : 82.759 %\n",
      "- F1 : 0.8321\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Twitter15-Multi_4LayerNet_BERT_Finetuned_with_TopTermsVectors Validation, 83.099, 83.666, 82.759, 0.8321, 82.609, 73.077, 0.77551, 71.698, 87.356, 0.78756, 86.17, 87.097, 0.86631, 94.186, 83.505, 0.88525, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([131])\n",
      "131 vs 131\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 87.879 %\n",
      "- Recall : 80.556 %\n",
      "- F1 : 0.84058\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 69.444 %\n",
      "- Recall : 80.645 %\n",
      "- F1 : 0.74627\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 83.784 %\n",
      "- Recall : 91.176 %\n",
      "- F1 : 0.87324\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 84.0 %\n",
      "- Recall : 70.0 %\n",
      "- F1 : 0.76364\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 80.916 %\n",
      "- Precision : 81.277 %\n",
      "- Recall : 80.594 %\n",
      "- F1 : 0.80934\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Twitter15-Multi_4LayerNet_BERT_Finetuned_with_TopTermsVectors Test, 80.916, 81.277, 80.594, 0.80934, 87.879, 80.556, 0.84058, 69.444, 80.645, 0.74627, 83.784, 91.176, 0.87324, 84.0, 70.0, 0.76364, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b4d368",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
