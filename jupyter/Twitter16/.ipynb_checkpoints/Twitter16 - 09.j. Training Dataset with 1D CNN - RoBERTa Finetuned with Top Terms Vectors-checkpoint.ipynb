{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Twitter16-Multi\"\n",
    "unique_name = \"RoBERTa_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "bigram_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(818, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter16_RoBERTa_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>656955120626880512</td>\n",
       "      <td>correct predictions in back to the future ii U...</td>\n",
       "      <td>false</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>615689290706595840</td>\n",
       "      <td>.@whitehouse in rainbow colors for #scotusmarr...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>613404935003217920</td>\n",
       "      <td>cops bought the alleged church shooter burger ...</td>\n",
       "      <td>false</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  656955120626880512  correct predictions in back to the future ii U...   \n",
       "1  615689290706595840  .@whitehouse in rainbow colors for #scotusmarr...   \n",
       "2  613404935003217920  cops bought the alleged church shooter burger ...   \n",
       "3  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "4  714598641827246081  an open letter to trump voters from his top st...   \n",
       "\n",
       "        label       tvt  cv_fold        tt        tvt2      tvt2_1    tvt2_2  \\\n",
       "0       false  training        1  training  validation    training  training   \n",
       "1        true  training        3  training    training  validation  training   \n",
       "2       false  training        2      test    training    training  training   \n",
       "3  unverified  training        3      test    training    training  training   \n",
       "4  unverified  training        1      test    training  validation  training   \n",
       "\n",
       "       tvt2_3  \n",
       "0  validation  \n",
       "1    training  \n",
       "2    training  \n",
       "3    training  \n",
       "4    training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter16_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['false', 'true', 'unverified', 'non-rumor']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = data['label'].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 2, 2, 1, 2, 3, 3, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d['label'])\n",
    "    labs = [1 if idx == lab else 0 for idx in range(len(labels_str))]\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['el chapo', '#opkkk #hoodsoff', 'mass shootings', 'red cross', 'burger king', 'the future', 'new cnn', 'new orleans', 'poll @hillaryclinton', 'that he']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_terms = []\n",
    "with open(\"../../data/processed/twitter16-multi_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        vector_terms.append(t.strip())\n",
    "\n",
    "print(vector_terms[:10])\n",
    "len(vector_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2unigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(text)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def text2trigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    trigrams = nltk.trigrams(text)\n",
    "    trigrams = map(' '.join, trigrams)\n",
    "    trigrams = [bgr for bgr in trigrams]\n",
    "    \n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def custom_vectors_generation(texts, vector_terms):\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "        trigrams = text2trigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(vector_terms) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in vector_terms:\n",
    "                idx = vector_terms.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        for tgr in trigrams:\n",
    "            if tgr in vector_terms:\n",
    "                idx = vector_terms.index(tgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        vectors.append(init_vec)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(818, 1519, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "terms_vectors = custom_vectors_generation(texts, vector_terms)\n",
    "\n",
    "vectors = np.concatenate([vectors, terms_vectors], axis=1)\n",
    "vectors = vectors.reshape(vectors.shape[0], vectors.shape[1], 1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(564, 1519, 1)\n",
      "(172, 1519, 1)\n",
      "(82, 1519, 1)\n",
      "(564,)\n",
      "(172,)\n",
      "(82,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv1d(n_input, 512, 1, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 128, 1, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=1, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, n_output)\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 80.814\n",
      "Saving after new best accuracy : 83.14\n",
      "Saving after new best accuracy : 83.721\n",
      "-- Epoch 50, Train Loss : 0.005674698390066624, Test Loss : 0.9009539484977722\n",
      "-- Epoch 100, Train Loss : 0.0012953232508152723, Test Loss : 1.080633521080017\n",
      "-- Epoch 150, Train Loss : 0.000567750888876617, Test Loss : 1.1878948211669922\n",
      "-- Epoch 200, Train Loss : 0.0003219851350877434, Test Loss : 1.2616221904754639\n",
      "-- Epoch 250, Train Loss : 0.00020792453869944438, Test Loss : 1.3187459707260132\n",
      "-- Epoch 300, Train Loss : 0.00014541050768457353, Test Loss : 1.3656219244003296\n",
      "-- Epoch 350, Train Loss : 9.576180673320778e-05, Test Loss : 1.4439955949783325\n",
      "-- Epoch 400, Train Loss : 6.774370740458835e-05, Test Loss : 1.5273714065551758\n",
      "-- Epoch 450, Train Loss : 5.2170946219121106e-05, Test Loss : 1.58513605594635\n",
      "-- Epoch 500, Train Loss : 4.166481267020572e-05, Test Loss : 1.6297764778137207\n",
      "-- Epoch 550, Train Loss : 3.4078476346621756e-05, Test Loss : 1.6665936708450317\n",
      "-- Epoch 600, Train Loss : 2.8372481210681144e-05, Test Loss : 1.6982457637786865\n",
      "-- Epoch 650, Train Loss : 2.3962432351254392e-05, Test Loss : 1.7261857986450195\n",
      "-- Epoch 700, Train Loss : 2.0480107195908204e-05, Test Loss : 1.751521110534668\n",
      "-- Epoch 750, Train Loss : 1.7662628124526236e-05, Test Loss : 1.774823784828186\n",
      "-- Epoch 800, Train Loss : 1.537127764095203e-05, Test Loss : 1.7964200973510742\n",
      "-- Epoch 850, Train Loss : 1.3475479136104695e-05, Test Loss : 1.8166276216506958\n",
      "-- Epoch 900, Train Loss : 1.1877656561409822e-05, Test Loss : 1.835688591003418\n",
      "-- Epoch 950, Train Loss : 1.0529119208513293e-05, Test Loss : 1.8533430099487305\n",
      "-- Epoch 1000, Train Loss : 9.38543439588102e-06, Test Loss : 1.8697887659072876\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 34.4 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([172])\n",
      "172 vs 172\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 77.273 %\n",
      "- Recall : 85.0 %\n",
      "- F1 : 0.80952\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 87.755 %\n",
      "- Recall : 91.489 %\n",
      "- F1 : 0.89583\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 88.372 %\n",
      "- Recall : 82.609 %\n",
      "- F1 : 0.85393\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 80.556 %\n",
      "- Recall : 74.359 %\n",
      "- F1 : 0.77333\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 83.721 %\n",
      "- Precision : 83.489 %\n",
      "- Recall : 83.364 %\n",
      "- F1 : 0.83426\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,false,,,true,,,unverified,,,non-rumor,,,\n",
      "Twitter16-Multi_4LayerNet_RoBERTa_Finetuned_with_TopTermsVectors Validation, 83.721, 83.489, 83.364, 0.83426, 77.273, 85.0, 0.80952, 87.755, 91.489, 0.89583, 88.372, 82.609, 0.85393, 80.556, 74.359, 0.77333, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([82])\n",
      "82 vs 82\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 75.0 %\n",
      "- Recall : 85.714 %\n",
      "- F1 : 0.8\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 85.714 %\n",
      "- Recall : 85.714 %\n",
      "- F1 : 0.85714\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 71.429 %\n",
      "- Recall : 78.947 %\n",
      "- F1 : 0.75\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 87.5 %\n",
      "- Recall : 66.667 %\n",
      "- F1 : 0.75676\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 79.268 %\n",
      "- Precision : 79.911 %\n",
      "- Recall : 79.261 %\n",
      "- F1 : 0.79585\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,false,,,true,,,unverified,,,non-rumor,,,\n",
      "Twitter16-Multi_4LayerNet_RoBERTa_Finetuned_with_TopTermsVectors Test, 79.268, 79.911, 79.261, 0.79585, 75.0, 85.714, 0.8, 85.714, 85.714, 0.85714, 71.429, 78.947, 0.75, 87.5, 66.667, 0.75676, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b4d368",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
