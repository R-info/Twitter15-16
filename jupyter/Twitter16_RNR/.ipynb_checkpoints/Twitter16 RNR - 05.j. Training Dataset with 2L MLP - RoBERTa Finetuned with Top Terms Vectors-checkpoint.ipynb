{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Twitter16-RNR\"\n",
    "unique_name = \"RoBERTa_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "terms_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(818, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter16-RNR_RoBERTa_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>656955120626880512</td>\n",
       "      <td>correct predictions in back to the future ii U...</td>\n",
       "      <td>false</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>615689290706595840</td>\n",
       "      <td>.@whitehouse in rainbow colors for #scotusmarr...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>613404935003217920</td>\n",
       "      <td>cops bought the alleged church shooter burger ...</td>\n",
       "      <td>false</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  656955120626880512  correct predictions in back to the future ii U...   \n",
       "1  615689290706595840  .@whitehouse in rainbow colors for #scotusmarr...   \n",
       "2  613404935003217920  cops bought the alleged church shooter burger ...   \n",
       "3  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "4  714598641827246081  an open letter to trump voters from his top st...   \n",
       "\n",
       "        label       tvt  cv_fold        tt        tvt2      tvt2_1    tvt2_2  \\\n",
       "0       false  training        1  training  validation    training  training   \n",
       "1        true  training        3  training    training  validation  training   \n",
       "2       false  training        2      test    training    training  training   \n",
       "3  unverified  training        3      test    training    training  training   \n",
       "4  unverified  training        1      test    training  validation  training   \n",
       "\n",
       "       tvt2_3  \n",
       "0  validation  \n",
       "1    training  \n",
       "2    training  \n",
       "3    training  \n",
       "4    training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter16_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rumour', 'non-rumour']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = ['rumour', 'non-rumour']\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [0], [0], [0], [0], [0], [0], [1], [1], [0]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "#     lab = labels_str.index(d['label'])\n",
    "    if d['label'] in ['true', 'false', 'unverified']:\n",
    "        lab = 0\n",
    "    else:\n",
    "        lab = 1\n",
    "    labels.append([lab])\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hostage situation', 'years ago', 'lindt cafe', '#opkkk #hoodsoff', 'el chapo', 'car dealership', '#charliehebdo attackers', \"what's the\", 'u s', 'from the']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_terms = []\n",
    "with open(\"../../data/processed/twitter16-rnr_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        vector_terms.append(t.strip())\n",
    "\n",
    "print(vector_terms[:10])\n",
    "len(vector_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2unigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(text)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def text2trigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    trigrams = nltk.trigrams(text)\n",
    "    trigrams = map(' '.join, trigrams)\n",
    "    trigrams = [bgr for bgr in trigrams]\n",
    "    \n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def bigrams_vectors_generation(texts):\n",
    "    bigram_vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(bigram_vector_base) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in bigram_vector_base:\n",
    "                idx = bigram_vector_base.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        bigram_vectors.append(init_vec)\n",
    "    \n",
    "    return bigram_vectors\n",
    "\n",
    "\n",
    "def custom_vectors_generation(texts, vector_terms):\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "        trigrams = text2trigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(vector_terms) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in vector_terms:\n",
    "                idx = vector_terms.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        for tgr in trigrams:\n",
    "            if tgr in vector_terms:\n",
    "                idx = vector_terms.index(tgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        vectors.append(init_vec)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(818, 1519)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "terms_vectors = custom_vectors_generation(texts, vector_terms)\n",
    "\n",
    "vectors = np.concatenate([vectors, terms_vectors], axis=1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(564, 1519)\n",
      "(172, 1519)\n",
      "(82, 1519)\n",
      "(564, 1)\n",
      "(172, 1)\n",
      "(82, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, n_output),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        binary: bool = False,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x, binary=binary)\n",
    "                if binary:\n",
    "                    preds = np.array([p[0] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([v[0] for v in test_y])\n",
    "                else:\n",
    "                    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y])\n",
    "                \n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=label_target,\n",
    "                    predictions=preds,\n",
    "                    binary=binary\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x, binary=False):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            \n",
    "            if binary:\n",
    "                return preds\n",
    "            else:\n",
    "                _, preds = torch.max(preds, dim = 1)\n",
    "                return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 85.465\n",
      "-- Epoch 50, Train Loss : 0.026722717098891735, Test Loss : 0.840453028678894\n",
      "-- Epoch 100, Train Loss : 0.025863364688120782, Test Loss : 0.9784480333328247\n",
      "-- Epoch 150, Train Loss : 0.025288689765147865, Test Loss : 1.047271490097046\n",
      "-- Epoch 200, Train Loss : 0.024367073900066316, Test Loss : 1.0829370021820068\n",
      "-- Epoch 250, Train Loss : 0.02309602894820273, Test Loss : 1.0969316959381104\n",
      "-- Epoch 300, Train Loss : 0.02146659337449819, Test Loss : 1.0881950855255127\n",
      "-- Epoch 350, Train Loss : 0.01977922406513244, Test Loss : 1.065572738647461\n",
      "-- Epoch 400, Train Loss : 0.018440329120494425, Test Loss : 1.037580132484436\n",
      "Saving after new best accuracy : 86.047\n",
      "-- Epoch 450, Train Loss : 0.016944785602390766, Test Loss : 1.0339657068252563\n",
      "-- Epoch 500, Train Loss : 0.015893380623310804, Test Loss : 1.0243146419525146\n",
      "-- Epoch 550, Train Loss : 0.014609699952416122, Test Loss : 1.030849814414978\n",
      "-- Epoch 600, Train Loss : 0.013283819775097072, Test Loss : 1.0459915399551392\n",
      "-- Epoch 650, Train Loss : 0.012258849805220962, Test Loss : 1.0534206628799438\n",
      "-- Epoch 700, Train Loss : 0.011114365886896849, Test Loss : 1.0794419050216675\n",
      "-- Epoch 750, Train Loss : 0.010704336920753121, Test Loss : 1.0855417251586914\n",
      "-- Epoch 800, Train Loss : 0.010640870954375714, Test Loss : 1.0969535112380981\n",
      "-- Epoch 850, Train Loss : 0.00950039509916678, Test Loss : 1.1242860555648804\n",
      "-- Epoch 900, Train Loss : 0.009750293305842206, Test Loss : 1.1297252178192139\n",
      "-- Epoch 950, Train Loss : 0.007251653325511143, Test Loss : 1.1508945226669312\n",
      "Saving after new best accuracy : 86.628\n",
      "-- Epoch 1000, Train Loss : 0.0072233270620927215, Test Loss : 1.197338342666626\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 14.38 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([172, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 30\n",
      "False Positive : 14\n",
      "False Negative : 9\n",
      "True Negative : 119\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 68.182 %\n",
      "- Recall : 76.923 %\n",
      "- F1 : 0.72289\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 92.969 %\n",
      "- Recall : 89.474 %\n",
      "- F1 : 0.91188\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 86.628 %\n",
      "- Precision : 80.575 %\n",
      "- Recall : 83.198 %\n",
      "- F1 : 0.81865\n",
      "- Average Confidence : 96.26 %\n",
      "Model, Combined,,,,non-rumour,,,rumour,,,\n",
      "Twitter16-RNR_2LMLP_RoBERTa_Finetuned_with_TopTermsVectors Validation, 86.628, 80.575, 83.198, 0.81865, 68.182, 76.923, 0.72289, 92.969, 89.474, 0.91188, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([82, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 15\n",
      "False Positive : 12\n",
      "False Negative : 6\n",
      "True Negative : 49\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 55.556 %\n",
      "- Recall : 71.429 %\n",
      "- F1 : 0.625\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 89.091 %\n",
      "- Recall : 80.328 %\n",
      "- F1 : 0.84483\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 78.049 %\n",
      "- Precision : 72.323 %\n",
      "- Recall : 75.878 %\n",
      "- F1 : 0.74058\n",
      "- Average Confidence : 95.81 %\n",
      "Model, Combined,,,,non-rumour,,,rumour,,,\n",
      "Twitter16-RNR_2LMLP_RoBERTa_Finetuned_with_TopTermsVectors Test, 78.049, 72.323, 75.878, 0.74058, 55.556, 71.429, 0.625, 89.091, 80.328, 0.84483, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "binary = True\n",
    "\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_2LMLP_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=1, criterion=nn.BCELoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                binary=binary,\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in val_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in test_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55461251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
