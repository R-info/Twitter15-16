{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Twitter15-RNR\"\n",
    "unique_name = \"RoBERTa_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "terms_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter15-RNR_RoBERTa_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>691809004356501505</td>\n",
       "      <td>america is a nation of second chances â€”@potus ...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693204708933160960</td>\n",
       "      <td>brandon marshall visits and offers advice, sup...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>551099691702956032</td>\n",
       "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "1  714598641827246081  an open letter to trump voters from his top st...   \n",
       "2  691809004356501505  america is a nation of second chances â€”@potus ...   \n",
       "3  693204708933160960  brandon marshall visits and offers advice, sup...   \n",
       "4  551099691702956032  rip elly may clampett: so sad to learn #beverl...   \n",
       "\n",
       "        label       tvt  cv_fold        tt        tvt2      tvt2_1  \\\n",
       "0  unverified  training        1  training    training  validation   \n",
       "1  unverified  training        1      test    training    testting   \n",
       "2   non-rumor  training        2  training  validation  validation   \n",
       "3   non-rumor  training        1  training    testting    testting   \n",
       "4        true  training        3  training  validation    training   \n",
       "\n",
       "       tvt2_2    tvt2_3  \n",
       "0    training  training  \n",
       "1    training  training  \n",
       "2  validation  testting  \n",
       "3    training  training  \n",
       "4  validation  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter15_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rumour', 'non-rumour']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = ['rumour', 'non-rumour']\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [0], [1], [1], [0], [1], [0], [0], [0], [0]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "#     lab = labels_str.index(d['label'])\n",
    "    if d['label'] in ['true', 'false', 'unverified']:\n",
    "        lab = 0\n",
    "    else:\n",
    "        lab = 1\n",
    "    labels.append([lab])\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"paul walker's\", 'us to', 'to watch', 'plan to', 'steps to', 'of the day', 'paul walker', 'want to', 'in ukraine', 'woman who']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_terms = []\n",
    "with open(\"../../data/processed/twitter15-rnr_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        vector_terms.append(t.strip())\n",
    "\n",
    "print(vector_terms[:10])\n",
    "len(vector_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2unigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(text)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def text2trigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    trigrams = nltk.trigrams(text)\n",
    "    trigrams = map(' '.join, trigrams)\n",
    "    trigrams = [bgr for bgr in trigrams]\n",
    "    \n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def bigrams_vectors_generation(texts):\n",
    "    bigram_vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(bigram_vector_base) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in bigram_vector_base:\n",
    "                idx = bigram_vector_base.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        bigram_vectors.append(init_vec)\n",
    "    \n",
    "    return bigram_vectors\n",
    "\n",
    "\n",
    "def custom_vectors_generation(texts, vector_terms):\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "        trigrams = text2trigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(vector_terms) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in vector_terms:\n",
    "                idx = vector_terms.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        for tgr in trigrams:\n",
    "            if tgr in vector_terms:\n",
    "                idx = vector_terms.index(tgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        vectors.append(init_vec)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 1519)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "terms_vectors = custom_vectors_generation(texts, vector_terms)\n",
    "\n",
    "vectors = np.concatenate([vectors, terms_vectors], axis=1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1004, 1519)\n",
      "(355, 1519)\n",
      "(131, 1519)\n",
      "(1004, 1)\n",
      "(355, 1)\n",
      "(131, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, n_output),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        binary: bool = False,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x, binary=binary)\n",
    "                if binary:\n",
    "                    preds = np.array([p[0] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([v[0] for v in test_y])\n",
    "                else:\n",
    "                    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y])\n",
    "                \n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=label_target,\n",
    "                    predictions=preds,\n",
    "                    binary=binary\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x, binary=False):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            \n",
    "            if binary:\n",
    "                return preds\n",
    "            else:\n",
    "                _, preds = torch.max(preds, dim = 1)\n",
    "                return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 85.07\n",
      "-- Epoch 50, Train Loss : 0.15780485421419144, Test Loss : 0.5509020090103149\n",
      "Saving after new best accuracy : 85.352\n",
      "Saving after new best accuracy : 85.634\n",
      "Saving after new best accuracy : 85.915\n",
      "-- Epoch 100, Train Loss : 0.13458043336868286, Test Loss : 0.49998119473457336\n",
      "Saving after new best accuracy : 86.197\n",
      "Saving after new best accuracy : 86.479\n",
      "-- Epoch 150, Train Loss : 0.07700925320386887, Test Loss : 0.5293693542480469\n",
      "Saving after new best accuracy : 86.761\n",
      "-- Epoch 200, Train Loss : 0.03504704311490059, Test Loss : 0.6659184694290161\n",
      "-- Epoch 250, Train Loss : 0.02199923899024725, Test Loss : 0.782473087310791\n",
      "-- Epoch 300, Train Loss : 0.015874773263931274, Test Loss : 0.870445966720581\n",
      "-- Epoch 350, Train Loss : 0.012338380794972181, Test Loss : 1.176885724067688\n",
      "-- Epoch 400, Train Loss : 0.010195286478847265, Test Loss : 1.2344794273376465\n",
      "-- Epoch 450, Train Loss : 0.008877408225089312, Test Loss : 1.9891494512557983\n",
      "-- Epoch 500, Train Loss : 0.008045885246247053, Test Loss : 2.024495840072632\n",
      "-- Epoch 550, Train Loss : 0.007478693267330527, Test Loss : 2.5308456420898438\n",
      "-- Epoch 600, Train Loss : 0.007062721531838179, Test Loss : 2.5621702671051025\n",
      "-- Epoch 650, Train Loss : 0.006744867656379938, Test Loss : 2.589470148086548\n",
      "-- Epoch 700, Train Loss : 0.006477245828136802, Test Loss : 2.6146795749664307\n",
      "-- Epoch 750, Train Loss : 0.0062376747373491526, Test Loss : 2.8738856315612793\n",
      "-- Epoch 800, Train Loss : 0.006018950953148305, Test Loss : 2.8947458267211914\n",
      "-- Epoch 850, Train Loss : 0.005805229186080396, Test Loss : 2.914109945297241\n",
      "-- Epoch 900, Train Loss : 0.005602633347734809, Test Loss : 2.938906669616699\n",
      "-- Epoch 950, Train Loss : 0.005418574204668403, Test Loss : 2.9723141193389893\n",
      "-- Epoch 1000, Train Loss : 0.0052104913629591465, Test Loss : 2.979598045349121\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 19.48 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([355, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 59\n",
      "False Positive : 19\n",
      "False Negative : 28\n",
      "True Negative : 249\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 75.641 %\n",
      "- Recall : 67.816 %\n",
      "- F1 : 0.71515\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 89.892 %\n",
      "- Recall : 92.91 %\n",
      "- F1 : 0.91376\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 86.761 %\n",
      "- Precision : 82.766 %\n",
      "- Recall : 80.363 %\n",
      "- F1 : 0.81547\n",
      "- Average Confidence : 93.36 %\n",
      "Model, Combined,,,,non-rumour,,,rumour,,,\n",
      "Twitter15-RNR_2LMLP_RoBERTa_Finetuned_with_TopTermsVectors Validation, 86.761, 82.766, 80.363, 0.81547, 75.641, 67.816, 0.71515, 89.892, 92.91, 0.91376, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([131, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 24\n",
      "False Positive : 2\n",
      "False Negative : 7\n",
      "True Negative : 98\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 92.308 %\n",
      "- Recall : 77.419 %\n",
      "- F1 : 0.84211\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 93.333 %\n",
      "- Recall : 98.0 %\n",
      "- F1 : 0.9561\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 93.13 %\n",
      "- Precision : 92.821 %\n",
      "- Recall : 87.71 %\n",
      "- F1 : 0.90193\n",
      "- Average Confidence : 93.24 %\n",
      "Model, Combined,,,,non-rumour,,,rumour,,,\n",
      "Twitter15-RNR_2LMLP_RoBERTa_Finetuned_with_TopTermsVectors Test, 93.13, 92.821, 87.71, 0.90193, 92.308, 77.419, 0.84211, 93.333, 98.0, 0.9561, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "binary = True\n",
    "\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_2LMLP_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=1, criterion=nn.BCELoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                binary=binary,\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in val_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in test_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55461251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
