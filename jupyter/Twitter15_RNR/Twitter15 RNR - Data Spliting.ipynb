{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a9b6fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1490, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>691809004356501505</td>\n",
       "      <td>america is a nation of second chances â€”@potus ...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693204708933160960</td>\n",
       "      <td>brandon marshall visits and offers advice, sup...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>551099691702956032</td>\n",
       "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "1  714598641827246081  an open letter to trump voters from his top st...   \n",
       "2  691809004356501505  america is a nation of second chances â€”@potus ...   \n",
       "3  693204708933160960  brandon marshall visits and offers advice, sup...   \n",
       "4  551099691702956032  rip elly may clampett: so sad to learn #beverl...   \n",
       "\n",
       "        label       tvt  cv_fold        tt        tvt2  \n",
       "0  unverified  training        1  training    testting  \n",
       "1  unverified  training        1      test    training  \n",
       "2   non-rumor  training        2  training  validation  \n",
       "3   non-rumor  training        1  training    training  \n",
       "4        true  training        3  training    testting  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"../../data/processed/twitter15_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38478d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1490"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = data.shape[0]\n",
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75afb59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights : 1000\n",
      "Training : 981 - 0.658\n",
      "Validation : 342 - 0.23\n",
      "Testing : 167 - 0.112\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# random.seed(37)\n",
    "\n",
    "train_w = [0 for i in range(675)]\n",
    "val_w = [1 for i in range(225)]\n",
    "test_w = [2 for i in range(100)]\n",
    "\n",
    "weights = train_w + val_w + test_w\n",
    "print(f\"weights : {len(weights)}\")\n",
    "\n",
    "tvt = []\n",
    "for i in range(length):\n",
    "    gacha = random.sample(weights, 1)[0]\n",
    "    if gacha == 0:\n",
    "        tvt.append(\"training\")\n",
    "    elif gacha == 1:\n",
    "        tvt.append(\"validation\")\n",
    "    else:\n",
    "        tvt.append(\"testting\")\n",
    "\n",
    "print(f\"Training : {tvt.count('training')} - {round(tvt.count('training')/length, 3)}\")\n",
    "print(f\"Validation : {tvt.count('validation')} - {round(tvt.count('validation')/length, 3)}\")\n",
    "print(f\"Testing : {tvt.count('testting')} - {round(tvt.count('testting')/length, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9463cc17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>691809004356501505</td>\n",
       "      <td>america is a nation of second chances â€”@potus ...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693204708933160960</td>\n",
       "      <td>brandon marshall visits and offers advice, sup...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>551099691702956032</td>\n",
       "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "1  714598641827246081  an open letter to trump voters from his top st...   \n",
       "2  691809004356501505  america is a nation of second chances â€”@potus ...   \n",
       "3  693204708933160960  brandon marshall visits and offers advice, sup...   \n",
       "4  551099691702956032  rip elly may clampett: so sad to learn #beverl...   \n",
       "\n",
       "        label       tvt  cv_fold        tt        tvt2  \n",
       "0  unverified  training        1  training    testting  \n",
       "1  unverified  training        1      test  validation  \n",
       "2   non-rumor  training        2  training    training  \n",
       "3   non-rumor  training        1  training    training  \n",
       "4        true  training        3  training  validation  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tvt2'] = pd.Series(tvt)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40803634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unverified    374\n",
       "non-rumor     374\n",
       "true          372\n",
       "false         370\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_count = data['label'].value_counts()\n",
    "label_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52bd5ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label,unverified,non-rumor,true,false\n",
      "Original\t0.25\t0.25\t0.25\t0.25\n",
      "Training\t0.24\t0.26\t0.24\t0.26\n",
      "Validation\t0.29\t0.24\t0.25\t0.23\n",
      "Testting\t0.25\t0.25\t0.28\t0.23\n",
      "\n",
      "Label,unverified,non-rumor,true,false\n",
      "Original\t374\t374\t372\t370\n",
      "Training\t234\t252\t240\t255\n",
      "Validation\t99\t81\t85\t77\n",
      "Testting\t41\t41\t47\t38\n"
     ]
    }
   ],
   "source": [
    "combination = data.apply(lambda row: f\"{row['label']}_{row['tvt2']}\", axis=1).value_counts()\n",
    "comparison = {}\n",
    "for k, comb in combination.items():\n",
    "    cv_fold = k.split(\"_\")[1]\n",
    "    label = k.split(\"_\")[0]\n",
    "\n",
    "    if cv_fold not in comparison:\n",
    "        comparison[cv_fold] = {}\n",
    "    \n",
    "    comparison[cv_fold][label] = comb\n",
    "\n",
    "labels = data['label'].unique().tolist()\n",
    "\n",
    "def label_ratio(label_dict, labels):\n",
    "    total = sum([v for k, v in label_dict.items()])\n",
    "    \n",
    "    report = \"\"\n",
    "    for l in labels:\n",
    "        report += f\"{round(label_dict[l]/total, 2)}\\t\"\n",
    "    \n",
    "    return report[:-1]\n",
    "\n",
    "def label_raw_value(label_dict, labels):\n",
    "    total = sum([v for k, v in label_dict.items()])\n",
    "    \n",
    "    report = \"\"\n",
    "    for l in labels:\n",
    "        report += f\"{label_dict[l]}\\t\"\n",
    "    \n",
    "    return report[:-1]\n",
    "\n",
    "labels_str = ','.join(labels)\n",
    "print(f\"\\nLabel,{labels_str}\")\n",
    "print(f\"Original\\t{label_ratio(label_count, labels)}\")\n",
    "for cv, comp in comparison.items():\n",
    "    print(f\"{cv.title()}\\t{label_ratio(comp, labels)}\")\n",
    "    \n",
    "labels_str = ','.join(labels)\n",
    "print(f\"\\nLabel,{labels_str}\")\n",
    "print(f\"Original\\t{label_raw_value(label_count, labels)}\")\n",
    "for cv, comp in comparison.items():\n",
    "    print(f\"{cv.title()}\\t{label_raw_value(comp, labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d80f19f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"../../data/processed/twitter15_dataset_with_tvt.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e3561b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
