{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# random.seed(33)\n",
    "\n",
    "dataset_name = \"Twitter15-TF\"\n",
    "unique_name = \"RoBERTa_Finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(742, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter15-TF_RoBERTa_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>551099691702956032</td>\n",
       "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
       "      <td>True</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>514106273852174337</td>\n",
       "      <td>just in: missing afghan soldiers found trying ...</td>\n",
       "      <td>True</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>495366618818830336</td>\n",
       "      <td>#riphulkhogan my heart is ripping like your sh...</td>\n",
       "      <td>False</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>532206910796468224</td>\n",
       "      <td>a chick-fil-a manager allegedly banned this hi...</td>\n",
       "      <td>False</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>560187970389819392</td>\n",
       "      <td>islamic tribunal using sharia law in texas has...</td>\n",
       "      <td>False</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  551099691702956032  rip elly may clampett: so sad to learn #beverl...   \n",
       "1  514106273852174337  just in: missing afghan soldiers found trying ...   \n",
       "2  495366618818830336  #riphulkhogan my heart is ripping like your sh...   \n",
       "3  532206910796468224  a chick-fil-a manager allegedly banned this hi...   \n",
       "4  560187970389819392  islamic tribunal using sharia law in texas has...   \n",
       "\n",
       "   label        tvt2  \n",
       "0   True    training  \n",
       "1   True    training  \n",
       "2  False    training  \n",
       "3  False    training  \n",
       "4  False  validation  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter15-tf_dataset.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = data['label'].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 1, 1, 1, 1, 0, 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d['label'])\n",
    "#     labels.append([1 if j == lab else 0 for j in range(len(labels_str))])\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(514, 768)\n",
      "(165, 768)\n",
      "(63, 768)\n",
      "(514,)\n",
      "(165,)\n",
      "(63,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, n_output),\n",
    "#             nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ce67903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from library.classification import SKLearnClassification\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "logres_model = LogisticRegression(random_state=0, solver='liblinear', multi_class='ovr', max_iter=10000)\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "svm = LinearSVC()\n",
    "\n",
    "models = [\n",
    "    SKLearnClassification(logres_model, \"Logistic Regression\"),\n",
    "    SKLearnClassification(neigh, \"K-Nearest Neighbor\"),\n",
    "    SKLearnClassification(svm, \"Support Vector Machine\"),\n",
    "]\n",
    "# for model in models:\n",
    "#     print(f\"\\n--- {model.model_name.upper()} ---\")\n",
    "#     model.train(train_vectors, train_labels, dataset_name)\n",
    "    \n",
    "#     print(\"Validation Set\")\n",
    "#     preds = model.predict(val_vectors)\n",
    "\n",
    "#     conf_mat = ConfusionMatrix(\n",
    "#         labels=val_labels,\n",
    "#         predictions=preds,\n",
    "#         binary=True\n",
    "#     )\n",
    "#     conf_mat.evaluate()\n",
    "    \n",
    "#     print(\"Test Set\")\n",
    "#     preds = model.predict(test_vectors)\n",
    "\n",
    "#     conf_mat = ConfusionMatrix(\n",
    "#         labels=test_labels,\n",
    "#         predictions=preds,\n",
    "#         binary=False\n",
    "#     )\n",
    "#     conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "#     print(\"--- END ---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd07cc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 89.091\n",
      "Saving after new best accuracy : 92.727\n",
      "Saving after new best accuracy : 93.333\n",
      "-- Epoch 50, Train Loss : 0.000610194358159788, Test Loss : 0.4599166810512543\n",
      "-- Epoch 100, Train Loss : 0.00014126345195109025, Test Loss : 0.5221102237701416\n",
      "-- Epoch 150, Train Loss : 6.148136526462622e-05, Test Loss : 0.5589112043380737\n",
      "-- Epoch 200, Train Loss : 3.41839704560698e-05, Test Loss : 0.5853528380393982\n",
      "-- Epoch 250, Train Loss : 2.1780533643322997e-05, Test Loss : 0.6060270071029663\n",
      "-- Epoch 300, Train Loss : 1.5007740330474917e-05, Test Loss : 0.6230989098548889\n",
      "-- Epoch 350, Train Loss : 1.090934074454708e-05, Test Loss : 0.6376662254333496\n",
      "-- Epoch 400, Train Loss : 8.29704390525876e-06, Test Loss : 0.6504662036895752\n",
      "-- Epoch 450, Train Loss : 6.51848608868022e-06, Test Loss : 0.6618403196334839\n",
      "-- Epoch 500, Train Loss : 5.277055493024818e-06, Test Loss : 0.67223060131073\n",
      "-- Epoch 550, Train Loss : 4.291730419936357e-06, Test Loss : 0.6817405819892883\n",
      "-- Epoch 600, Train Loss : 3.5802097499981755e-06, Test Loss : 0.6905853748321533\n",
      "-- Epoch 650, Train Loss : 2.927359219029313e-06, Test Loss : 0.6988950371742249\n",
      "-- Epoch 700, Train Loss : 2.539467914175475e-06, Test Loss : 0.7064639329910278\n",
      "-- Epoch 750, Train Loss : 2.216535449406365e-06, Test Loss : 0.7136052846908569\n",
      "-- Epoch 800, Train Loss : 1.943427491823968e-06, Test Loss : 0.7206268906593323\n",
      "-- Epoch 850, Train Loss : 1.7026828800226212e-06, Test Loss : 0.7272843718528748\n",
      "-- Epoch 900, Train Loss : 1.4246845125853724e-06, Test Loss : 0.7337021231651306\n",
      "-- Epoch 950, Train Loss : 1.3015181252740149e-06, Test Loss : 0.7395229935646057\n",
      "-- Epoch 1000, Train Loss : 1.1315525796362635e-06, Test Loss : 0.7453094720840454\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 28.13 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([165])\n",
      "165 vs 165\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class True Evaluation\n",
      "- Precision : 89.362 %\n",
      "- Recall : 98.824 %\n",
      "- F1 : 0.93855\n",
      "\n",
      "Class False Evaluation\n",
      "- Precision : 98.592 %\n",
      "- Recall : 87.5 %\n",
      "- F1 : 0.92715\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 93.333 %\n",
      "- Precision : 93.977 %\n",
      "- Recall : 93.162 %\n",
      "- F1 : 0.93568\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,True,,,False,,,\n",
      "Twitter15-TF_4LayerNet_RoBERTa_Finetuned Validation, 93.333, 93.977, 93.162, 0.93568, 89.362, 98.824, 0.93855, 98.592, 87.5, 0.92715, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([63])\n",
      "63 vs 63\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class True Evaluation\n",
      "- Precision : 93.75 %\n",
      "- Recall : 100.0 %\n",
      "- F1 : 0.96774\n",
      "\n",
      "Class False Evaluation\n",
      "- Precision : 100.0 %\n",
      "- Recall : 93.939 %\n",
      "- F1 : 0.96875\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 96.825 %\n",
      "- Precision : 96.875 %\n",
      "- Recall : 96.97 %\n",
      "- F1 : 0.96922\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,True,,,False,,,\n",
      "Twitter15-TF_4LayerNet_RoBERTa_Finetuned Test, 96.825, 96.875, 96.97, 0.96922, 93.75, 100.0, 0.96774, 100.0, 93.939, 0.96875, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=2, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55461251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
