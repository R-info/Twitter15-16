{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "random.seed(33)\n",
    "\n",
    "unique_name = \"RoBERTa_Finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(818, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter16_RoBERTa_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>656955120626880512</td>\n",
       "      <td>correct predictions in back to the future ii U...</td>\n",
       "      <td>false</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>615689290706595840</td>\n",
       "      <td>.@whitehouse in rainbow colors for #scotusmarr...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>613404935003217920</td>\n",
       "      <td>cops bought the alleged church shooter burger ...</td>\n",
       "      <td>false</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  656955120626880512  correct predictions in back to the future ii U...   \n",
       "1  615689290706595840  .@whitehouse in rainbow colors for #scotusmarr...   \n",
       "2  613404935003217920  cops bought the alleged church shooter burger ...   \n",
       "3  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "4  714598641827246081  an open letter to trump voters from his top st...   \n",
       "\n",
       "        label       tvt  cv_fold        tt        tvt2  \n",
       "0       false  training        1  training  validation  \n",
       "1        true  training        3  training    training  \n",
       "2       false  training        2      test    training  \n",
       "3  unverified  training        3      test    training  \n",
       "4  unverified  training        1      test    training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter16_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['false', 'true', 'unverified', 'non-rumor']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = data['label'].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 2, 2, 1, 2, 3, 3, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d['label'])\n",
    "#     labels.append([1 if j == lab else 0 for j in range(len(labels_str))])\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(531, 768)\n",
      "(185, 768)\n",
      "(102, 768)\n",
      "(531,)\n",
      "(185,)\n",
      "(102,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, n_output),\n",
    "#             nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ce67903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from library.classification import SKLearnClassification\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Twitter16\"\n",
    "\n",
    "logres_model = LogisticRegression(random_state=0, solver='liblinear', multi_class='ovr', max_iter=10000)\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "svm = LinearSVC()\n",
    "\n",
    "models = [\n",
    "    SKLearnClassification(logres_model, \"Logistic Regression\"),\n",
    "    SKLearnClassification(neigh, \"K-Nearest Neighbor\"),\n",
    "    SKLearnClassification(svm, \"Support Vector Machine\"),\n",
    "]\n",
    "# for model in models:\n",
    "#     print(f\"\\n--- {model.model_name.upper()} ---\")\n",
    "#     model.train(train_vectors, train_labels, dataset_name)\n",
    "    \n",
    "#     print(\"Validation Set\")\n",
    "#     preds = model.predict(val_vectors)\n",
    "\n",
    "#     conf_mat = ConfusionMatrix(\n",
    "#         labels=val_labels,\n",
    "#         predictions=preds,\n",
    "#         binary=True\n",
    "#     )\n",
    "#     conf_mat.evaluate()\n",
    "    \n",
    "#     print(\"Test Set\")\n",
    "#     preds = model.predict(test_vectors)\n",
    "\n",
    "#     conf_mat = ConfusionMatrix(\n",
    "#         labels=test_labels,\n",
    "#         predictions=preds,\n",
    "#         binary=False\n",
    "#     )\n",
    "#     conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "#     print(\"--- END ---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd07cc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 39.459\n",
      "Saving after new best accuracy : 75.135\n",
      "Saving after new best accuracy : 80.0\n",
      "Saving after new best accuracy : 81.081\n",
      "Saving after new best accuracy : 81.622\n",
      "Saving after new best accuracy : 82.162\n",
      "Saving after new best accuracy : 82.703\n",
      "Saving after new best accuracy : 83.243\n",
      "Saving after new best accuracy : 83.784\n",
      "-- Epoch 50, Train Loss : 0.0009198821499012411, Test Loss : 0.9133590459823608\n",
      "-- Epoch 100, Train Loss : 0.00021419808763312176, Test Loss : 1.0537985563278198\n",
      "-- Epoch 150, Train Loss : 9.459590000915341e-05, Test Loss : 1.1346827745437622\n",
      "-- Epoch 200, Train Loss : 5.301004603097681e-05, Test Loss : 1.1923866271972656\n",
      "-- Epoch 250, Train Loss : 3.393469614820788e-05, Test Loss : 1.237244963645935\n",
      "-- Epoch 300, Train Loss : 2.3496628273278475e-05, Test Loss : 1.274609923362732\n",
      "-- Epoch 350, Train Loss : 1.7177380868815817e-05, Test Loss : 1.3066402673721313\n",
      "-- Epoch 400, Train Loss : 1.3098052022542106e-05, Test Loss : 1.3344632387161255\n",
      "-- Epoch 450, Train Loss : 1.0307368484063772e-05, Test Loss : 1.3591138124465942\n",
      "-- Epoch 500, Train Loss : 8.30236854199029e-06, Test Loss : 1.3813095092773438\n",
      "-- Epoch 550, Train Loss : 6.807090358051937e-06, Test Loss : 1.4015811681747437\n",
      "-- Epoch 600, Train Loss : 5.731013970944332e-06, Test Loss : 1.4202433824539185\n",
      "-- Epoch 650, Train Loss : 4.83762255498732e-06, Test Loss : 1.437549352645874\n",
      "-- Epoch 700, Train Loss : 4.1498924474581145e-06, Test Loss : 1.4537509679794312\n",
      "-- Epoch 750, Train Loss : 3.5498899251251714e-06, Test Loss : 1.4689573049545288\n",
      "-- Epoch 800, Train Loss : 3.0857371484671603e-06, Test Loss : 1.4834040403366089\n",
      "-- Epoch 850, Train Loss : 2.742312972259242e-06, Test Loss : 1.4971600770950317\n",
      "-- Epoch 900, Train Loss : 2.3652260665585345e-06, Test Loss : 1.5103107690811157\n",
      "-- Epoch 950, Train Loss : 2.103929489294387e-06, Test Loss : 1.522783875465393\n",
      "-- Epoch 1000, Train Loss : 1.9033523130929098e-06, Test Loss : 1.534895658493042\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 31.73 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([185])\n",
      "185 vs 185\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 90.909 %\n",
      "- Recall : 78.431 %\n",
      "- F1 : 0.84211\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 91.667 %\n",
      "- Recall : 94.286 %\n",
      "- F1 : 0.92958\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 80.851 %\n",
      "- Recall : 77.551 %\n",
      "- F1 : 0.79167\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 75.862 %\n",
      "- Recall : 88.0 %\n",
      "- F1 : 0.81481\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 83.784 %\n",
      "- Precision : 84.822 %\n",
      "- Recall : 84.567 %\n",
      "- F1 : 0.84694\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,false,,,true,,,unverified,,,non-rumor,,,\n",
      "Twitter16_4LayerNet_RoBERTa_Finetuned Validation, 83.784, 84.822, 84.567, 0.84694, 90.909, 78.431, 0.84211, 91.667, 94.286, 0.92958, 80.851, 77.551, 0.79167, 75.862, 88.0, 0.81481, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([102])\n",
      "102 vs 102\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 91.667 %\n",
      "- Recall : 81.481 %\n",
      "- F1 : 0.86275\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 88.462 %\n",
      "- Recall : 88.462 %\n",
      "- F1 : 0.88462\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 90.909 %\n",
      "- Recall : 80.0 %\n",
      "- F1 : 0.85106\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 66.667 %\n",
      "- Recall : 83.333 %\n",
      "- F1 : 0.74074\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 83.333 %\n",
      "- Precision : 84.426 %\n",
      "- Recall : 83.319 %\n",
      "- F1 : 0.83869\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,false,,,true,,,unverified,,,non-rumor,,,\n",
      "Twitter16_4LayerNet_RoBERTa_Finetuned Test, 83.333, 84.426, 83.319, 0.83869, 91.667, 81.481, 0.86275, 88.462, 88.462, 0.88462, 90.909, 80.0, 0.85106, 66.667, 83.333, 0.74074, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "start = time.time()\n",
    "model_name = f\"Twitter16_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55461251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
