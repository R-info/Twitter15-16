{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "random.seed(33)\n",
    "\n",
    "unique_name = \"DistilBERT_Finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter15_DistilBERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>691809004356501505</td>\n",
       "      <td>america is a nation of second chances â€”@potus ...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693204708933160960</td>\n",
       "      <td>brandon marshall visits and offers advice, sup...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>551099691702956032</td>\n",
       "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "1  714598641827246081  an open letter to trump voters from his top st...   \n",
       "2  691809004356501505  america is a nation of second chances â€”@potus ...   \n",
       "3  693204708933160960  brandon marshall visits and offers advice, sup...   \n",
       "4  551099691702956032  rip elly may clampett: so sad to learn #beverl...   \n",
       "\n",
       "        label       tvt  cv_fold        tt      tvt2  \n",
       "0  unverified  training        1  training  training  \n",
       "1  unverified  training        1      test  training  \n",
       "2   non-rumor  training        2  training  training  \n",
       "3   non-rumor  training        1  training  testting  \n",
       "4        true  training        3  training  testting  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter15_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unverified', 'non-rumor', 'true', 'false']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = data['label'].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 2, 1, 0, 2, 0, 3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d['label'])\n",
    "#     labels.append([1 if j == lab else 0 for j in range(len(labels_str))])\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1017, 768)\n",
      "(328, 768)\n",
      "(145, 768)\n",
      "(1017,)\n",
      "(328,)\n",
      "(145,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, n_output),\n",
    "#             nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ce67903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from library.classification import SKLearnClassification\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Twitter15\"\n",
    "\n",
    "logres_model = LogisticRegression(random_state=0, solver='liblinear', multi_class='ovr', max_iter=10000)\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "svm = LinearSVC()\n",
    "\n",
    "models = [\n",
    "    SKLearnClassification(logres_model, \"Logistic Regression\"),\n",
    "    SKLearnClassification(neigh, \"K-Nearest Neighbor\"),\n",
    "    SKLearnClassification(svm, \"Support Vector Machine\"),\n",
    "]\n",
    "# for model in models:\n",
    "#     print(f\"\\n--- {model.model_name.upper()} ---\")\n",
    "#     model.train(train_vectors, train_labels, dataset_name)\n",
    "    \n",
    "#     print(\"Validation Set\")\n",
    "#     preds = model.predict(val_vectors)\n",
    "\n",
    "#     conf_mat = ConfusionMatrix(\n",
    "#         labels=val_labels,\n",
    "#         predictions=preds,\n",
    "#         binary=True\n",
    "#     )\n",
    "#     conf_mat.evaluate()\n",
    "    \n",
    "#     print(\"Test Set\")\n",
    "#     preds = model.predict(test_vectors)\n",
    "\n",
    "#     conf_mat = ConfusionMatrix(\n",
    "#         labels=test_labels,\n",
    "#         predictions=preds,\n",
    "#         binary=False\n",
    "#     )\n",
    "#     conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "#     print(\"--- END ---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd07cc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 52.439\n",
      "Saving after new best accuracy : 58.232\n",
      "Saving after new best accuracy : 76.22\n",
      "Saving after new best accuracy : 77.439\n",
      "Saving after new best accuracy : 78.049\n",
      "-- Epoch 50, Train Loss : 0.0007251840434037149, Test Loss : 1.1367998123168945\n",
      "-- Epoch 100, Train Loss : 0.0001755126504576765, Test Loss : 1.2970417737960815\n",
      "-- Epoch 150, Train Loss : 7.863829523557797e-05, Test Loss : 1.3904744386672974\n",
      "-- Epoch 200, Train Loss : 4.45232362835668e-05, Test Loss : 1.4574774503707886\n",
      "-- Epoch 250, Train Loss : 2.864014186343411e-05, Test Loss : 1.5097967386245728\n",
      "-- Epoch 300, Train Loss : 1.997273284359835e-05, Test Loss : 1.5528969764709473\n",
      "-- Epoch 350, Train Loss : 1.4717909834871534e-05, Test Loss : 1.589699149131775\n",
      "-- Epoch 400, Train Loss : 1.1282496870990144e-05, Test Loss : 1.6219491958618164\n",
      "-- Epoch 450, Train Loss : 8.90655564944609e-06, Test Loss : 1.650753140449524\n",
      "-- Epoch 500, Train Loss : 7.192432804004056e-06, Test Loss : 1.6768301725387573\n",
      "-- Epoch 550, Train Loss : 5.907433205720736e-06, Test Loss : 1.7007176876068115\n",
      "-- Epoch 600, Train Loss : 4.940507324135979e-06, Test Loss : 1.72272527217865\n",
      "-- Epoch 650, Train Loss : 4.1780865558394e-06, Test Loss : 1.7432833909988403\n",
      "-- Epoch 700, Train Loss : 3.5718388744498952e-06, Test Loss : 1.762587547302246\n",
      "-- Epoch 750, Train Loss : 3.0714531931153033e-06, Test Loss : 1.7808005809783936\n",
      "-- Epoch 800, Train Loss : 2.6664887400329462e-06, Test Loss : 1.7980718612670898\n",
      "-- Epoch 850, Train Loss : 2.3393322408082895e-06, Test Loss : 1.8144720792770386\n",
      "-- Epoch 900, Train Loss : 2.0754227989527863e-06, Test Loss : 1.8301670551300049\n",
      "-- Epoch 950, Train Loss : 1.8518306319492694e-06, Test Loss : 1.845244288444519\n",
      "-- Epoch 1000, Train Loss : 1.6582561102040927e-06, Test Loss : 1.8597843647003174\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 40.36 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([328])\n",
      "328 vs 328\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 71.429 %\n",
      "- Recall : 77.381 %\n",
      "- F1 : 0.74286\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 78.049 %\n",
      "- Recall : 74.419 %\n",
      "- F1 : 0.7619\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 83.544 %\n",
      "- Recall : 83.544 %\n",
      "- F1 : 0.83544\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 80.263 %\n",
      "- Recall : 77.215 %\n",
      "- F1 : 0.7871\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 78.049 %\n",
      "- Precision : 78.321 %\n",
      "- Recall : 78.14 %\n",
      "- F1 : 0.7823\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Twitter15_4LayerNet_DistilBERT_Finetuned Validation, 78.049, 78.321, 78.14, 0.7823, 71.429, 77.381, 0.74286, 78.049, 74.419, 0.7619, 83.544, 83.544, 0.83544, 80.263, 77.215, 0.7871, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([145])\n",
      "145 vs 145\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 61.905 %\n",
      "- Recall : 74.286 %\n",
      "- F1 : 0.67532\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 69.444 %\n",
      "- Recall : 65.789 %\n",
      "- F1 : 0.67568\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 83.333 %\n",
      "- Recall : 83.333 %\n",
      "- F1 : 0.83333\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 70.968 %\n",
      "- Recall : 61.111 %\n",
      "- F1 : 0.65672\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 71.034 %\n",
      "- Precision : 71.413 %\n",
      "- Recall : 71.13 %\n",
      "- F1 : 0.71271\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Twitter15_4LayerNet_DistilBERT_Finetuned Test, 71.034, 71.413, 71.13, 0.71271, 61.905, 74.286, 0.67532, 69.444, 65.789, 0.67568, 83.333, 83.333, 0.83333, 70.968, 61.111, 0.65672, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "start = time.time()\n",
    "model_name = f\"Twitter15_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55461251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
