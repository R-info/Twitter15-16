{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feff3561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8a6e983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>691809004356501505</td>\n",
       "      <td>america is a nation of second chances â€”@potus ...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693204708933160960</td>\n",
       "      <td>brandon marshall visits and offers advice, sup...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>551099691702956032</td>\n",
       "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "1  714598641827246081  an open letter to trump voters from his top st...   \n",
       "2  691809004356501505  america is a nation of second chances â€”@potus ...   \n",
       "3  693204708933160960  brandon marshall visits and offers advice, sup...   \n",
       "4  551099691702956032  rip elly may clampett: so sad to learn #beverl...   \n",
       "\n",
       "        label       tvt  cv_fold        tt        tvt2  \n",
       "0  unverified  training        1  training    training  \n",
       "1  unverified  training        1      test    testting  \n",
       "2   non-rumor  training        2  training    training  \n",
       "3   non-rumor  training        1  training  validation  \n",
       "4        true  training        3  training    training  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter15_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af92ba46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>unverified</th>\n",
       "      <th>non-rumor</th>\n",
       "      <th>true</th>\n",
       "      <th>false</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca kkk</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kkk grand</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grand wizard</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wizard endorses</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>endorses @hillaryclinton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      token  unverified  non-rumor  true  false\n",
       "0                    ca kkk           1          0     0      0\n",
       "1                 kkk grand           1          0     0      0\n",
       "2              grand wizard           1          0     0      0\n",
       "3           wizard endorses           1          0     0      0\n",
       "4  endorses @hillaryclinton           1          0     0      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_data = pd.read_excel('../../data/processed/twitter15_ngram_distribution.xlsx', sheet_name='bigram')\n",
    "bigram_data.columns = [\"token\", \"unverified\", \"non-rumor\", \"true\", \"false\"]\n",
    "bigram_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d048e008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'to trump'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vector_base = bigram_data['token'].tolist()\n",
    "print(len(bigram_vector_base))\n",
    "bigram_vector_base[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63153167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>label_rnr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>testting</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>691809004356501505</td>\n",
       "      <td>america is a nation of second chances â€”@potus ...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>non-rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693204708933160960</td>\n",
       "      <td>brandon marshall visits and offers advice, sup...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>non-rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>551099691702956032</td>\n",
       "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "1  714598641827246081  an open letter to trump voters from his top st...   \n",
       "2  691809004356501505  america is a nation of second chances â€”@potus ...   \n",
       "3  693204708933160960  brandon marshall visits and offers advice, sup...   \n",
       "4  551099691702956032  rip elly may clampett: so sad to learn #beverl...   \n",
       "\n",
       "        label       tvt  cv_fold        tt        tvt2    label_rnr  \n",
       "0  unverified  training        1  training    training      rumours  \n",
       "1  unverified  training        1      test    testting      rumours  \n",
       "2   non-rumor  training        2  training    training  non-rumours  \n",
       "3   non-rumor  training        1  training  validation  non-rumours  \n",
       "4        true  training        3  training    training      rumours  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_rnr = []\n",
    "for i, d in data.iterrows():\n",
    "    if d['label'] == \"non-rumor\":\n",
    "        label_rnr.append(\"non-rumours\")\n",
    "    else:\n",
    "        label_rnr.append(\"rumours\")\n",
    "        \n",
    "data['label_rnr'] = pd.Series(label_rnr)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b95fb4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unverified', 'non-rumor', 'true', 'false']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = data['label'].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6ce7b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 0, 0],\n",
       " [1, 0, 0, 0],\n",
       " [0, 1, 0, 0],\n",
       " [0, 1, 0, 0],\n",
       " [0, 0, 1, 0],\n",
       " [0, 1, 0, 0],\n",
       " [1, 0, 0, 0],\n",
       " [0, 0, 1, 0],\n",
       " [1, 0, 0, 0],\n",
       " [0, 0, 0, 1]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d['label'])\n",
    "    labs = [1 if idx == lab else 0 for idx in range(len(labels_str))]\n",
    "    labels.append(labs)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fc83a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "def text2bigrams(text):\n",
    "    bigrams = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    bigrams = [t for t in bigrams if t not in string.punctuation]\n",
    "    bigrams = [t for t in bigrams if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(bigrams)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def bigrams_vectors_generation(texts):\n",
    "    bigram_vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(bigram_vector_base) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in bigram_vector_base:\n",
    "                idx = bigram_vector_base.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        bigram_vectors.append(init_vec)\n",
    "    \n",
    "    return bigram_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97281e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 13843)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "vectors = bigrams_vectors_generation(texts)\n",
    "vectors = np.array(vectors)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "189f900d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ca kkk', 'kkk grand', 'grand wizard', 'wizard endorses', 'endorses @hillaryclinton', '@hillaryclinton #neverhillary', '#neverhillary #trump2016'], ['an open', 'open letter', 'letter to', 'to trump', 'trump voters', 'voters from', 'from his', 'his top', 'top strategist-turned-defector', 'strategist-turned-defector via', 'via @xojanedotcom'], ['america is', 'is a', 'a nation', 'nation of', 'of second', 'second chances', 'chances @potus', '@potus on', 'on new', 'new reforms', 'reforms to', 'to solitary', 'solitary confinement'], ['brandon marshall', 'marshall visits', 'visits and', 'and offers', 'offers advice', 'advice support', 'support to', 'to brother', 'brother of', 'of fallen', 'fallen hero', 'hero zaevion', 'zaevion dobson'], ['rip elly', 'elly may', 'may clampett', 'clampett so', 'so sad', 'sad to', 'to learn', 'learn #beverlyhillbillies', '#beverlyhillbillies star', 'star donna', 'donna douglas', 'douglas has', 'has passed', 'passed away']]\n",
      "(1490, 13842)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/storage/Work/DataScience/.venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "raw_texts = data['tweet_text'].tolist()\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "texts = [tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8')) for text in raw_texts]\n",
    "texts = [[t for t in text if t not in string.punctuation] for text in texts]\n",
    "texts = [[t for t in text if t not in ['URL', 'â€˜', 'â€™']] for text in texts]\n",
    "\n",
    "tokens = []\n",
    "\n",
    "for i, text in enumerate(texts):\n",
    "    bigrms = nltk.bigrams(text)\n",
    "    bigrms = map(' '.join, bigrms)\n",
    "    bigrms = [b for b in bigrms]\n",
    "    tokens.append(bigrms)\n",
    "print(tokens[:5])\n",
    "    \n",
    "corpus = tokens\n",
    "\n",
    "def identity_tokenizer(text):\n",
    "    return text\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=identity_tokenizer, stop_words=\"english\", lowercase=False)\n",
    "vectors = vectorizer.fit_transform(corpus)\n",
    "vectors = vectors.toarray()\n",
    "print(vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cccd2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f3f387c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RANDOM FOREST ---\n",
      "---> execution time : 5.92 seconds\n",
      "Validation Set\n",
      "328 vs 328\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 64.516 %\n",
      "- Recall : 24.39 %\n",
      "- F1 : 0.35398\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 35.747 %\n",
      "- Recall : 97.531 %\n",
      "- F1 : 0.52318\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 100.0 %\n",
      "- Recall : 62.353 %\n",
      "- F1 : 0.76812\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 95.652 %\n",
      "- Recall : 27.5 %\n",
      "- F1 : 0.42718\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 53.049 %\n",
      "- Precision : 73.979 %\n",
      "- Recall : 52.944 %\n",
      "- F1 : 0.61718\n",
      "\n",
      "- Average Confidence : 95.73 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Anonymous, 53.049, 73.979, 52.944, 0.61718, 64.516, 24.39, 0.35398, 35.747, 97.531, 0.52318, 100.0, 62.353, 0.76812, 95.652, 27.5, 0.42718, \n",
      "Test Set\n",
      "175 vs 175\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 83.333 %\n",
      "- Recall : 42.553 %\n",
      "- F1 : 0.56338\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 38.596 %\n",
      "- Recall : 97.778 %\n",
      "- F1 : 0.55346\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 100.0 %\n",
      "- Recall : 62.5 %\n",
      "- F1 : 0.76923\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 100.0 %\n",
      "- Recall : 27.907 %\n",
      "- F1 : 0.43636\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 57.714 %\n",
      "- Precision : 80.482 %\n",
      "- Recall : 57.684 %\n",
      "- F1 : 0.67202\n",
      "\n",
      "- Average Confidence : 96.0 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Anonymous, 57.714, 80.482, 57.684, 0.67202, 83.333, 42.553, 0.56338, 38.596, 97.778, 0.55346, 100.0, 62.5, 0.76923, 100.0, 27.907, 0.43636, \n",
      "--- END ---\n",
      "\n",
      "\n",
      "--- K-NEAREST NEIGHBOR ---\n",
      "---> execution time : 0.01 seconds\n",
      "Validation Set\n",
      "328 vs 328\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 43.827 %\n",
      "- Recall : 86.585 %\n",
      "- F1 : 0.58197\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 48.214 %\n",
      "- Recall : 33.333 %\n",
      "- F1 : 0.39416\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 92.647 %\n",
      "- Recall : 74.118 %\n",
      "- F1 : 0.82353\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 88.095 %\n",
      "- Recall : 46.25 %\n",
      "- F1 : 0.60656\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 60.366 %\n",
      "- Precision : 68.196 %\n",
      "- Recall : 60.072 %\n",
      "- F1 : 0.63877\n",
      "\n",
      "- Average Confidence : 69.21 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Anonymous, 60.366, 68.196, 60.072, 0.63877, 43.827, 86.585, 0.58197, 48.214, 33.333, 0.39416, 92.647, 74.118, 0.82353, 88.095, 46.25, 0.60656, \n",
      "Test Set\n",
      "175 vs 175\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 39.286 %\n",
      "- Recall : 70.213 %\n",
      "- F1 : 0.50382\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 40.0 %\n",
      "- Recall : 31.111 %\n",
      "- F1 : 0.35\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 81.081 %\n",
      "- Recall : 75.0 %\n",
      "- F1 : 0.77922\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 89.474 %\n",
      "- Recall : 39.535 %\n",
      "- F1 : 0.54839\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 53.714 %\n",
      "- Precision : 62.46 %\n",
      "- Recall : 53.965 %\n",
      "- F1 : 0.57903\n",
      "\n",
      "- Average Confidence : 74.86 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Anonymous, 53.714, 62.46, 53.965, 0.57903, 39.286, 70.213, 0.50382, 40.0, 31.111, 0.35, 81.081, 75.0, 0.77922, 89.474, 39.535, 0.54839, \n",
      "--- END ---\n",
      "\n",
      "\n",
      "--- SUPPORT VECTOR MACHINE ---\n",
      "---> execution time : 0.08 seconds\n",
      "Validation Set\n",
      "328 vs 328\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 84.848 %\n",
      "- Recall : 68.293 %\n",
      "- F1 : 0.75676\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 53.383 %\n",
      "- Recall : 87.654 %\n",
      "- F1 : 0.66355\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 94.366 %\n",
      "- Recall : 78.824 %\n",
      "- F1 : 0.85897\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 87.931 %\n",
      "- Recall : 63.75 %\n",
      "- F1 : 0.73913\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 74.695 %\n",
      "- Precision : 80.132 %\n",
      "- Recall : 74.63 %\n",
      "- F1 : 0.77283\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Anonymous, 74.695, 80.132, 74.63, 0.77283, 84.848, 68.293, 0.75676, 53.383, 87.654, 0.66355, 94.366, 78.824, 0.85897, 87.931, 63.75, 0.73913, \n",
      "Test Set\n",
      "175 vs 175\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 74.359 %\n",
      "- Recall : 61.702 %\n",
      "- F1 : 0.67442\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 54.412 %\n",
      "- Recall : 82.222 %\n",
      "- F1 : 0.65487\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 91.667 %\n",
      "- Recall : 82.5 %\n",
      "- F1 : 0.86842\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 81.25 %\n",
      "- Recall : 60.465 %\n",
      "- F1 : 0.69333\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 71.429 %\n",
      "- Precision : 75.422 %\n",
      "- Recall : 71.722 %\n",
      "- F1 : 0.73525\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Anonymous, 71.429, 75.422, 71.722, 0.73525, 74.359, 61.702, 0.67442, 54.412, 82.222, 0.65487, 91.667, 82.5, 0.86842, 81.25, 60.465, 0.69333, \n",
      "--- END ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from library.classification import SKLearnClassification\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Phemernr\"\n",
    "\n",
    "random_forest = RandomForestClassifier(class_weight=\"balanced\")\n",
    "neigh = KNeighborsClassifier(n_neighbors=5, weights=\"distance\")\n",
    "svm = LinearSVC(class_weight=\"balanced\")\n",
    "\n",
    "models = [\n",
    "    SKLearnClassification(random_forest, \"Random Forest\"),\n",
    "    SKLearnClassification(neigh, \"K-Nearest Neighbor\"),\n",
    "    SKLearnClassification(svm, \"Support Vector Machine\"),\n",
    "]\n",
    "for model in models:\n",
    "    print(f\"\\n--- {model.model_name.upper()} ---\")\n",
    "    if model.model_name == \"Support Vector Machine\":\n",
    "        y = [l.tolist().index(max(l)) for l in train_labels]\n",
    "        model.train(train_vectors, y, dataset_name)\n",
    "    else:\n",
    "        model.train(train_vectors, train_labels, dataset_name)\n",
    "    \n",
    "    print(\"Validation Set\")\n",
    "    preds = model.predict(val_vectors)\n",
    "    if model.model_name == \"Support Vector Machine\":\n",
    "        preds = np.array([[1 if p == idx else 0 for idx in range(len(labels_str))] for p in preds])\n",
    "#     print(preds)\n",
    "\n",
    "    conf_mat = ConfusionMatrix(\n",
    "        labels=val_labels,\n",
    "        predictions=preds,\n",
    "        binary=False\n",
    "    )\n",
    "    conf_mat.evaluate(labels_str)\n",
    "    \n",
    "    print(\"Test Set\")\n",
    "    preds = model.predict(test_vectors)\n",
    "    if model.model_name == \"Support Vector Machine\":\n",
    "        preds = np.array([[1 if p == idx else 0 for idx in range(len(labels_str))] for p in preds])\n",
    "\n",
    "    conf_mat = ConfusionMatrix(\n",
    "        labels=test_labels,\n",
    "        predictions=preds,\n",
    "        binary=False\n",
    "    )\n",
    "    conf_mat.evaluate(labels_str)\n",
    "\n",
    "    print(\"--- END ---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1f3a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
