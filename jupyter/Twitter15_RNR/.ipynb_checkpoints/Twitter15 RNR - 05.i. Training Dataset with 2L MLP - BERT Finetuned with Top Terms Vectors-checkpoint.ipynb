{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Twitter15-RNR\"\n",
    "unique_name = \"BERT_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "terms_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter15-RNR_BERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>691809004356501505</td>\n",
       "      <td>america is a nation of second chances â€”@potus ...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693204708933160960</td>\n",
       "      <td>brandon marshall visits and offers advice, sup...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>551099691702956032</td>\n",
       "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "1  714598641827246081  an open letter to trump voters from his top st...   \n",
       "2  691809004356501505  america is a nation of second chances â€”@potus ...   \n",
       "3  693204708933160960  brandon marshall visits and offers advice, sup...   \n",
       "4  551099691702956032  rip elly may clampett: so sad to learn #beverl...   \n",
       "\n",
       "        label       tvt  cv_fold        tt        tvt2      tvt2_1  \\\n",
       "0  unverified  training        1  training    training  validation   \n",
       "1  unverified  training        1      test    training    testting   \n",
       "2   non-rumor  training        2  training  validation  validation   \n",
       "3   non-rumor  training        1  training    testting    testting   \n",
       "4        true  training        3  training  validation    training   \n",
       "\n",
       "       tvt2_2    tvt2_3  \n",
       "0    training  training  \n",
       "1    training  training  \n",
       "2  validation  testting  \n",
       "3    training  training  \n",
       "4  validation  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter15_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rumour', 'non-rumour']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = ['rumour', 'non-rumour']\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [0], [1], [1], [0], [1], [0], [0], [0], [0]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "#     lab = labels_str.index(d['label'])\n",
    "    if d['label'] in ['true', 'false', 'unverified']:\n",
    "        lab = 0\n",
    "    else:\n",
    "        lab = 1\n",
    "    labels.append([lab])\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"paul walker's\", 'us to', 'to watch', 'plan to', 'steps to', 'of the day', 'paul walker', 'want to', 'in ukraine', 'woman who']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_terms = []\n",
    "with open(\"../../data/processed/twitter15-rnr_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        vector_terms.append(t.strip())\n",
    "\n",
    "print(vector_terms[:10])\n",
    "len(vector_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2unigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(text)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def text2trigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    trigrams = nltk.trigrams(text)\n",
    "    trigrams = map(' '.join, trigrams)\n",
    "    trigrams = [bgr for bgr in trigrams]\n",
    "    \n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def bigrams_vectors_generation(texts):\n",
    "    bigram_vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(bigram_vector_base) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in bigram_vector_base:\n",
    "                idx = bigram_vector_base.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        bigram_vectors.append(init_vec)\n",
    "    \n",
    "    return bigram_vectors\n",
    "\n",
    "\n",
    "def custom_vectors_generation(texts, vector_terms):\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "        trigrams = text2trigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(vector_terms) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in vector_terms:\n",
    "                idx = vector_terms.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        for tgr in trigrams:\n",
    "            if tgr in vector_terms:\n",
    "                idx = vector_terms.index(tgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        vectors.append(init_vec)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 1519)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "terms_vectors = custom_vectors_generation(texts, vector_terms)\n",
    "\n",
    "vectors = np.concatenate([vectors, terms_vectors], axis=1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1004, 1519)\n",
      "(355, 1519)\n",
      "(131, 1519)\n",
      "(1004, 1)\n",
      "(355, 1)\n",
      "(131, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, n_output),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        binary: bool = False,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x, binary=binary)\n",
    "                if binary:\n",
    "                    preds = np.array([p[0] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([v[0] for v in test_y])\n",
    "                else:\n",
    "                    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y])\n",
    "                \n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=label_target,\n",
    "                    predictions=preds,\n",
    "                    binary=binary\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x, binary=False):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            \n",
    "            if binary:\n",
    "                return preds\n",
    "            else:\n",
    "                _, preds = torch.max(preds, dim = 1)\n",
    "                return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 86.761\n",
      "-- Epoch 50, Train Loss : 0.001318054914008826, Test Loss : 0.6081445813179016\n",
      "-- Epoch 100, Train Loss : 0.0002830696030287072, Test Loss : 0.7333474159240723\n",
      "-- Epoch 150, Train Loss : 0.00011509771866258234, Test Loss : 0.8100733757019043\n",
      "-- Epoch 200, Train Loss : 6.067194408387877e-05, Test Loss : 0.8659660816192627\n",
      "-- Epoch 250, Train Loss : 3.686220588861033e-05, Test Loss : 0.9102029800415039\n",
      "-- Epoch 300, Train Loss : 2.450068677717354e-05, Test Loss : 0.9468448758125305\n",
      "-- Epoch 350, Train Loss : 1.6736285942897666e-05, Test Loss : 0.981718122959137\n",
      "-- Epoch 400, Train Loss : 1.215868223880534e-05, Test Loss : 1.0110689401626587\n",
      "-- Epoch 450, Train Loss : 9.23201150726527e-06, Test Loss : 1.0364625453948975\n",
      "-- Epoch 500, Train Loss : 7.236322289827513e-06, Test Loss : 1.0591093301773071\n",
      "-- Epoch 550, Train Loss : 5.80590449317242e-06, Test Loss : 1.0795923471450806\n",
      "-- Epoch 600, Train Loss : 4.753803068524576e-06, Test Loss : 1.0982288122177124\n",
      "-- Epoch 650, Train Loss : 3.950522796003497e-06, Test Loss : 1.1155081987380981\n",
      "-- Epoch 700, Train Loss : 3.3306413342870655e-06, Test Loss : 1.1317625045776367\n",
      "-- Epoch 750, Train Loss : 2.83588633465115e-06, Test Loss : 1.1469942331314087\n",
      "-- Epoch 800, Train Loss : 2.4386215500271646e-06, Test Loss : 1.161110281944275\n",
      "-- Epoch 850, Train Loss : 2.115492861776147e-06, Test Loss : 1.174663782119751\n",
      "-- Epoch 900, Train Loss : 1.8451967775945377e-06, Test Loss : 1.1874816417694092\n",
      "-- Epoch 950, Train Loss : 1.6203795212277328e-06, Test Loss : 1.1998568773269653\n",
      "-- Epoch 1000, Train Loss : 1.435529270565894e-06, Test Loss : 1.2118955850601196\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 20.74 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([355, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 59\n",
      "False Positive : 19\n",
      "False Negative : 28\n",
      "True Negative : 249\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 75.641 %\n",
      "- Recall : 67.816 %\n",
      "- F1 : 0.71515\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 89.892 %\n",
      "- Recall : 92.91 %\n",
      "- F1 : 0.91376\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 86.761 %\n",
      "- Precision : 82.766 %\n",
      "- Recall : 80.363 %\n",
      "- F1 : 0.81547\n",
      "- Average Confidence : 17.39 %\n",
      "Model, Combined,,,,non-rumour,,,rumour,,,\n",
      "Twitter15-RNR_2LMLP_BERT_Finetuned_with_TopTermsVectors Validation, 86.761, 82.766, 80.363, 0.81547, 75.641, 67.816, 0.71515, 89.892, 92.91, 0.91376, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([131, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 22\n",
      "False Positive : 2\n",
      "False Negative : 9\n",
      "True Negative : 98\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 91.667 %\n",
      "- Recall : 70.968 %\n",
      "- F1 : 0.8\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 91.589 %\n",
      "- Recall : 98.0 %\n",
      "- F1 : 0.94686\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 91.603 %\n",
      "- Precision : 91.628 %\n",
      "- Recall : 84.484 %\n",
      "- F1 : 0.87911\n",
      "- Average Confidence : 18.43 %\n",
      "Model, Combined,,,,non-rumour,,,rumour,,,\n",
      "Twitter15-RNR_2LMLP_BERT_Finetuned_with_TopTermsVectors Test, 91.603, 91.628, 84.484, 0.87911, 91.667, 70.968, 0.8, 91.589, 98.0, 0.94686, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "binary = True\n",
    "\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_2LMLP_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=1, criterion=nn.BCELoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                binary=binary,\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in val_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in test_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55461251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
