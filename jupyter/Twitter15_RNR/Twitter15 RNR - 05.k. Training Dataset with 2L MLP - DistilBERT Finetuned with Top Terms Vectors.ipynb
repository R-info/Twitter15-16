{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Twitter15-RNR\"\n",
    "unique_name = \"DistilBERT_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "terms_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter15-RNR_DistilBERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>691809004356501505</td>\n",
       "      <td>america is a nation of second chances â€”@potus ...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693204708933160960</td>\n",
       "      <td>brandon marshall visits and offers advice, sup...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>551099691702956032</td>\n",
       "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "1  714598641827246081  an open letter to trump voters from his top st...   \n",
       "2  691809004356501505  america is a nation of second chances â€”@potus ...   \n",
       "3  693204708933160960  brandon marshall visits and offers advice, sup...   \n",
       "4  551099691702956032  rip elly may clampett: so sad to learn #beverl...   \n",
       "\n",
       "        label       tvt  cv_fold        tt        tvt2      tvt2_1  \\\n",
       "0  unverified  training        1  training    training  validation   \n",
       "1  unverified  training        1      test    training    testting   \n",
       "2   non-rumor  training        2  training  validation  validation   \n",
       "3   non-rumor  training        1  training    testting    testting   \n",
       "4        true  training        3  training  validation    training   \n",
       "\n",
       "       tvt2_2    tvt2_3  \n",
       "0    training  training  \n",
       "1    training  training  \n",
       "2  validation  testting  \n",
       "3    training  training  \n",
       "4  validation  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter15_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rumour', 'non-rumour']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = ['rumour', 'non-rumour']\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [0], [1], [1], [0], [1], [0], [0], [0], [0]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "#     lab = labels_str.index(d['label'])\n",
    "    if d['label'] in ['true', 'false', 'unverified']:\n",
    "        lab = 0\n",
    "    else:\n",
    "        lab = 1\n",
    "    labels.append([lab])\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"paul walker's\", 'us to', 'to watch', 'plan to', 'steps to', 'of the day', 'paul walker', 'want to', 'in ukraine', 'woman who']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_terms = []\n",
    "with open(\"../../data/processed/twitter15-rnr_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        vector_terms.append(t.strip())\n",
    "\n",
    "print(vector_terms[:10])\n",
    "len(vector_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2unigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(text)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def text2trigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    trigrams = nltk.trigrams(text)\n",
    "    trigrams = map(' '.join, trigrams)\n",
    "    trigrams = [bgr for bgr in trigrams]\n",
    "    \n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def bigrams_vectors_generation(texts):\n",
    "    bigram_vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(bigram_vector_base) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in bigram_vector_base:\n",
    "                idx = bigram_vector_base.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        bigram_vectors.append(init_vec)\n",
    "    \n",
    "    return bigram_vectors\n",
    "\n",
    "\n",
    "def custom_vectors_generation(texts, vector_terms):\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "        trigrams = text2trigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(vector_terms) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in vector_terms:\n",
    "                idx = vector_terms.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        for tgr in trigrams:\n",
    "            if tgr in vector_terms:\n",
    "                idx = vector_terms.index(tgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        vectors.append(init_vec)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 1519)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "terms_vectors = custom_vectors_generation(texts, vector_terms)\n",
    "\n",
    "vectors = np.concatenate([vectors, terms_vectors], axis=1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1004, 1519)\n",
      "(355, 1519)\n",
      "(131, 1519)\n",
      "(1004, 1)\n",
      "(355, 1)\n",
      "(131, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, n_output),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        binary: bool = False,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x, binary=binary)\n",
    "                if binary:\n",
    "                    preds = np.array([p[0] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([v[0] for v in test_y])\n",
    "                else:\n",
    "                    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y])\n",
    "                \n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=label_target,\n",
    "                    predictions=preds,\n",
    "                    binary=binary\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x, binary=False):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            \n",
    "            if binary:\n",
    "                return preds\n",
    "            else:\n",
    "                _, preds = torch.max(preds, dim = 1)\n",
    "                return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 89.859\n",
      "-- Epoch 50, Train Loss : 0.00144177523907274, Test Loss : 0.542248010635376\n",
      "-- Epoch 100, Train Loss : 0.00029097301012370735, Test Loss : 0.6630521416664124\n",
      "-- Epoch 150, Train Loss : 0.00012078068903065287, Test Loss : 0.7313627600669861\n",
      "-- Epoch 200, Train Loss : 6.570821642526425e-05, Test Loss : 0.7796429991722107\n",
      "-- Epoch 250, Train Loss : 4.113995782972779e-05, Test Loss : 0.8172087669372559\n",
      "-- Epoch 300, Train Loss : 2.8083381948817987e-05, Test Loss : 0.8480601906776428\n",
      "-- Epoch 350, Train Loss : 2.032740940194344e-05, Test Loss : 0.874296247959137\n",
      "-- Epoch 400, Train Loss : 1.5350620742538013e-05, Test Loss : 0.8973474502563477\n",
      "-- Epoch 450, Train Loss : 1.196672064907034e-05, Test Loss : 0.9173693656921387\n",
      "-- Epoch 500, Train Loss : 9.56443409450003e-06, Test Loss : 0.9363384246826172\n",
      "-- Epoch 550, Train Loss : 7.794794782967074e-06, Test Loss : 0.9530123472213745\n",
      "-- Epoch 600, Train Loss : 6.463503268605564e-06, Test Loss : 0.9690305590629578\n",
      "-- Epoch 650, Train Loss : 5.426095640359563e-06, Test Loss : 0.9849020838737488\n",
      "-- Epoch 700, Train Loss : 4.612352313415613e-06, Test Loss : 0.9971631169319153\n",
      "-- Epoch 750, Train Loss : 3.9585150943821645e-06, Test Loss : 1.007843017578125\n",
      "-- Epoch 800, Train Loss : 3.429931780374318e-06, Test Loss : 1.0243961811065674\n",
      "-- Epoch 850, Train Loss : 2.99287546567939e-06, Test Loss : 1.0348150730133057\n",
      "-- Epoch 900, Train Loss : 2.6211680506094126e-06, Test Loss : 1.0440045595169067\n",
      "-- Epoch 950, Train Loss : 2.3091901084626443e-06, Test Loss : 1.0538643598556519\n",
      "-- Epoch 1000, Train Loss : 2.046225631602283e-06, Test Loss : 1.0623457431793213\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 20.48 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([355, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 65\n",
      "False Positive : 14\n",
      "False Negative : 22\n",
      "True Negative : 254\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 82.278 %\n",
      "- Recall : 74.713 %\n",
      "- F1 : 0.78313\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 92.029 %\n",
      "- Recall : 94.776 %\n",
      "- F1 : 0.93382\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 89.859 %\n",
      "- Precision : 87.154 %\n",
      "- Recall : 84.744 %\n",
      "- F1 : 0.85932\n",
      "- Average Confidence : 9.87 %\n",
      "Model, Combined,,,,non-rumour,,,rumour,,,\n",
      "Twitter15-RNR_2LMLP_DistilBERT_Finetuned_with_TopTermsVectors Validation, 89.859, 87.154, 84.744, 0.85932, 82.278, 74.713, 0.78313, 92.029, 94.776, 0.93382, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([131, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 25\n",
      "False Positive : 2\n",
      "False Negative : 6\n",
      "True Negative : 98\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 92.593 %\n",
      "- Recall : 80.645 %\n",
      "- F1 : 0.86207\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 94.231 %\n",
      "- Recall : 98.0 %\n",
      "- F1 : 0.96078\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 93.893 %\n",
      "- Precision : 93.412 %\n",
      "- Recall : 89.323 %\n",
      "- F1 : 0.91322\n",
      "- Average Confidence : 10.01 %\n",
      "Model, Combined,,,,non-rumour,,,rumour,,,\n",
      "Twitter15-RNR_2LMLP_DistilBERT_Finetuned_with_TopTermsVectors Test, 93.893, 93.412, 89.323, 0.91322, 92.593, 80.645, 0.86207, 94.231, 98.0, 0.96078, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "binary = True\n",
    "\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_2LMLP_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=1, criterion=nn.BCELoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                binary=binary,\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in val_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in test_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55461251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
