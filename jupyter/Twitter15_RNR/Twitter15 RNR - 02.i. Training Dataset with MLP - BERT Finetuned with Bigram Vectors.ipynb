{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Twitter15-RNR\"\n",
    "unique_name = \"BERT_Finetuned_with_BigramVectors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter15-RNR_BERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>691809004356501505</td>\n",
       "      <td>america is a nation of second chances â€”@potus ...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693204708933160960</td>\n",
       "      <td>brandon marshall visits and offers advice, sup...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>551099691702956032</td>\n",
       "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "1  714598641827246081  an open letter to trump voters from his top st...   \n",
       "2  691809004356501505  america is a nation of second chances â€”@potus ...   \n",
       "3  693204708933160960  brandon marshall visits and offers advice, sup...   \n",
       "4  551099691702956032  rip elly may clampett: so sad to learn #beverl...   \n",
       "\n",
       "        label       tvt  cv_fold        tt        tvt2  \n",
       "0  unverified  training        1  training  validation  \n",
       "1  unverified  training        1      test    training  \n",
       "2   non-rumor  training        2  training  validation  \n",
       "3   non-rumor  training        1  training    testting  \n",
       "4        true  training        3  training    testting  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter15_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rumour', 'non-rumour']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = ['rumour', 'non-rumour']\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 0, 1, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "#     lab = labels_str.index(d['label'])\n",
    "    if d['label'] in ['true', 'false', 'unverified']:\n",
    "        lab = 0\n",
    "    else:\n",
    "        lab = 1\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80acc574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>unverified</th>\n",
       "      <th>non-rumor</th>\n",
       "      <th>true</th>\n",
       "      <th>false</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca kkk</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kkk grand</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grand wizard</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wizard endorses</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>endorses @hillaryclinton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      token  unverified  non-rumor  true  false\n",
       "0                    ca kkk           1          0     0      0\n",
       "1                 kkk grand           1          0     0      0\n",
       "2              grand wizard           1          0     0      0\n",
       "3           wizard endorses           1          0     0      0\n",
       "4  endorses @hillaryclinton           1          0     0      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_data = pd.read_excel('../../data/processed/twitter15_ngram_distribution.xlsx', sheet_name='bigram')\n",
    "bigram_data.columns = [\"token\", \"unverified\", \"non-rumor\", \"true\", \"false\"]\n",
    "bigram_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bigram_vector_base = bigram_data['token'].tolist()\n",
    "bigram_vector_base = []\n",
    "with open(\"../../data/processed/twitter15_best_bigrams.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        bigram_vector_base.append(t)\n",
    "len(bigram_vector_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    bigrams = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    bigrams = [t for t in bigrams if t not in string.punctuation]\n",
    "    bigrams = [t for t in bigrams if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(bigrams)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def bigrams_vectors_generation(texts):\n",
    "    bigram_vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(bigram_vector_base) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in bigram_vector_base:\n",
    "                idx = bigram_vector_base.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        bigram_vectors.append(init_vec)\n",
    "    \n",
    "    return bigram_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 6869)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "bigram_vectors = bigrams_vectors_generation(texts)\n",
    "\n",
    "vectors = np.concatenate([vectors, bigram_vectors], axis=1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 6869)\n",
      "(334, 6869)\n",
      "(156, 6869)\n",
      "(1000,)\n",
      "(334,)\n",
      "(156,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, n_output),\n",
    "#             nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 81.737\n",
      "Saving after new best accuracy : 87.126\n",
      "Saving after new best accuracy : 88.623\n",
      "-- Epoch 50, Train Loss : 0.00026725162751972675, Test Loss : 0.7584598660469055\n",
      "-- Epoch 100, Train Loss : 5.982319999020547e-05, Test Loss : 0.9198530912399292\n",
      "-- Epoch 150, Train Loss : 2.4799500351946335e-05, Test Loss : 1.018168568611145\n",
      "-- Epoch 200, Train Loss : 1.3141284398443531e-05, Test Loss : 1.0897445678710938\n",
      "-- Epoch 250, Train Loss : 8.046833954722388e-06, Test Loss : 1.145528793334961\n",
      "-- Epoch 300, Train Loss : 5.390650358094717e-06, Test Loss : 1.1913992166519165\n",
      "-- Epoch 350, Train Loss : 3.8206831050047185e-06, Test Loss : 1.231022596359253\n",
      "-- Epoch 400, Train Loss : 2.8278984700591536e-06, Test Loss : 1.2656573057174683\n",
      "-- Epoch 450, Train Loss : 2.169352342207276e-06, Test Loss : 1.2962671518325806\n",
      "-- Epoch 500, Train Loss : 1.7126291709246289e-06, Test Loss : 1.3237658739089966\n",
      "-- Epoch 550, Train Loss : 1.3791365631732333e-06, Test Loss : 1.3487969636917114\n",
      "-- Epoch 600, Train Loss : 1.1330988058944058e-06, Test Loss : 1.371789574623108\n",
      "-- Epoch 650, Train Loss : 9.454160760924424e-07, Test Loss : 1.3931032419204712\n",
      "-- Epoch 700, Train Loss : 8.013801959805278e-07, Test Loss : 1.4130148887634277\n",
      "-- Epoch 750, Train Loss : 6.802666234762e-07, Test Loss : 1.4317163228988647\n",
      "-- Epoch 800, Train Loss : 5.815072370296548e-07, Test Loss : 1.4493340253829956\n",
      "-- Epoch 850, Train Loss : 5.025415532600164e-07, Test Loss : 1.4659959077835083\n",
      "-- Epoch 900, Train Loss : 4.3533893290259584e-07, Test Loss : 1.4817843437194824\n",
      "-- Epoch 950, Train Loss : 3.828462524779752e-07, Test Loss : 1.4968643188476562\n",
      "-- Epoch 1000, Train Loss : 3.3776568386656436e-07, Test Loss : 1.5113446712493896\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 48.56 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([334])\n",
      "334 vs 334\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 90.076 %\n",
      "- Recall : 95.161 %\n",
      "- F1 : 0.92549\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 83.333 %\n",
      "- Recall : 69.767 %\n",
      "- F1 : 0.75949\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 88.623 %\n",
      "- Precision : 86.705 %\n",
      "- Recall : 82.464 %\n",
      "- F1 : 0.84531\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,rumour,,,non-rumour,,,\n",
      "Twitter15-RNR_4LayerNet_BERT_Finetuned_with_BigramVectors Validation, 88.623, 86.705, 82.464, 0.84531, 90.076, 95.161, 0.92549, 83.333, 69.767, 0.75949, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([156])\n",
      "156 vs 156\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 87.218 %\n",
      "- Recall : 98.305 %\n",
      "- F1 : 0.9243\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 91.304 %\n",
      "- Recall : 55.263 %\n",
      "- F1 : 0.68852\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 87.821 %\n",
      "- Precision : 89.261 %\n",
      "- Recall : 76.784 %\n",
      "- F1 : 0.82554\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,rumour,,,non-rumour,,,\n",
      "Twitter15-RNR_4LayerNet_BERT_Finetuned_with_BigramVectors Test, 87.821, 89.261, 76.784, 0.82554, 87.218, 98.305, 0.9243, 91.304, 55.263, 0.68852, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=2, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55461251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
