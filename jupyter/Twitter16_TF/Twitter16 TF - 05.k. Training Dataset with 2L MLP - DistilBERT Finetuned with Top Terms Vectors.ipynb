{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Twitter16-TF\"\n",
    "unique_name = \"DistilBERT_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "terms_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(412, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter16-TF_DistilBERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>656955120626880512</td>\n",
       "      <td>correct predictions in back to the future ii U...</td>\n",
       "      <td>False</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>615689290706595840</td>\n",
       "      <td>.@whitehouse in rainbow colors for #scotusmarr...</td>\n",
       "      <td>True</td>\n",
       "      <td>testting</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>613404935003217920</td>\n",
       "      <td>cops bought the alleged church shooter burger ...</td>\n",
       "      <td>False</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>614467824313106432</td>\n",
       "      <td>god put a rainbow over the white house ðŸŒˆ URL\\r</td>\n",
       "      <td>True</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>622891631293935616</td>\n",
       "      <td>#wakeupamericaðŸ‡ºðŸ‡¸ who needs a #gun registry whe...</td>\n",
       "      <td>False</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  656955120626880512  correct predictions in back to the future ii U...   \n",
       "1  615689290706595840  .@whitehouse in rainbow colors for #scotusmarr...   \n",
       "2  613404935003217920  cops bought the alleged church shooter burger ...   \n",
       "3  614467824313106432     god put a rainbow over the white house ðŸŒˆ URL\\r   \n",
       "4  622891631293935616  #wakeupamericaðŸ‡ºðŸ‡¸ who needs a #gun registry whe...   \n",
       "\n",
       "   label        tvt2    tvt2_1    tvt2_2    tvt2_3  \n",
       "0  False    training  training  training  training  \n",
       "1   True    testting  testting  training  testting  \n",
       "2  False  validation  training  training  training  \n",
       "3   True  validation  training  training  training  \n",
       "4  False    training  testting  training  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter16-tf_dataset.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_type = \"label\"\n",
    "labels_str = data[label_type].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [1], [0], [1], [0], [1], [1], [0], [0], [1]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d[label_type])\n",
    "    labels.append([lab])\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mass shootings', 'charlie hebdo', 'lindt cafe', 'he was', '#charliehebdo attackers', 'will be', 'a rainbow', 'parliament hill', 'is not', 'red cross']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "474"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_terms = []\n",
    "with open(\"../../data/processed/twitter16-tf_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        vector_terms.append(t.strip())\n",
    "\n",
    "print(vector_terms[:10])\n",
    "len(vector_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2unigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(text)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def text2trigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    trigrams = nltk.trigrams(text)\n",
    "    trigrams = map(' '.join, trigrams)\n",
    "    trigrams = [bgr for bgr in trigrams]\n",
    "    \n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def bigrams_vectors_generation(texts):\n",
    "    bigram_vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(bigram_vector_base) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in bigram_vector_base:\n",
    "                idx = bigram_vector_base.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        bigram_vectors.append(init_vec)\n",
    "    \n",
    "    return bigram_vectors\n",
    "\n",
    "\n",
    "def custom_vectors_generation(texts, vector_terms):\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "        trigrams = text2trigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(vector_terms) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in vector_terms:\n",
    "                idx = vector_terms.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        for tgr in trigrams:\n",
    "            if tgr in vector_terms:\n",
    "                idx = vector_terms.index(tgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        vectors.append(init_vec)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(412, 1243)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "terms_vectors = custom_vectors_generation(texts, vector_terms)\n",
    "\n",
    "vectors = np.concatenate([vectors, terms_vectors], axis=1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(278, 1243)\n",
      "(95, 1243)\n",
      "(39, 1243)\n",
      "(278, 1)\n",
      "(95, 1)\n",
      "(39, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, n_output),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        binary: bool = False,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x, binary=binary)\n",
    "                if binary:\n",
    "                    preds = np.array([p[0] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([v[0] for v in test_y])\n",
    "                else:\n",
    "                    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y])\n",
    "                \n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=label_target,\n",
    "                    predictions=preds,\n",
    "                    binary=binary\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x, binary=False):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            \n",
    "            if binary:\n",
    "                return preds\n",
    "            else:\n",
    "                _, preds = torch.max(preds, dim = 1)\n",
    "                return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 91.579\n",
      "Saving after new best accuracy : 92.632\n",
      "-- Epoch 50, Train Loss : 0.0029580816626548767, Test Loss : 0.4252467751502991\n",
      "-- Epoch 100, Train Loss : 0.0005041277036070824, Test Loss : 0.5483983159065247\n",
      "-- Epoch 150, Train Loss : 0.0001905790122691542, Test Loss : 0.6169192790985107\n",
      "-- Epoch 200, Train Loss : 0.00010025387746281922, Test Loss : 0.6629337668418884\n",
      "-- Epoch 250, Train Loss : 6.19267811998725e-05, Test Loss : 0.6977383494377136\n",
      "-- Epoch 300, Train Loss : 4.209011240163818e-05, Test Loss : 0.7258047461509705\n",
      "-- Epoch 350, Train Loss : 3.0482677175314166e-05, Test Loss : 0.7492459416389465\n",
      "-- Epoch 400, Train Loss : 2.3101765691535547e-05, Test Loss : 0.769435465335846\n",
      "-- Epoch 450, Train Loss : 1.725117544992827e-05, Test Loss : 0.7913029789924622\n",
      "-- Epoch 500, Train Loss : 1.3508578376786318e-05, Test Loss : 0.8094841241836548\n",
      "-- Epoch 550, Train Loss : 1.092993716156343e-05, Test Loss : 0.8250604867935181\n",
      "-- Epoch 600, Train Loss : 9.046477316587698e-06, Test Loss : 0.8390951156616211\n",
      "-- Epoch 650, Train Loss : 7.61567207518965e-06, Test Loss : 0.851739764213562\n",
      "-- Epoch 700, Train Loss : 6.497065442090388e-06, Test Loss : 0.8633142709732056\n",
      "-- Epoch 750, Train Loss : 5.605744718195638e-06, Test Loss : 0.8743259310722351\n",
      "-- Epoch 800, Train Loss : 4.883172096015187e-06, Test Loss : 0.8845683932304382\n",
      "-- Epoch 850, Train Loss : 4.289678599889157e-06, Test Loss : 0.894031286239624\n",
      "-- Epoch 900, Train Loss : 3.7973886719555594e-06, Test Loss : 0.9030349254608154\n",
      "-- Epoch 950, Train Loss : 3.379287591087632e-06, Test Loss : 0.9118450880050659\n",
      "-- Epoch 1000, Train Loss : 3.0263677217590157e-06, Test Loss : 0.9197150468826294\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAFXCAYAAAC1NambAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAreElEQVR4nO3de3xU9Z3/8dcnCUkEEeWilUQS3apbQISan1St6yW4tdrqbrduVbDQWllhK96q1dKLy0q37m69K4ou4iXear2t2rVqpWJVNFi0gloRgwTvIIggl8Dn98c5gTEkmZlkzpw5mffz8ZgHcy5z5nsmQz75fD/n+z3m7oiIiGSqJO4GiIhIsihwiIhIVhQ4REQkKwocIiKSFQUOERHJigKHiIhkRYFDpJvM7FAzez2P7/cfZnZWvt6vnfe/yMxu62T782Y2LJ9tkvxS4JBuMbMmMxsTdzvyyczczL7Yuuzuc9193zy99yDgu8D1+Xi/LvpvYFrcjZDoKHCIdMDMyuJuQzsmAI+4+2dxN6QTDwJHmNkX4m6IREOBQyJhZhVmdrmZvRM+LjezinDbQDN7yMxWmdlKM5trZiXhth+b2XIzW2Nmr5tZfQfH72dmt5jZh2a21Mx+amYl4fuuMrPhKfsOMrPPzGzXcPkbZrYg3O8ZMxuRsm9T2IaXgbVtg4eZPRU+fcnMPjWz75jZ4WbW3OYY55nZy2a21sz+x8x2M7Pfhef1uJntkrL/V8J2rDKzl8zs8E4+2q8Df2zTpnTnc6GZLTKzj83sJjOrTNl+mpktDn8OD5rZ4JRtw8zssXDb+2b2k5S3LQ8//zVmttDM6lo3uPt6YD7wtU7OQ5LM3fXQo8sPoAkY0876acBzwK7AIOAZ4N/Dbf8BXAf0Ch+HAgbsCywDBof71QJ/08H73gI8APQN9/srcGq4bRYwPWXffwX+L3w+CvgAGA2UAuPDc6hIOZ8FwB7ADh28twNfTFk+HGhu85k8B+wGVIXv92L43pXAH4BfhPtWASuAYwj+kDsqXB7UwXt/CPy/lOVMzueV8Hz6A38CLg63HQl8BHwZqACuAp4Kt/UF3gXODdvcFxgdbrsIWB+2uTT8eT7Xpp1XApfG/f3UI5qHMg6Jylhgmrt/4O4fAv8GnBJu2wTsDtS4+yYPagQObCb4BTbUzHq5e5O7v9n2wGZWCpwIXOjua9y9Cfh1yvFvD7e3OjlcBzARuN7d57n7Zne/GdgAfCVl/yvdfZl3rzvoKnd/392XA3OBee7+Zw/+Gr+P4Bc+wDiCrqdH3H2Luz8GNBL8Um7PzsCalOVMzufq8HxWAtOBk8L1Y4FZ7v6iu28ALgQOMrNa4BvAe+7+a3dfH37O81KO+XTY5s3ArcD+bdq5Jmyr9EAKHBKVwcDSlOWl4TqA/wIWA783syVmdgGAuy8GziL4i/YDM7szteskxUCCTKXt8avC508Cvc1sdPhLcCTBL2uAGuDcsFtnlZmtIvhrPPV9lmV7su14P+X5Z+0s75jSnhPatOerBIG1PR8T/PXfKtvzSf05fO5n5O6fEmQ7VeExtgvaKd5Leb4OqGzTrdcXWNXJ6yXBFDgkKu8Q/FJrNSRcR/jX67nuvhdwHHBOay3D3W9396+Gr3XgknaO/RFB1tL2+MvDY2wG7ib4y/ok4CF3b/0rfRlBN9bOKY/e7n5HyrHyOWX0MuDWNu3p4+6/6mD/l4F92rw+3fnskfJ868+BNj8jM+sDDCD4HJcBe3XjvL4EvNSN10sBU+CQXOhlZpUpjzLgDuCnYWF6IPBz4DbYWsz9opkZsJqgi2qLme1rZkeGRfT1BH+Zb2n7ZimBYbqZ9TWzGuCc1uOHbge+Q9Adc3vK+huA08NsxMysj5kda2apf8Wn8z7d+6Wa6jbgm2b2NTMrDT+/w82suoP9HwEOS1nO5Hz+1cyqzaw/MBW4K1x/B/A9MxsZfua/JOhSawIeAnY3s7PCCw76mtnoTE4oLL4fADyW4WcgCaPAIbnwCMEv+dbHRcDFBH31LwN/ISgOXxzuvzfwOPAp8Cxwrbs/SVDf+BVBRvEeQWH9wg7e8wxgLbAEeJogOMxq3Rj2x68l6I75Xcr6RuA04GqCbp/FBJe4ZuMi4Oawa+ifs3zt57j7MuB44CcEhe9lwHl0/H/zFuAYM9shfH0m53M78HuCz+pNwp+Duz8O/Az4LUEh/G8Ia0NhhnYU8E2Cn8UbwBEZntY3gTnu/k7aPSWRLKhJikhSmNkvgQ/c/fIM9m0CfhAGibwws3kEV7i9kq/3lPwqxAFOItIJd/9J+r3i4+4ZdWlJcqmrSkREsqKuKhERyYoyDhERyYoCh4iIZCVxxfGBAwd6bW1t3M0QEem6lSuhqQnyWCpoAj5yt1wcK3GBo7a2lsbGxribISKSXkMDfP/7sHFj3C2hLv0uGVNXlYhId02eDGbbP8aNK4igkWuJyzhERGIzeTLMmBF3K2KnjENEpK2OMogkBI3KSrjttqB+kvKYH9xcKyeUcYhI8SqgGkRWKivhxhth7NhY3l6BQ0R6vqQGiEmT4Npr427FdhQ4RKRnGTMGnngi7lZkp0ADREdU4xCRZGpogIqK7esQhRw0Jk3arvaAe6KCBijjEJEkSFJXU8z1h3xQ4BCRwpKUS16LIEB0RIFDROKThHpEEQeIjqjGISLRS0o9or0axGefKWi0oYxDRHKv0LubEnYVU6FR4BCR7inkIFFfD4/n7XbrRUNdVSKSufa6nAolaLTXzaSgEQllHCLSsUItXqurKVbKOEQk0F42EXfQ6GDCPgWNeCnjEClWhZZNqB6RGMo4RIpBoWUTqkckmjIOkZ6okKbo0AC6HkeBQ6QnKJRAoSBRFNRVJZJEbbue4rq3ddsuJ42yLgrKOESSoBAG2al4LSFlHCKFqG1GEUfQaJtNKGhISBmHSCGIu0ahbEKyoIxDJC6TJ8dXo1A2Id2gjEMkX+LMKjRFh+SQAodIlOIana1AIRFSV5VILqV2P+VzdHbbricFDYmQMg6R7sp3VqFBdhIzZRwiXTFmTH6zitSMQoPsJGbKOEQylc/MQjUKKWCRZhxmdrSZvW5mi83sgna2DzGzJ83sz2b2spkdE2V7RLLSdhBelEGj7X0nFDSkgEWWcZhZKXANcBTQDLxgZg+6+6KU3X4K3O3uM8xsKPAIUBtVm0Qykq/MQlmFJFSUGceBwGJ3X+LuG4E7gePb7OPATuHzfsA7EbZHpGP5qFnoyifpIaIMHFXAspTl5nBdqouAcWbWTJBtnNHegcxsopk1mlnjhx9+GEVbpRilXjobRbBQ95P0UHFfVXUSMNvdq4FjgFvNbLs2uftMd69z97pBgwblvZHSg6TWLaKYOLC+Xlc/SY8XZeBYDuyRslwdrkt1KnA3gLs/C1QCAyNskxSr1uwiijmhUoOF5nySIhBl4HgB2NvM9jSzcuBE4ME2+7wN1AOY2ZcIAof6oiR3WmsXuc4uFCykiEUWONy9Bfgh8CjwKsHVUwvNbJqZHRfudi5wmpm9BNwBTHB3j6pNUkRaA0YuaxepxW0FCylikQ4AdPdHCIreqet+nvJ8EXBIlG2QIhLF7LO6T4XIdjRyXJJNwUIk7+K+qkoke6lXRuWq2J166ayChkinlHFIckQxolujt0WypoxDClsUg/RSswsFDZGsKeOQwhPVLVZVuxDJCQUOKRxRTS6ogCGSU+qqknhFOV9U67gLBQ2RnFLGIfGIKrtQsVskcso4JH+iyi5SR3QraIhEThmHRC+K7EJ1C5HYKOOQaKQO0oviMloFDZHYKHBIbkUxfXlrV5TubyFSENRVJbkxeXJupy5XV5RIwVLgkO7JZf2ishJuvFFZhUiBU+CQrsllwFB2IZIoqnFI5nJZ8FahWySxlHFIermsXyi7EEk8ZRzSsdYrpHIRNDT9h0iPoYxDttfQAKecEvyi746yMpg9W8VukR5GGYds09AQ/LIfN657QaO1frFpk4KGSA+kjEOCgDF+PGze3L3jqH4hUhQUOIrdsGGwaFH3jqGAIVJU1FVVrMaMCQrfXQ0aZWW6nFakSCUucMyfD7W1Qe+KdEHrlVJdHYfRGjBUvxApWonsqlq6FCZODJ7rd1eGunulVGkp3HyzPnARwby7l1zmmVmdQyMANTXQ1BRvexKhu3UM3VVPJPHMbL671+XiWInrqkr19ttxt6DAtXZLdTVotA7aU9AQkRSJ7KpqNWRI3C0oUN3tllKGISKdSGzg6N0bpk+PuxUFqDuz1uqyWhHJQCK7qmpqYOZM1Wk/p6EBSkq6FjSGDtVltSKSscRlHL16qSC+na5mGbpSSkS6IHEZR8IuAotWd7KMSZOgpUVBQ0SylriMQ0JdzTKGDoWFC3PfHhEpGso4kqiqKvugUVoajPhW0BCRblLgSJKGhmBcxjvvZPe6+np1S4lIzihwJMWYMcF9MrLRmmXoaikRySHVOJKgqqprWYYChohEQBlHIetK15SyDBGJWCIzji1bgqtQe7SuXDWlLENE8iCRv35bWuJuQcSGDcsuaJgpyxCRvElkxtHSAuXlcbciItnWMwYPhuXLo2uPiEgbyjgKyS67ZBc06usVNEQk7xQ4CkFrEXzVqsz2V9eUiMQocYHjAObTb//annPT8cmTsxufMXhwcHWABvOJSEwSFzgASpvDm44nPXhMngwzZmS+v7qmRKQAJDJwALBuHUydGncrui7boDFpkrqmRKQgJPKqqq2SetPxbMZomMGtt6prSkQKRrIDRxJvOj5sGCxalNm+O+8MH38caXNERLKV2K6qlvIE3nQ8m6AxeLCChogUpEQGjiZqOM1n0kCCum/GjMk8aAwdqiK4iBQs84TNGjjKynwBwUCOmpqE3H88m0K47tAnIhEws/nuXpeLYyUu4zC2BbpE1MYVNESkh4k0cJjZ0Wb2upktNrMLOtjnn81skZktNLPb0x6TLVufF3xtPJugUV+voCEiiRDZVVVmVgpcAxwFNAMvmNmD7r4oZZ+9gQuBQ9z9YzPbNe1xAXB697bCro03NGQeNCZNgmuvjbY9IiI5EmXGcSCw2N2XuPtG4E7g+Db7nAZc4+4fA7j7B5kcuHrXTcycWeBDG8aPz2w/BQ0RSZgoA0cVsCxluTlcl2ofYB8z+5OZPWdmR2dy4Ftu3FjYQaOqCjZvTr9ffb2ChogkTtwDAMuAvYHDgWrgKTPbz91Xpe5kZhOBiQAHAFvWb8xvK7MxbFhmU6MPHaopREQkkaLMOJYDe6QsV4frUjUDD7r7Jnd/C/grQSD5HHef6e51rZeSFWzgyHSshq6eEpEEizJwvADsbWZ7mlk5cCLwYJt97ifINjCzgQRdV0vSHfirZ9UV3sy4kydnNv+UgoaIJFxkgcPdW4AfAo8CrwJ3u/tCM5tmZseFuz0KrDCzRcCTwHnuviLdsXdYubywplXP9AqqwYMVNEQk8RI3crzOzBtbFwpl6HivXulvS2gW3IBJRCQGRT1y/HMKYej4mDGZ3cv21lujb4uISB4kO3DEPXQ807rGpEkFPuhERCRzyQ0cvWOeVj3TuobGaohID5PIwLGu767EPnR8woT0+2ishoj0QIkMHE+ccnO8QSOTukZpqa6gEpEeKZGBg40xDgBsaMisrnHzzdG3RUQkBgoc2cqki6q+XsVwEemxEhk47rhlI7W1MYz/mzw5fReV6hoi0sMlMnCUs5GlS2MYPJ7uKirVNUSkCCQ2cACsWwdTp+bpTceMSb+P6hoiUgQSHTggT4PHMymIq64hIkUi8YEjL4PH0xXES0tV1xCRopHIwPFrzuUtapnQqyH6weOZFMTVRSUiRSTRs+O2lPembFbEI8jNOt9eXg4bNkT3/iIiOaDZcUNlGyOujk+enH6fWbOie38RkQKU6IwDiPY+F+myjfp61TZEJBGUcaSKqjqeLttQQVxEilSyA0eUU6unG+yngriIFKlEBg6H4LaxUU2tni7bKC/XmA0RKVplcTcgWxutnDnVJ3JEU4R/8afLNlQQF5EilsCMwyjZHOHsuOmmFlG2ISJFLnGBwzFKowocmUwtomxDRIpc8gKHlUQXOE4/vfPtyjZERBIYOKLKOBoa4NNPO99H2YaISPICBxZR4DjzzM63K9sQEQESGDgcoyyKwLFiRefblW2IiAAJDByVmz9lxNpnaC6r5enJObr9X7pxG336KNsQEQklLnCU4BhQvXkpo2ZMzE3wuO66zrdff33330NEpIdIXOBI1Yd11M7s5uy4DQ3Q2USPyjZERD4no8BhZn3MrCR8vo+ZHWdmvaJtWmYGb+7mvWPTXYKrbENE5HMyzTieAirNrAr4PXAKMDuqRmXjndJuzI6b7hJcXUklIrKdTAOHufs64FvAte5+AjAsumZlZi29aZrYjdlx012CqyupRES2k3HgMLODgLHAw+G60mia1LnNlOBAc2kNf540k69e242MIN0luMo2RES2k+nsuGcBFwL3uftCM9sLeDKyVnViXe9BrFu3huqWJqq7c6CGNFdjDRjQnaOLiPRYGQUOd/8j8EeAsEj+kbtPibJhHTKjnBwMAExXFL/iiu6/h4hID5TpVVW3m9lOZtYHeAVYZGbnRdu09jlGL1q6d5/xdEVxXYIrItKhTGscQ939E+AfgN8BexJcWZV/JQaAb9zU9WOkK4rrElwRkQ5lGjh6heM2/gF40N03Ed7BNe+C4SRs/qwb3VWdFcWVbYiIdCrTwHE90AT0AZ4ysxrgk6ga1SkLMo5Na7sYONIVxZVtiIh0yryz6TY6e6FZmbu35Lg9aX25pMxf9M1sGVxFyX9ekn12MHBg5xlHFz8PEZFCZmbz3b0uF8fKtDjez8wuNbPG8PFrguwj70p8c/DvO8th4sT0GURbnQUNXYIrIpJWpl1Vs4A1wD+Hj0+Am6JqVMbWrYOpWUxymG76dF2CKyKSVkZdVWa2wN1HpluXD3Vm3vj5hmR+aW5JSeddUeqmEpEeKu9dVcBnZvbVlAYcAnyWiwZ025AMJzlMN326uqlERDKS6ZQjpwO3mFm/cPljYHw0TcpcS3lvyqZnOMlhurEb6qYSEclIRhmHu7/k7vsDI4AR7j4KODLSlnVgUxjr3mNXTvOZNJDhVVWdFcU1fbqISMayugOgu38SjiAHOCeC9qT1Jl8EYAI3M3vT2Mxq4+muvNL06SIiGevOrWMtZ63IwpbwbSvYAMDbmdwAMF03lbINEZGMdSdwxHIJkrcJHBnVxjV2Q0QkZzotjpvZGtoPEAbsEEmL0vAw1lWwgd69IW1tPF03lYriIiJZ6TRwuHvffDUkUyVlBi0wqO8GZs7IoJdJ3VQiIjmV6eW4BaOmtgQWw2mnrOdLmfzOVzeViEhOdafGEYuyT1cB8LfXngG1tZ13RambSkQk5yINHGZ2tJm9bmaLzeyCTvb7JzNzM0s7HL7i/WXBawCWLu18okN1U4mI5FxkgcPMSoFrgK8DQ4GTzGxoO/v1Bc4E5mV0YG8zL1VnEx2qm0pEJOeizDgOBBa7+xJ33wjcCRzfzn7/DlwCrO/yO7U3mEPdVCIikYgycFQBy1KWm8N1W5nZl4E93P3hzg5kZhNb7wXS7g7tDeZQN5WISCRiK46bWQlwKXBuun3dfaa717l7Xes9x7fqaDCHuqlERCIRZeBYDuyRslwdrmvVFxgOzDGzJuArwIPpCuSb96ihhdJgVGJNDcycmX32oG4qEZEui3IcxwvA3ma2J0HAOBE4uXWju68GBrYum9kc4Efu3n53VOvrdulP09sltBwwmr9t7KCOka6+oW4qEZEuiyzjcPcW4IfAo8CrwN3uvtDMppnZcV09rhmsp5KSTRs63ildfUNERLos0pHj7v4I8EibdT/vYN/DMzmmGWyggsqNnQSOzuobNTWZvI2IiHQgcSPHP/44CBxLXtvQ/sDxdN1Umd4xUERE2mXe2X24C9DAkr18mb9DJRtYSg3/1ms6Y24au61sUVsbjCjvSMLOV0QkF8xsvrunnZ0jE4nLOIb4UnZgAwbUspSrN01k3pkpWUZnQUOX4YqIdFviAkcJn59ypA/rOGdFypQj1smNCXUZrohItyUucLRnCOGUIw0NnXdF6TJcEZFu6xGBY92AcMqRjiY7FBGRnElc4PA2U460lPdmxyvCK6VU3xARiVziAofV1rDGdto65UjZrJQpR0o6OR3VN0REciJxgYP+/fmfnc4ObuS0ZMnn6xZbtnT0KtU3RERyJHmBA9jQq0/w5LPPtq1MN/BPRERyIpGBY1NZ7+DJunXbVnY2P5XqGyIiOZO8wLFyJT/88BfB81GjtmUanc1PpfqGiEjORDrJYSSWLmXn1lrG8uUwcWL616i+ISKSM8nLONoWwNet67ybqrOR5CIikrXkBY72dNZNpUkNRURyqmcEjs7o/hsiIjmVvMDRdpBf796dd0fp/hsiIjmVvMBRU8NHFYOD5wMGwMyZmthQRCSPEhc4VtKfizdfCICvWMH6f9H9xUVE8imRdwB829+jN5+l33nAAPjoo+gbJSJS4HJ5B8DEjeMY7MvpzcbMdtbAPxGRnEtcV1V5pkEDVN8QEYlA4gLHRsrjboKISFFLXOB4x6pYT6+4myEiUrQSFzgGDgQjg2lENCOuiEgkEhc4dly9nIpM6hwqjIuIRCJxgYONGRbHVRgXEYlE8gJHuYrjIiJxSl7g6NePZA1ZFBHpWZIXOFavTl8aV2FcRCQyyQscmdQ4VBgXEYlM8gJHJjUOFcZFRCKTvMBRVaUah4hIjJIXOPr373y76hsiIpFKXOBYuRK2dNZs1TdERCKVuMCxdCnM4F/a766qr1d9Q0QkYokLHFu2wBlcyzVMooVSHGihFCZNgscfj7t5IiI9XuLuAGhW59DYZl0QUEREpH25vANg4jKO9gwZEncLRESKR+ICR0mbFvfuDdOnx9MWEZFilLjAUVMDu+0WPN91V5g5U/VwEZF8Slzg6N8f7rsveH7LLQoaIiL5lrjAAdtmHcn01hwiIpI7iQ4cGzbE2w4RkWKUyMBRURH8q4xDRCT/Ehk41FUlIhKfRAcOdVWJiORfIgOHuqpEROKTyMChrioRkfgkMnDce2/w749+BLW10NAQa3NERIpK4gLHypUwefK25aVLYeJEBQ8RkXxJXOBYvhzWrfv8unXrYOrUeNojIlJsIg0cZna0mb1uZovN7IJ2tp9jZovM7GUze8LMatIds6O6xttvd7+9IiKSXmSBw8xKgWuArwNDgZPMbGib3f4M1Ln7COAe4D/THbe1MN6WplYXEcmPKDOOA4HF7r7E3TcCdwLHp+7g7k+6e2vH03NAdbqDVlUFU6mn0tTqIiL5E2XgqAKWpSw3h+s6cirwu/Y2mNlEM2s0s8bNmz9k5kwoLQ221dRoanURkXwqiOK4mY0D6oD/am+7u8909zp3rxs0aBBjx8Jee8FJJ0FTk4KGiEg+lUV47OXAHinL1eG6zzGzMcBU4DB3z3gSkYoKDQAUEYlDlBnHC8DeZranmZUDJwIPpu5gZqOA64Hj3P2DbA5eXq65qkRE4hBZ4HD3FuCHwKPAq8Dd7r7QzKaZ2XHhbv8F7Aj8xswWmNmDHRxuO+XlyjhEROIQZVcV7v4I8EibdT9PeT6mq8dWV5WISDwKojierYYGmDcP5szRXFUiIvmWuMCxcmUwN9X69cGy5qoSEcmvxAUOzVUlIhKvxAUOzVUlIhKvxAUOzVUlIhKvxAUOzVUlIhKvxAWO/v2Dual22ilY1lxVIiL5Fek4jqiMHQt//StMmwZvvQVmcbdIRKR4JC7jaLXDDsG/mnZERCS/Eh842l6aKyIi0Upk4GhoCLqpAEaM0OA/EZF8SlyNo3XkeGumsXx5sAwqkIuI5EPiMg6NHBcRiVfiAodGjouIxCtxgUMjx0VE4pW4wKGR4yIi8Upc4GgdOb777sHywIEaOS4ikk+JCxwQBIk5c4Lnl1+uoCEikk+Juxy3lQYAivQMmzZtorm5mfWtd2eTbqmsrKS6uppevXpF9h6JDRyPhHcynzgxqG9Mn67MQySJmpub6du3L7W1tZgmnusWd2fFihU0Nzez5557RvY+ieyqamiAs8/etqzbx4ok1/r16xkwYICCRg6YGQMGDIg8e0tk4Jg6FT777PPrNAhQJLkUNHInH59lIgNHR4P9NAhQRLK1YsUKRo4cyciRI/nCF75AVVXV1uWNHY04DjU2NjJlypSs3q+2tpaPPvqoO02OXSIDR0eD/TQIUKTna2iA2looKQn+7W4X9YABA1iwYAELFizg9NNP5+yzz966XF5eTktLS4evraur48orr+xeAxIokYFj+nQNAhQpRg0NQT1z6VJwj66+OWHCBE4//XRGjx7N+eefz/PPP89BBx3EqFGjOPjgg3n99dcBmDNnDt/4xjcAuOiii/j+97/P4Ycfzl577ZVVQGlqauLII49kxIgR1NfX83bYffKb3/yG4cOHs//++/N3f/d3ACxcuJADDzyQkSNHMmLECN54443cnnwGEnlV1dix8Kc/wYwZwXJpKYwfr6uqRJLurLNgwYKOtz/33PY3b1u3Dk49FW64of3XjBwZjPfKVnNzM8888wylpaV88sknzJ07l7KyMh5//HF+8pOf8Nvf/na717z22ms8+eSTrFmzhn333ZdJkyZldFnsGWecwfjx4xk/fjyzZs1iypQp3H///UybNo1HH32UqqoqVq1aBcB1113HmWeeydixY9m4cSObN2/O/uS6KZEZR0MD3HzztuXNm4NlXVUl0rN1dMfPKO4EesIJJ1BaWgrA6tWrOeGEExg+fDhnn302CxcubPc1xx57LBUVFQwcOJBdd92V999/P6P3evbZZzn55JMBOOWUU3j66acBOOSQQ5gwYQI33HDD1gBx0EEH8ctf/pJLLrmEpUuXskProLY8SmTGMXVqx1OrK+sQSa50mUFtbdA91VZNzbbZJHKlT58+W5//7Gc/44gjjuC+++6jqamJww8/vN3XVFRUbH1eWlraaX0kE9dddx3z5s3j4Ycf5oADDmD+/PmcfPLJjB49mocffphjjjmG66+/niOPPLJb75OtRGYcuqpKpDjFVd9cvXo1VVVVAMyePTvnxz/44IO58847AWhoaODQQw8F4M0332T06NFMmzaNQYMGsWzZMpYsWcJee+3FlClTOP7443n55Zdz3p50Ehk4dFWVSHEaOzaY1LSmBsyCf/Mxyen555/PhRdeyKhRo7qdRQCMGDGC6upqqqurOeecc7jqqqu46aabGDFiBLfeeitXXHEFAOeddx777bcfw4cP5+CDD2b//ffn7rvvZvjw4YwcOZJXXnmF7373u91uT7bM3fP+pt1RV1fnZ5/dyPe+B5s2bVvfqxfcdJO6qkSS5tVXX+VLX/pS3M3oUdr7TM1svrvX5eL4icw4IPhro7NlERGJRiIDx9Sp299CduNGTTkiIpIPiQwcKo6LiMQnkYGjoyJ4//75bYeISDFKZOCYPj0ohre1Zo0GAYqIRC2RgWPsWNhpp+3Xq84hIhK9RI4cB1i5sv31qnOISDZWrFhBfX09AO+99x6lpaUMGjQIgOeff57y8vJOXz9nzhzKy8s5+OCDt9s2e/ZsGhsbufrqq3Pf8BglMuOAjusZqnOI9HA5nlc93bTq6cyZM4dnnnmmW21ImsQGDhEpQnmaV33+/PkcdthhHHDAAXzta1/j3XffBeDKK69k6NChjBgxghNPPJGmpiauu+46LrvsMkaOHMncuXMzOv6ll17K8OHDGT58OJeHE3StXbuWY489lv3335/hw4dz1113AXDBBRdsfc8f/ehHOT3PrupxXVUdrReRBCiAedXdnTPOOIMHHniAQYMGcddddzF16lRmzZrFr371K9566y0qKipYtWoVO++8M6effjo77rhjxr/U58+fz0033cS8efNwd0aPHs1hhx3GkiVLGDx4MA8//DAQzI+1YsUK7rvvPl577TXMbOvU6nFLbMahriqRIpSHedU3bNjAK6+8wlFHHcXIkSO5+OKLaW5uBoI5psaOHcttt91GWVnX/u5++umn+cd//Ef69OnDjjvuyLe+9S3mzp3Lfvvtx2OPPcaPf/xj5s6dS79+/ejXrx+VlZWceuqp3HvvvfRuO8NjTBKbcXRk/fq4WyAiXVYA86q7O8OGDePZZ5/dbtvDDz/MU089xf/+7/8yffp0/vKXv+TkPQH22WcfXnzxRR555BF++tOfUl9fz89//nOef/55nnjiCe655x6uvvpq/vCHP+TsPbsqsRlHR11Sa9dqLIdIj5WHedUrKir48MMPtwaOTZs2sXDhQrZs2cKyZcs44ogjuOSSS1i9ejWffvopffv2Zc2aNRkf/9BDD+X+++9n3bp1rF27lvvuu49DDz2Ud955h969ezNu3DjOO+88XnzxRT799FNWr17NMcccw2WXXcZLL72Us/PsjsRmHEOGtP+HB8CZZ2qWXJEeqfU/9tSpwbX3Q4YEQSOH/+FLSkq45557mDJlCqtXr6alpYWzzjqLffbZh3HjxrF69WrcnSlTprDzzjvzzW9+k29/+9s88MADXHXVVVvvpdFq9uzZ3H///VuXn3vuOSZMmMCBBx4IwA9+8ANGjRrFo48+ynnnnUdJSQm9evVixowZrFmzhuOPP57169fj7lx66aU5O8/uSOS06o2NjTQ0wLhxHe+XsNMSKVqaVj33NK16B9L9gaHuKhGRaCQ2cKRz5plxt0BEpGdKdOAYMKDjbStW5K8dIiLFJNGBI7wtb4eGDctPO0Ske5JWay1k+fgsEx040tU5Fi2CsjLVO0QKWWVlJStWrFDwyAF3Z8WKFVRWVkb6Pom9qqrVwIGZd0tVVsKNN+pSXZFCsmnTJpqbm1mv0bs5UVlZSXV1Nb3a3LQol1dVJT5wpLsstzsUaESkp1DgSAkcADvsoKlGREQ6V4d7o+XiSImucbS68ca4WyAiUjx6ROAYOxYmTYq7FSIixSFxXVVmtgZ4vf2tA/vDkFqwnKRjIiI9RxPuH+Xkd2MSJzl8PVcFnqQzs0Z9FgF9Ftvos9hGn8U2ZtaYfq/M9IiuKhERyR8FDhERyUoSA8fMuBtQQPRZbKPPYht9Ftvos9gmZ59F4orjIiISryRmHCIiEqNEBQ4zO9rMXjezxWZ2QdztiZKZ7WFmT5rZIjNbaGZnhuv7m9ljZvZG+O8u4XozsyvDz+ZlM/tyvGeQe2ZWamZ/NrOHwuU9zWxeeM53mVl5uL4iXF4cbq+NteE5ZmY7m9k9Zvaamb1qZgcV6/fCzM4O/3+8YmZ3mFllsXwvzGyWmX1gZq+krMv6e2Bm48P93zCz8Zm8d2ICh5mVAtcAXweGAieZ2dB4WxWpFuBcdx8KfAX41/B8LwCecPe9gSfCZQg+l73Dx0RgRv6bHLkzgVdTli8BLnP3LwIfA6eG608FPg7XXxbu15NcAfyfu/8tsD/BZ1J03wszqwKmAHXuPhwoBU6keL4Xs4Gj26zL6ntgZv2BXwCjgQOBX7QGm065eyIewEHAoynLFwIXxt2uPJ7/A8BRBIMfdw/X7U4wrgXgeuCklP237tcTHkB1+B/hSOAhwICPgLK23w/gUeCg8HlZuJ/FfQ45+hz6AW+1PZ9i/F4AVcAyoH/4c34I+FoxfS+AWuCVrn4PgJOA61PWf26/jh6JyTjY9iVp1Ryu6/HClHoUMA/Yzd3fDTe9B+wWPu/pn8/lwPnAlnB5ALDK3VvC5dTz3fpZhNtXh/v3BHsCHwI3hd12N5pZH4rwe+Huy4H/Bt4G3iX4Oc+nOL8XrbL9HnTp+5GkwFGUzGxH4LfAWe7+Seo2D/5E6PGXxZnZN4AP3H1+3G0pAGXAl4EZ7j4KWMu27gigqL4XuwDHEwTTwUAftu+6KVpRfg+SFDiWA3ukLFeH63osM+tFEDQa3P3ecPX7ZrZ7uH134INwfU/+fA4BjjOzJuBOgu6qK4Cdzax12pzU8936WYTb+wE95S70zUCzu88Ll+8hCCTF+L0YA7zl7h+6+ybgXoLvSjF+L1pl+z3o0vcjSYHjBWDv8IqJcoIi2IMxtykyZmbA/wCvuvulKZseBFqvfBhPUPtoXf/d8OqJrwCrU1LWRHP3C9292t1rCX7uf3D3scCTwLfD3dp+Fq2f0bfD/XvEX+Du/h6wzMz2DVfVA4sowu8FQRfVV8ysd/j/pfWzKLrvRYpsvwePAn9vZruEGdzfh+s6F3dxJ8tC0DHAX4E3galxtyfic/0qQZr5MrAgfBxD0Cf7BPAG8DjQP9zfCK46exP4C8GVJrGfRwSfy+HAQ+HzvYDngcXAb4CKcH1luLw43L5X3O3O8WcwEmgMvxv3A7sU6/cC+DfgNeAV4Fagoli+F8AdBLWdTQSZ6Kld+R4A3w8/k8XA9zJ5b40cFxGRrCSpq0pERAqAAoeIiGRFgUNERLKiwCEiIllR4BARkawocIi0YWabzWxByiNnMzGbWW3qbKYiSVSWfheRovOZu4+MuxEihUoZh0iGzKzJzP7TzP5iZs+b2RfD9bVm9ofwPgdPmNmQcP1uZnafmb0UPg4OD1VqZjeE95H4vZntENtJiXSBAofI9nZo01X1nZRtq919P+Bqghl7Aa4Cbnb3EUADcGW4/krgj+6+P8F8UgvD9XsD17j7MGAV8E+Rno1IjmnkuEgbZvapu+/Yzvom4Eh3XxJOQPmeuw8ws48I7oGwKVz/rrsPNLMPgWp335ByjFrgMQ9utIOZ/Rjo5e4X5+HURHJCGYdIdryD59nYkPJ8M6o1SsIocIhk5zsp/z4bPn+GYNZegLHA3PD5E8Ak2Hq/9H75aqRIlPSXjsj2djCzBSnL/+furZfk7mJmLxNkDSeF684guCPfeQR35/teuP5MYKaZnUqQWUwimM1UJNFU4xDJUFjjqHP3j+Jui0ic1FUlIiJZUcYhIiJZUcYhIiJZUeAQEZGsKHCIiEhWFDhERCQrChwiIpIVBQ4REcnK/wexbRd7wlTBMQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 10.17 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([95, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 45\n",
      "False Positive : 4\n",
      "False Negative : 3\n",
      "True Negative : 43\n",
      "\n",
      "Class True Evaluation\n",
      "- Precision : 91.837 %\n",
      "- Recall : 93.75 %\n",
      "- F1 : 0.92784\n",
      "\n",
      "Class False Evaluation\n",
      "- Precision : 93.478 %\n",
      "- Recall : 91.489 %\n",
      "- F1 : 0.92473\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 92.632 %\n",
      "- Precision : 92.657 %\n",
      "- Recall : 92.62 %\n",
      "- F1 : 0.92638\n",
      "- Average Confidence : 21.04 %\n",
      "Model, Combined,,,,True,,,False,,,\n",
      "Twitter16-TF_2LMLP_DistilBERT_Finetuned_with_TopTermsVectors Validation, 92.632, 92.657, 92.62, 0.92638, 91.837, 93.75, 0.92784, 93.478, 91.489, 0.92473, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([39, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 18\n",
      "False Positive : 0\n",
      "False Negative : 1\n",
      "True Negative : 20\n",
      "\n",
      "Class True Evaluation\n",
      "- Precision : 100.0 %\n",
      "- Recall : 94.737 %\n",
      "- F1 : 0.97297\n",
      "\n",
      "Class False Evaluation\n",
      "- Precision : 95.238 %\n",
      "- Recall : 100.0 %\n",
      "- F1 : 0.97561\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 97.436 %\n",
      "- Precision : 97.619 %\n",
      "- Recall : 97.368 %\n",
      "- F1 : 0.97493\n",
      "- Average Confidence : 20.13 %\n",
      "Model, Combined,,,,True,,,False,,,\n",
      "Twitter16-TF_2LMLP_DistilBERT_Finetuned_with_TopTermsVectors Test, 97.436, 97.619, 97.368, 0.97493, 100.0, 94.737, 0.97297, 95.238, 100.0, 0.97561, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "binary = True\n",
    "\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_2LMLP_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=1, criterion=nn.BCELoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                binary=binary,\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in val_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in test_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55461251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
