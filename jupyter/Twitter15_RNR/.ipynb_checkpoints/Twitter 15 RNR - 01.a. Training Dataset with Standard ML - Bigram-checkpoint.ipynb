{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feff3561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8a6e983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>691809004356501505</td>\n",
       "      <td>america is a nation of second chances â€”@potus ...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693204708933160960</td>\n",
       "      <td>brandon marshall visits and offers advice, sup...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>551099691702956032</td>\n",
       "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "1  714598641827246081  an open letter to trump voters from his top st...   \n",
       "2  691809004356501505  america is a nation of second chances â€”@potus ...   \n",
       "3  693204708933160960  brandon marshall visits and offers advice, sup...   \n",
       "4  551099691702956032  rip elly may clampett: so sad to learn #beverl...   \n",
       "\n",
       "        label       tvt  cv_fold        tt        tvt2  \n",
       "0  unverified  training        1  training    testting  \n",
       "1  unverified  training        1      test  validation  \n",
       "2   non-rumor  training        2  training    training  \n",
       "3   non-rumor  training        1  training    training  \n",
       "4        true  training        3  training  validation  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter15_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af92ba46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>unverified</th>\n",
       "      <th>non-rumor</th>\n",
       "      <th>true</th>\n",
       "      <th>false</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca kkk</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kkk grand</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grand wizard</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wizard endorses</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>endorses @hillaryclinton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      token  unverified  non-rumor  true  false\n",
       "0                    ca kkk           1          0     0      0\n",
       "1                 kkk grand           1          0     0      0\n",
       "2              grand wizard           1          0     0      0\n",
       "3           wizard endorses           1          0     0      0\n",
       "4  endorses @hillaryclinton           1          0     0      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_data = pd.read_excel('../../data/processed/twitter15_ngram_distribution.xlsx', sheet_name='bigram')\n",
    "bigram_data.columns = [\"token\", \"unverified\", \"non-rumor\", \"true\", \"false\"]\n",
    "bigram_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d048e008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bigram_vector_base = bigram_data['token'].tolist()\n",
    "# print(len(bigram_vector_base))\n",
    "# bigram_vector_base[10]\n",
    "\n",
    "bigram_vector_base = []\n",
    "with open(\"../../data/processed/twitter15_best_bigrams.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        bigram_vector_base.append(t)\n",
    "        \n",
    "len(bigram_vector_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63153167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>label_rnr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>validation</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>691809004356501505</td>\n",
       "      <td>america is a nation of second chances â€”@potus ...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>non-rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693204708933160960</td>\n",
       "      <td>brandon marshall visits and offers advice, sup...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>non-rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>551099691702956032</td>\n",
       "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "1  714598641827246081  an open letter to trump voters from his top st...   \n",
       "2  691809004356501505  america is a nation of second chances â€”@potus ...   \n",
       "3  693204708933160960  brandon marshall visits and offers advice, sup...   \n",
       "4  551099691702956032  rip elly may clampett: so sad to learn #beverl...   \n",
       "\n",
       "        label       tvt  cv_fold        tt        tvt2    label_rnr  \n",
       "0  unverified  training        1  training    testting      rumours  \n",
       "1  unverified  training        1      test  validation      rumours  \n",
       "2   non-rumor  training        2  training    training  non-rumours  \n",
       "3   non-rumor  training        1  training    training  non-rumours  \n",
       "4        true  training        3  training  validation      rumours  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_rnr = []\n",
    "for i, d in data.iterrows():\n",
    "    if d['label'] == \"non-rumor\":\n",
    "        label_rnr.append(\"non-rumours\")\n",
    "    else:\n",
    "        label_rnr.append(\"rumours\")\n",
    "        \n",
    "data['label_rnr'] = pd.Series(label_rnr)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b95fb4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rumour', 'non-rumour']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = ['rumour', 'non-rumour']\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6ce7b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 0, 1, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "#     lab = labels_str.index(d['label'])\n",
    "    if d['label'] in ['true', 'false', 'unverified']:\n",
    "        lab = 0\n",
    "    else:\n",
    "        lab = 1\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fc83a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "def text2bigrams(text):\n",
    "    bigrams = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    bigrams = [t for t in bigrams if t not in string.punctuation]\n",
    "    bigrams = [t for t in bigrams if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(bigrams)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def bigrams_vectors_generation(texts):\n",
    "    bigram_vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(bigram_vector_base) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in bigram_vector_base:\n",
    "                idx = bigram_vector_base.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        bigram_vectors.append(init_vec)\n",
    "    \n",
    "    return bigram_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97281e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 1501)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "vectors = bigrams_vectors_generation(texts)\n",
    "vectors = np.array(vectors)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "189f900d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ca kkk', 'kkk grand', 'grand wizard', 'wizard endorses', 'endorses @hillaryclinton', '@hillaryclinton #neverhillary', '#neverhillary #trump2016'], ['an open', 'open letter', 'letter to', 'to trump', 'trump voters', 'voters from', 'from his', 'his top', 'top strategist-turned-defector', 'strategist-turned-defector via', 'via @xojanedotcom'], ['america is', 'is a', 'a nation', 'nation of', 'of second', 'second chances', 'chances @potus', '@potus on', 'on new', 'new reforms', 'reforms to', 'to solitary', 'solitary confinement'], ['brandon marshall', 'marshall visits', 'visits and', 'and offers', 'offers advice', 'advice support', 'support to', 'to brother', 'brother of', 'of fallen', 'fallen hero', 'hero zaevion', 'zaevion dobson'], ['rip elly', 'elly may', 'may clampett', 'clampett so', 'so sad', 'sad to', 'to learn', 'learn #beverlyhillbillies', '#beverlyhillbillies star', 'star donna', 'donna douglas', 'douglas has', 'has passed', 'passed away']]\n",
      "(1490, 13842)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/storage/Work/DataScience/.venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "raw_texts = data['tweet_text'].tolist()\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "texts = [tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8')) for text in raw_texts]\n",
    "texts = [[t for t in text if t not in string.punctuation] for text in texts]\n",
    "texts = [[t for t in text if t not in ['URL', 'â€˜', 'â€™']] for text in texts]\n",
    "\n",
    "tokens = []\n",
    "\n",
    "for i, text in enumerate(texts):\n",
    "    bigrms = nltk.bigrams(text)\n",
    "    bigrms = map(' '.join, bigrms)\n",
    "    bigrms = [b for b in bigrms]\n",
    "    tokens.append(bigrms)\n",
    "print(tokens[:5])\n",
    "    \n",
    "corpus = tokens\n",
    "\n",
    "def identity_tokenizer(text):\n",
    "    return text\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=identity_tokenizer, stop_words=\"english\", lowercase=False)\n",
    "vectors = vectorizer.fit_transform(corpus)\n",
    "vectors = vectors.toarray()\n",
    "print(vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cccd2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f3f387c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RANDOM FOREST ---\n",
      "---> execution time : 4.98 seconds\n",
      "Execution Time : 4.98 seconds\n",
      "Validation Set\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 2\n",
      "False Positive : 0\n",
      "False Negative : 79\n",
      "True Negative : 261\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 100.0 %\n",
      "- Recall : 2.469 %\n",
      "- F1 : 0.04819\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 76.765 %\n",
      "- Recall : 100.0 %\n",
      "- F1 : 0.86855\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 76.901 %\n",
      "- Precision : 88.382 %\n",
      "- Recall : 51.235 %\n",
      "- F1 : 0.64867\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumour,,,rumour,,,\n",
      "Anonymous, 76.901, 88.382, 51.235, 0.64867, 100.0, 2.469, 0.04819, 76.765, 100.0, 0.86855, \n",
      "Test Set\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 0\n",
      "False Positive : 0\n",
      "False Negative : 41\n",
      "True Negative : 126\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 0 %\n",
      "- Recall : 0.0 %\n",
      "- F1 : 0\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 75.449 %\n",
      "- Recall : 100.0 %\n",
      "- F1 : 0.86007\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 75.449 %\n",
      "- Precision : 37.725 %\n",
      "- Recall : 50.0 %\n",
      "- F1 : 0.43004\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumour,,,rumour,,,\n",
      "Anonymous, 75.449, 37.725, 50.0, 0.43004, 0, 0.0, 0, 75.449, 100.0, 0.86007, \n",
      "--- END ---\n",
      "\n",
      "\n",
      "--- K-NEAREST NEIGHBOR ---\n",
      "---> execution time : 0.01 seconds\n",
      "Execution Time : 0.01 seconds\n",
      "Validation Set\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 17\n",
      "False Positive : 2\n",
      "False Negative : 64\n",
      "True Negative : 259\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 89.474 %\n",
      "- Recall : 20.988 %\n",
      "- F1 : 0.34\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 80.186 %\n",
      "- Recall : 99.234 %\n",
      "- F1 : 0.88699\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 80.702 %\n",
      "- Precision : 84.83 %\n",
      "- Recall : 60.111 %\n",
      "- F1 : 0.70363\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumour,,,rumour,,,\n",
      "Anonymous, 80.702, 84.83, 60.111, 0.70363, 89.474, 20.988, 0.34, 80.186, 99.234, 0.88699, \n",
      "Test Set\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 6\n",
      "False Positive : 0\n",
      "False Negative : 35\n",
      "True Negative : 126\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 100.0 %\n",
      "- Recall : 14.634 %\n",
      "- F1 : 0.25532\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 78.261 %\n",
      "- Recall : 100.0 %\n",
      "- F1 : 0.87805\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 79.042 %\n",
      "- Precision : 89.13 %\n",
      "- Recall : 57.317 %\n",
      "- F1 : 0.69768\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumour,,,rumour,,,\n",
      "Anonymous, 79.042, 89.13, 57.317, 0.69768, 100.0, 14.634, 0.25532, 78.261, 100.0, 0.87805, \n",
      "--- END ---\n",
      "\n",
      "\n",
      "--- SUPPORT VECTOR MACHINE ---\n",
      "---> execution time : 0.06 seconds\n",
      "Execution Time : 0.06 seconds\n",
      "Validation Set\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 9\n",
      "False Positive : 0\n",
      "False Negative : 72\n",
      "True Negative : 261\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 100.0 %\n",
      "- Recall : 11.111 %\n",
      "- F1 : 0.2\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 78.378 %\n",
      "- Recall : 100.0 %\n",
      "- F1 : 0.87879\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 78.947 %\n",
      "- Precision : 89.189 %\n",
      "- Recall : 55.556 %\n",
      "- F1 : 0.68465\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumour,,,rumour,,,\n",
      "Anonymous, 78.947, 89.189, 55.556, 0.68465, 100.0, 11.111, 0.2, 78.378, 100.0, 0.87879, \n",
      "Test Set\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 9\n",
      "False Positive : 0\n",
      "False Negative : 32\n",
      "True Negative : 126\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 100.0 %\n",
      "- Recall : 21.951 %\n",
      "- F1 : 0.36\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 79.747 %\n",
      "- Recall : 100.0 %\n",
      "- F1 : 0.88732\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 80.838 %\n",
      "- Precision : 89.873 %\n",
      "- Recall : 60.976 %\n",
      "- F1 : 0.72657\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumour,,,rumour,,,\n",
      "Anonymous, 80.838, 89.873, 60.976, 0.72657, 100.0, 21.951, 0.36, 79.747, 100.0, 0.88732, \n",
      "--- END ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from library.classification import SKLearnClassification\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "import time\n",
    "\n",
    "dataset_name = \"Phemernr\"\n",
    "\n",
    "random_forest = RandomForestClassifier(class_weight=\"balanced\")\n",
    "neigh = KNeighborsClassifier(n_neighbors=5, weights=\"distance\")\n",
    "svm = LinearSVC(class_weight=\"balanced\")\n",
    "\n",
    "models = [\n",
    "    SKLearnClassification(random_forest, \"Random Forest\"),\n",
    "    SKLearnClassification(neigh, \"K-Nearest Neighbor\"),\n",
    "    SKLearnClassification(svm, \"Support Vector Machine\"),\n",
    "]\n",
    "for model in models:\n",
    "    print(f\"\\n--- {model.model_name.upper()} ---\")\n",
    "    start = time.time()\n",
    "    model.train(train_vectors, train_labels, dataset_name)\n",
    "    print(f\"Execution Time : {round(time.time() - start, 2)} seconds\")\n",
    "    \n",
    "    print(\"Validation Set\")\n",
    "    preds = model.predict(val_vectors)\n",
    "\n",
    "    conf_mat = ConfusionMatrix(\n",
    "        labels=val_labels,\n",
    "        predictions=preds,\n",
    "        binary=True\n",
    "    )\n",
    "    conf_mat.evaluate(labels_str)\n",
    "    \n",
    "    print(\"Test Set\")\n",
    "    preds = model.predict(test_vectors)\n",
    "\n",
    "    conf_mat = ConfusionMatrix(\n",
    "        labels=test_labels,\n",
    "        predictions=preds,\n",
    "        binary=True\n",
    "    )\n",
    "    conf_mat.evaluate(labels_str)\n",
    "\n",
    "    print(\"--- END ---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1f3a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
