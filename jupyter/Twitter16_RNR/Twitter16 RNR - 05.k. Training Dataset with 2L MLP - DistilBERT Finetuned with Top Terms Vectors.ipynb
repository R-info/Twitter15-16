{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Twitter16-RNR\"\n",
    "unique_name = \"DistilBERT_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "terms_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(818, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter16-RNR_DistilBERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>656955120626880512</td>\n",
       "      <td>correct predictions in back to the future ii U...</td>\n",
       "      <td>false</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>615689290706595840</td>\n",
       "      <td>.@whitehouse in rainbow colors for #scotusmarr...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>613404935003217920</td>\n",
       "      <td>cops bought the alleged church shooter burger ...</td>\n",
       "      <td>false</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  656955120626880512  correct predictions in back to the future ii U...   \n",
       "1  615689290706595840  .@whitehouse in rainbow colors for #scotusmarr...   \n",
       "2  613404935003217920  cops bought the alleged church shooter burger ...   \n",
       "3  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "4  714598641827246081  an open letter to trump voters from his top st...   \n",
       "\n",
       "        label       tvt  cv_fold        tt        tvt2      tvt2_1    tvt2_2  \\\n",
       "0       false  training        1  training  validation    training  training   \n",
       "1        true  training        3  training    training  validation  training   \n",
       "2       false  training        2      test    training    training  training   \n",
       "3  unverified  training        3      test    training    training  training   \n",
       "4  unverified  training        1      test    training  validation  training   \n",
       "\n",
       "       tvt2_3  \n",
       "0  validation  \n",
       "1    training  \n",
       "2    training  \n",
       "3    training  \n",
       "4    training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter16_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rumour', 'non-rumour']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = ['rumour', 'non-rumour']\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [0], [0], [0], [0], [0], [0], [1], [1], [0]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "#     lab = labels_str.index(d['label'])\n",
    "    if d['label'] in ['true', 'false', 'unverified']:\n",
    "        lab = 0\n",
    "    else:\n",
    "        lab = 1\n",
    "    labels.append([lab])\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hostage situation', 'years ago', 'lindt cafe', '#opkkk #hoodsoff', 'el chapo', 'car dealership', '#charliehebdo attackers', \"what's the\", 'u s', 'from the']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_terms = []\n",
    "with open(\"../../data/processed/twitter16-rnr_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        vector_terms.append(t.strip())\n",
    "\n",
    "print(vector_terms[:10])\n",
    "len(vector_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2unigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(text)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def text2trigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    trigrams = nltk.trigrams(text)\n",
    "    trigrams = map(' '.join, trigrams)\n",
    "    trigrams = [bgr for bgr in trigrams]\n",
    "    \n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def bigrams_vectors_generation(texts):\n",
    "    bigram_vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(bigram_vector_base) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in bigram_vector_base:\n",
    "                idx = bigram_vector_base.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        bigram_vectors.append(init_vec)\n",
    "    \n",
    "    return bigram_vectors\n",
    "\n",
    "\n",
    "def custom_vectors_generation(texts, vector_terms):\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "        trigrams = text2trigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(vector_terms) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in vector_terms:\n",
    "                idx = vector_terms.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        for tgr in trigrams:\n",
    "            if tgr in vector_terms:\n",
    "                idx = vector_terms.index(tgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        vectors.append(init_vec)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(818, 1519)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "terms_vectors = custom_vectors_generation(texts, vector_terms)\n",
    "\n",
    "vectors = np.concatenate([vectors, terms_vectors], axis=1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(564, 1519)\n",
      "(172, 1519)\n",
      "(82, 1519)\n",
      "(564, 1)\n",
      "(172, 1)\n",
      "(82, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, n_output),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        binary: bool = False,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x, binary=binary)\n",
    "                if binary:\n",
    "                    preds = np.array([p[0] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([v[0] for v in test_y])\n",
    "                else:\n",
    "                    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y])\n",
    "                \n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=label_target,\n",
    "                    predictions=preds,\n",
    "                    binary=binary\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x, binary=False):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            \n",
    "            if binary:\n",
    "                return preds\n",
    "            else:\n",
    "                _, preds = torch.max(preds, dim = 1)\n",
    "                return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 84.302\n",
      "Saving after new best accuracy : 84.884\n",
      "-- Epoch 50, Train Loss : 0.0016566603444516659, Test Loss : 0.7287678122520447\n",
      "-- Epoch 100, Train Loss : 0.00029203345184214413, Test Loss : 0.9016929268836975\n",
      "-- Epoch 150, Train Loss : 6.970844697207212e-05, Test Loss : 1.0432846546173096\n",
      "-- Epoch 200, Train Loss : 2.724355636019027e-05, Test Loss : 1.1386009454727173\n",
      "-- Epoch 250, Train Loss : 1.3946251328889048e-05, Test Loss : 1.2091532945632935\n",
      "-- Epoch 300, Train Loss : 8.451003850495908e-06, Test Loss : 1.2632297277450562\n",
      "-- Epoch 350, Train Loss : 5.672491624864051e-06, Test Loss : 1.3066136837005615\n",
      "-- Epoch 400, Train Loss : 4.075431888850289e-06, Test Loss : 1.3432060480117798\n",
      "-- Epoch 450, Train Loss : 3.0595904263464035e-06, Test Loss : 1.3743839263916016\n",
      "-- Epoch 500, Train Loss : 2.3392419734591385e-06, Test Loss : 1.403404712677002\n",
      "-- Epoch 550, Train Loss : 1.8090736375597771e-06, Test Loss : 1.4295125007629395\n",
      "-- Epoch 600, Train Loss : 1.457497319279355e-06, Test Loss : 1.4524097442626953\n",
      "-- Epoch 650, Train Loss : 1.1923735314667283e-06, Test Loss : 1.473940134048462\n",
      "-- Epoch 700, Train Loss : 8.22341291950579e-07, Test Loss : 1.5064640045166016\n",
      "-- Epoch 750, Train Loss : 6.282943445512501e-07, Test Loss : 1.5315555334091187\n",
      "-- Epoch 800, Train Loss : 5.294395748478564e-07, Test Loss : 1.551186442375183\n",
      "-- Epoch 850, Train Loss : 4.5228289025089907e-07, Test Loss : 1.5719956159591675\n",
      "-- Epoch 900, Train Loss : 3.879856933508563e-07, Test Loss : 1.5851199626922607\n",
      "-- Epoch 950, Train Loss : 3.2643775682572596e-07, Test Loss : 1.6053576469421387\n",
      "-- Epoch 1000, Train Loss : 2.657136803918547e-07, Test Loss : 1.6160304546356201\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 13.69 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([172, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 23\n",
      "False Positive : 10\n",
      "False Negative : 16\n",
      "True Negative : 123\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 69.697 %\n",
      "- Recall : 58.974 %\n",
      "- F1 : 0.63889\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 88.489 %\n",
      "- Recall : 92.481 %\n",
      "- F1 : 0.90441\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 84.884 %\n",
      "- Precision : 79.093 %\n",
      "- Recall : 75.728 %\n",
      "- F1 : 0.77374\n",
      "- Average Confidence : 27.48 %\n",
      "Model, Combined,,,,non-rumour,,,rumour,,,\n",
      "Twitter16-RNR_2LMLP_DistilBERT_Finetuned_with_TopTermsVectors Validation, 84.884, 79.093, 75.728, 0.77374, 69.697, 58.974, 0.63889, 88.489, 92.481, 0.90441, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([82, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 14\n",
      "False Positive : 7\n",
      "False Negative : 7\n",
      "True Negative : 54\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 66.667 %\n",
      "- Recall : 66.667 %\n",
      "- F1 : 0.66667\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 88.525 %\n",
      "- Recall : 88.525 %\n",
      "- F1 : 0.88525\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 82.927 %\n",
      "- Precision : 77.596 %\n",
      "- Recall : 77.596 %\n",
      "- F1 : 0.77596\n",
      "- Average Confidence : 28.06 %\n",
      "Model, Combined,,,,non-rumour,,,rumour,,,\n",
      "Twitter16-RNR_2LMLP_DistilBERT_Finetuned_with_TopTermsVectors Test, 82.927, 77.596, 77.596, 0.77596, 66.667, 66.667, 0.66667, 88.525, 88.525, 0.88525, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "binary = True\n",
    "\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_2LMLP_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=1, criterion=nn.BCELoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                binary=binary,\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in val_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in test_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55461251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
