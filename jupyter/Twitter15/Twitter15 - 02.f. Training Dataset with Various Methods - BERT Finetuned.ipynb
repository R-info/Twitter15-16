{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "random.seed(33)\n",
    "\n",
    "unique_name = \"BERT_Finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter15_BERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>691809004356501505</td>\n",
       "      <td>america is a nation of second chances â€”@potus ...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693204708933160960</td>\n",
       "      <td>brandon marshall visits and offers advice, sup...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>551099691702956032</td>\n",
       "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "1  714598641827246081  an open letter to trump voters from his top st...   \n",
       "2  691809004356501505  america is a nation of second chances â€”@potus ...   \n",
       "3  693204708933160960  brandon marshall visits and offers advice, sup...   \n",
       "4  551099691702956032  rip elly may clampett: so sad to learn #beverl...   \n",
       "\n",
       "        label       tvt  cv_fold        tt      tvt2  \n",
       "0  unverified  training        1  training  training  \n",
       "1  unverified  training        1      test  training  \n",
       "2   non-rumor  training        2  training  training  \n",
       "3   non-rumor  training        1  training  testting  \n",
       "4        true  training        3  training  testting  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter15_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unverified', 'non-rumor', 'true', 'false']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = data['label'].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 2, 1, 0, 2, 0, 3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d['label'])\n",
    "#     labels.append([1 if j == lab else 0 for j in range(len(labels_str))])\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1017, 768)\n",
      "(328, 768)\n",
      "(145, 768)\n",
      "(1017,)\n",
      "(328,)\n",
      "(145,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, n_output),\n",
    "#             nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ce67903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from library.classification import SKLearnClassification\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Twitter15\"\n",
    "\n",
    "logres_model = LogisticRegression(random_state=0, solver='liblinear', multi_class='ovr', max_iter=10000)\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "svm = LinearSVC()\n",
    "\n",
    "models = [\n",
    "    SKLearnClassification(logres_model, \"Logistic Regression\"),\n",
    "    SKLearnClassification(neigh, \"K-Nearest Neighbor\"),\n",
    "    SKLearnClassification(svm, \"Support Vector Machine\"),\n",
    "]\n",
    "# for model in models:\n",
    "#     print(f\"\\n--- {model.model_name.upper()} ---\")\n",
    "#     model.train(train_vectors, train_labels, dataset_name)\n",
    "    \n",
    "#     print(\"Validation Set\")\n",
    "#     preds = model.predict(val_vectors)\n",
    "\n",
    "#     conf_mat = ConfusionMatrix(\n",
    "#         labels=val_labels,\n",
    "#         predictions=preds,\n",
    "#         binary=True\n",
    "#     )\n",
    "#     conf_mat.evaluate()\n",
    "    \n",
    "#     print(\"Test Set\")\n",
    "#     preds = model.predict(test_vectors)\n",
    "\n",
    "#     conf_mat = ConfusionMatrix(\n",
    "#         labels=test_labels,\n",
    "#         predictions=preds,\n",
    "#         binary=False\n",
    "#     )\n",
    "#     conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "#     print(\"--- END ---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd07cc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 24.085\n",
      "Saving after new best accuracy : 66.159\n",
      "Saving after new best accuracy : 79.573\n",
      "Saving after new best accuracy : 80.183\n",
      "Saving after new best accuracy : 80.488\n",
      "Saving after new best accuracy : 80.793\n",
      "Saving after new best accuracy : 81.098\n",
      "Saving after new best accuracy : 81.402\n",
      "-- Epoch 50, Train Loss : 0.0007915847818367183, Test Loss : 1.0974034070968628\n",
      "-- Epoch 100, Train Loss : 0.0001979486842174083, Test Loss : 1.2609628438949585\n",
      "-- Epoch 150, Train Loss : 8.946574962465093e-05, Test Loss : 1.3574672937393188\n",
      "-- Epoch 200, Train Loss : 5.098761903354898e-05, Test Loss : 1.4266680479049683\n",
      "-- Epoch 250, Train Loss : 3.290536642452935e-05, Test Loss : 1.4809415340423584\n",
      "-- Epoch 300, Train Loss : 2.297114497196162e-05, Test Loss : 1.5259166955947876\n",
      "-- Epoch 350, Train Loss : 1.6923644579946995e-05, Test Loss : 1.5643177032470703\n",
      "-- Epoch 400, Train Loss : 1.2953957593708765e-05, Test Loss : 1.597929835319519\n",
      "-- Epoch 450, Train Loss : 1.0198768450209172e-05, Test Loss : 1.6281460523605347\n",
      "-- Epoch 500, Train Loss : 8.209651014112751e-06, Test Loss : 1.6556695699691772\n",
      "-- Epoch 550, Train Loss : 6.739469881722471e-06, Test Loss : 1.6808581352233887\n",
      "-- Epoch 600, Train Loss : 5.614152996713528e-06, Test Loss : 1.7041072845458984\n",
      "-- Epoch 650, Train Loss : 4.742253167933086e-06, Test Loss : 1.725767731666565\n",
      "-- Epoch 700, Train Loss : 4.05603202580096e-06, Test Loss : 1.7460980415344238\n",
      "-- Epoch 750, Train Loss : 3.4963064763360308e-06, Test Loss : 1.7653154134750366\n",
      "-- Epoch 800, Train Loss : 3.0290806307675666e-06, Test Loss : 1.7835228443145752\n",
      "-- Epoch 850, Train Loss : 2.6432055619807215e-06, Test Loss : 1.8008307218551636\n",
      "-- Epoch 900, Train Loss : 2.327144670744019e-06, Test Loss : 1.8173571825027466\n",
      "-- Epoch 950, Train Loss : 2.0487390770540514e-06, Test Loss : 1.8331389427185059\n",
      "-- Epoch 1000, Train Loss : 1.816083113226341e-06, Test Loss : 1.8482913970947266\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 40.54 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([328])\n",
      "328 vs 328\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 81.707 %\n",
      "- Recall : 79.762 %\n",
      "- F1 : 0.80723\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 74.0 %\n",
      "- Recall : 86.047 %\n",
      "- F1 : 0.7957\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 89.041 %\n",
      "- Recall : 82.278 %\n",
      "- F1 : 0.85526\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 83.562 %\n",
      "- Recall : 77.215 %\n",
      "- F1 : 0.80263\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 81.402 %\n",
      "- Precision : 82.078 %\n",
      "- Recall : 81.326 %\n",
      "- F1 : 0.817\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Twitter15_4LayerNet_BERT_Finetuned Validation, 81.402, 82.078, 81.326, 0.817, 81.707, 79.762, 0.80723, 74.0, 86.047, 0.7957, 89.041, 82.278, 0.85526, 83.562, 77.215, 0.80263, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([145])\n",
      "145 vs 145\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 74.194 %\n",
      "- Recall : 65.714 %\n",
      "- F1 : 0.69697\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 65.217 %\n",
      "- Recall : 78.947 %\n",
      "- F1 : 0.71429\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 82.051 %\n",
      "- Recall : 88.889 %\n",
      "- F1 : 0.85333\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 82.759 %\n",
      "- Recall : 66.667 %\n",
      "- F1 : 0.73846\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 75.172 %\n",
      "- Precision : 76.055 %\n",
      "- Recall : 75.054 %\n",
      "- F1 : 0.75551\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Twitter15_4LayerNet_BERT_Finetuned Test, 75.172, 76.055, 75.054, 0.75551, 74.194, 65.714, 0.69697, 65.217, 78.947, 0.71429, 82.051, 88.889, 0.85333, 82.759, 66.667, 0.73846, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "start = time.time()\n",
    "model_name = f\"Twitter15_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55461251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
