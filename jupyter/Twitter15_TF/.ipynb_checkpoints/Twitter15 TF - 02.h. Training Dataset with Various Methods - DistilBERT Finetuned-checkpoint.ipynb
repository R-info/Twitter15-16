{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# random.seed(33)\n",
    "\n",
    "dataset_name = \"Twitter15-TF\"\n",
    "unique_name = \"DistilBERT_Finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(742, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter15-TF_DistilBERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>551099691702956032</td>\n",
       "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
       "      <td>True</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>514106273852174337</td>\n",
       "      <td>just in: missing afghan soldiers found trying ...</td>\n",
       "      <td>True</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>495366618818830336</td>\n",
       "      <td>#riphulkhogan my heart is ripping like your sh...</td>\n",
       "      <td>False</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>532206910796468224</td>\n",
       "      <td>a chick-fil-a manager allegedly banned this hi...</td>\n",
       "      <td>False</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>560187970389819392</td>\n",
       "      <td>islamic tribunal using sharia law in texas has...</td>\n",
       "      <td>False</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  551099691702956032  rip elly may clampett: so sad to learn #beverl...   \n",
       "1  514106273852174337  just in: missing afghan soldiers found trying ...   \n",
       "2  495366618818830336  #riphulkhogan my heart is ripping like your sh...   \n",
       "3  532206910796468224  a chick-fil-a manager allegedly banned this hi...   \n",
       "4  560187970389819392  islamic tribunal using sharia law in texas has...   \n",
       "\n",
       "   label        tvt2  \n",
       "0   True    training  \n",
       "1   True    training  \n",
       "2  False    training  \n",
       "3  False    training  \n",
       "4  False  validation  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter15-tf_dataset.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = data['label'].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 1, 1, 1, 1, 0, 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d['label'])\n",
    "#     labels.append([1 if j == lab else 0 for j in range(len(labels_str))])\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(514, 768)\n",
      "(165, 768)\n",
      "(63, 768)\n",
      "(514,)\n",
      "(165,)\n",
      "(63,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, n_output),\n",
    "#             nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ce67903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from library.classification import SKLearnClassification\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "logres_model = LogisticRegression(random_state=0, solver='liblinear', multi_class='ovr', max_iter=10000)\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "svm = LinearSVC()\n",
    "\n",
    "models = [\n",
    "    SKLearnClassification(logres_model, \"Logistic Regression\"),\n",
    "    SKLearnClassification(neigh, \"K-Nearest Neighbor\"),\n",
    "    SKLearnClassification(svm, \"Support Vector Machine\"),\n",
    "]\n",
    "# for model in models:\n",
    "#     print(f\"\\n--- {model.model_name.upper()} ---\")\n",
    "#     model.train(train_vectors, train_labels, dataset_name)\n",
    "    \n",
    "#     print(\"Validation Set\")\n",
    "#     preds = model.predict(val_vectors)\n",
    "\n",
    "#     conf_mat = ConfusionMatrix(\n",
    "#         labels=val_labels,\n",
    "#         predictions=preds,\n",
    "#         binary=True\n",
    "#     )\n",
    "#     conf_mat.evaluate()\n",
    "    \n",
    "#     print(\"Test Set\")\n",
    "#     preds = model.predict(test_vectors)\n",
    "\n",
    "#     conf_mat = ConfusionMatrix(\n",
    "#         labels=test_labels,\n",
    "#         predictions=preds,\n",
    "#         binary=False\n",
    "#     )\n",
    "#     conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "#     print(\"--- END ---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd07cc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 51.515\n",
      "Saving after new best accuracy : 80.0\n",
      "Saving after new best accuracy : 86.061\n",
      "Saving after new best accuracy : 88.485\n",
      "Saving after new best accuracy : 89.697\n",
      "Saving after new best accuracy : 90.303\n",
      "Saving after new best accuracy : 90.909\n",
      "Saving after new best accuracy : 91.515\n",
      "-- Epoch 50, Train Loss : 0.00034793574013747275, Test Loss : 0.545915424823761\n",
      "-- Epoch 100, Train Loss : 8.207633072743192e-05, Test Loss : 0.6499319076538086\n",
      "-- Epoch 150, Train Loss : 3.5980997836304596e-05, Test Loss : 0.7116401195526123\n",
      "-- Epoch 200, Train Loss : 1.9986853885711753e-05, Test Loss : 0.7559711933135986\n",
      "-- Epoch 250, Train Loss : 1.2707080486507039e-05, Test Loss : 0.7909151315689087\n",
      "-- Epoch 300, Train Loss : 8.783399266576453e-06, Test Loss : 0.8197771310806274\n",
      "-- Epoch 350, Train Loss : 6.349113050418964e-06, Test Loss : 0.8445103764533997\n",
      "-- Epoch 400, Train Loss : 4.8334923121728934e-06, Test Loss : 0.8662379384040833\n",
      "-- Epoch 450, Train Loss : 3.776166067837039e-06, Test Loss : 0.8856847882270813\n",
      "-- Epoch 500, Train Loss : 3.0847732546135376e-06, Test Loss : 0.9033955931663513\n",
      "-- Epoch 550, Train Loss : 2.4366433137856802e-06, Test Loss : 0.9192968010902405\n",
      "-- Epoch 600, Train Loss : 2.0203883082103857e-06, Test Loss : 0.9340201616287231\n",
      "-- Epoch 650, Train Loss : 1.681651127682926e-06, Test Loss : 0.9476576447486877\n",
      "-- Epoch 700, Train Loss : 1.4635103013915796e-06, Test Loss : 0.9603416919708252\n",
      "-- Epoch 750, Train Loss : 1.2251070842239642e-06, Test Loss : 0.9723990559577942\n",
      "-- Epoch 800, Train Loss : 1.0795987321898792e-06, Test Loss : 0.9835919141769409\n",
      "-- Epoch 850, Train Loss : 9.587678135858368e-07, Test Loss : 0.994408369064331\n",
      "-- Epoch 900, Train Loss : 8.56561300111025e-07, Test Loss : 1.0048776865005493\n",
      "-- Epoch 950, Train Loss : 7.105810446716987e-07, Test Loss : 1.0145349502563477\n",
      "-- Epoch 1000, Train Loss : 6.395712794926567e-07, Test Loss : 1.023819923400879\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAFXCAYAAAC1NambAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAArI0lEQVR4nO3de5xVdb3/8ddnBphxgEBQK2ZgRk/oL0TEnCNpebyAJ7PUczxlGhaWxgMs0exoGmXmkXPqdI7mNaQOajreMm8pHVOzpOMtMCVQScIBBm8Igigit8/vj7U2bIeZfZnZa6/5zn4/H4/9YK/LrPXdezbz3t/L+i5zd0RERApVlXYBREQkLAoOEREpioJDRESKouAQEZGiKDhERKQoCg4RESmKgkOkm8zsUDNbXMbz/YeZnV2u83Vw/ovM7KYc258ys33LWSYpLwWHdIuZtZrZhLTLUU5m5mb2kcyyu891933KdO7dgS8D15bjfF30X8DFaRdCkqPgEOmEmfVJuwwdOBWY4+7vpl2QHO4FjjCzD6VdEEmGgkMSYWY1ZvYTM3s5fvzEzGribbuZ2X1mttbM1pjZXDOrird928xWmtl6M1tsZuM7Of4gM/uFma0ys2Vm9l0zq4rPu9bMRmftu7uZvWtme8TLnzWzZ+L9HjOzMVn7tsZlWAC80z48zOzR+OmzZva2mX3BzA43s7Z2xzjXzBaY2Ttm9j9m9kEz+038uh4ys12z9v94XI61ZvasmR2e4639NPCHdmXK93ouMLPnzOxNM7vOzGqztn/NzJbEv4d7zWxY1rZ9zezBeNtrZvadrNP2i9//9Wa2yMyaMxvcfSMwH/hUjtchIXN3PfTo8gNoBSZ0sP5i4AlgD2B34DHg3+Jt/wHMBPrGj0MBA/YBVgDD4v2agL/r5Ly/AO4BBsb7/RU4Ld42G5iRte/Xgf+Nnx8AvA6MA6qBSfFrqMl6Pc8Aw4FdOjm3Ax/JWj4caGv3njwBfBCoj8/3dHzuWuB3wPfjfeuB1cAxRF/kjoqXd+/k3KuAv89aLuT1LIxfzxDg/4BL4m1HAm8AHwNqgCuBR+NtA4FXgG/FZR4IjIu3XQRsjMtcHf8+n2hXziuAS9P+fOqRzEM1DknKROBid3/d3VcBPwC+FG/bDHwYaHT3zR71ETiwlegP2Cgz6+vure7+t/YHNrNq4CTgAndf7+6twH9nHf/meHvGF+N1AJOBa939SXff6u43AO8BH8/a/wp3X+Hdaw660t1fc/eVwFzgSXf/s0ffxu8i+oMPcApR09Mcd9/m7g8C84j+KHdkMLA+a7mQ13NV/HrWADOAk+P1E4HZ7v60u78HXAAcbGZNwGeBV939v919Y/w+P5l1zD/GZd4K3Ajs366c6+OySi+k4JCkDAOWZS0vi9cB/BhYAvzWzJaa2fkA7r4EOJvoG+3rZnZrdtNJlt2Iairtj18fP38EqDOzcfEfwbFEf6wBGoFvxc06a81sLdG38ezzrCj2xXbgtazn73awPCCrPJ9vV55PEgVrR94k+vafUezryf49vO935O5vE9V26uNj7BTaWV7Ner4BqG3XrDcQWJvj5yVgCg5JystEf9QyRsTriL+9fsvd9wKOA87J9GW4+83u/sn4Zx34UQfHfoOo1tL++CvjY2wFbif6Zn0ycJ+7Z76lryBqxhqc9ahz91uyjlXOKaNXADe2K09/d/9hJ/svAPZu9/P5Xs/wrOfbfw+0+x2ZWX9gKNH7uALYqxuv66PAs934eenBFBxSCn3NrDbr0Qe4Bfhu3DG9G3AhcBNs78z9iJkZsI6oiWqbme1jZkfGnegbib6Zb2t/sqxgmGFmA82sETgnc/zYzcAXiJpjbs5a/zNgSlwbMTPrb2afMbPsb/H5vEb3/qhmuwk41sw+ZWbV8ft3uJk1dLL/HOCwrOVCXs/XzazBzIYA04Hb4vW3AF8xs7Hxe/7vRE1qrcB9wIfN7Ox4wMFAMxtXyAuKO98PBB4s8D2QwCg4pBTmEP2RzzwuAi4haqtfAPyFqHP4knj/kcBDwNvA48A17v4IUf/GD4lqFK8Sdaxf0Mk5zwTeAZYCfyQKh9mZjXF7/DtEzTG/yVo/D/gacBVRs88SoiGuxbgIuCFuGjqxyJ99H3dfARwPfIeo43sFcC6d/9/8BXCMme0S/3whr+dm4LdE79XfiH8P7v4Q8D3gV0Qd4X9H3DcU19COAo4l+l28CBxR4Ms6Fvi9u7+cd08JkkV9kiISCjP7d+B1d/9JAfu2AqfHIVEWZvYk0Qi3heU6p5RXT7zASURycPfv5N8rPe5eUJOWhEtNVSIiUhQ1VYmISFFU4xARkaIoOEREpCjBdY6b7ebR1ESRAw9MrywiIqGYP3/+G+6+eymOFVxwRKExD4DGRpg3L9XCiIgEwcyW5d+rMME2VdXVwYwZaZdCRKTyBBkcI0bArFkwcWLaJRERqTwBNlXB4sVQW5t/PxERKb0gaxxbtqRdAhGRyhVkcGzenHYJREQqV5DBoRqHiEh6FBwiIlKUIINDTVUiIukJMjhU4xARSY+CQ0REihJkcKipSkQkPUEGh2ocIiLpUXCIiEhRggyOv/97aGqClpa0SyIiUnmCDA53WLYMJk9WeIiIlFuQwZGxYQNMn552KUREKkvQwQGwfHnaJRARqSzBB8eIEWmXQESksgQdHLoLoIhI+QUZHGbR/cZ1F0ARkfIL8g6At94KJ56YdilERCpTYjUOM5ttZq+b2cJOtk80swVm9hcze8zM9i/02LoAUEQkPUk2VV0PHJ1j+0vAYe6+H/BvwKxCD6y5qkRE0pNYU5W7P2pmTTm2P5a1+ATQUOixVeMQEUlPT+kcPw34TaE7KzhERNKTeue4mR1BFByfzLHPZGBytHSgmqpERFKUao3DzMYAPweOd/fVne3n7rPcvdndm0E1DhGRNKUWHGY2ArgT+JK7/7WYn1VwiIikJ7GmKjO7BTgc2M3M2oDvA30B3H0mcCEwFLjGzAC2ZGoU+aipSkQkPUmOqjo5z/bTgdO7cmzVOERE0tNTRlUVRcEhIpKeIINDTVUiIukJLjjMVOMQEUmTgkNERIoSXHBs2waXXQZNTbrfuIhIGoILjoxly2DyZIWHiEi5BRscABs2wPTpaZdCRKSyBB0cAMuXp10CEZHKEnxwjBiRdglERCpL0MFRVwczZqRdChGRyhJscDQ2wqxZMHFi2iUREaksqd+Po1i1tXDccXDbbWmXRESkMgVZ49i6Ne0SiIhUruCCwyy6CFBERNIRXHCAahwiImkKLjhU4xARSVdwwQGqcYiIpCm44DBTcIiIpCm44AA1VYmIpCm44FCNQ0QkXcEFB6jGISKSpuCCQzUOEZF0BRccoBqHiEiaggsO1ThERNIVXHCAahwiImkKLjhU4xARSVdwwQGqcYiIpCm44FCNQ0QkXcEFB6jGISKSpuCCQzUOEZFOtLRATU30h7Ld40A4sFSnCS44QDUOEalQZ5zRYShsf5xyCmzalHgxgrvnuGocItJrTZgADz+cdinyCi44QDUOEQlUIMGQT3BNVapxiEiPla8pqReEBiQYHGY228xeN7OFnWw3M7vCzJaY2QIz+1ihx1aNQ0RSkS8YfvrTtEtYFknWOK4Hjs6x/dPAyPgxGSjoHVeNQ0QSNWFCxQdDPokFh7s/CqzJscvxwC888gQw2Mw+XMixVeMQkS7LMWS1NzUnATB1KriDO/NhfqkOm2YfRz2wImu5LV63EzObbGbzzGzexo3vqsYhIrnlalIq05DVxNXWwk03bQ+GDh/XXJPIqYPoHHf3We7e7O7NGzbswhtvQFNT9MVBRCpUrnDoDU1K48fnDoV334WJE1MpWprDcVcCw7OWG+J1OWWaqZYtg8mTo+cpvXcikrQzzugdIdCR8ePhoYfSLkWXpFnjuBf4cjy66uPAOnd/pZgDbNgA06cnUzgRKZNcfQ4hh8aAAbmbkgINDUiwxmFmtwCHA7uZWRvwfaAvgLvPBOYAxwBLgA3AV7pynuXLS1FaEUlcL7n4bbvaWvj5zyuyySOx4HD3k/Nsd+Dr3T3PiBHdPYKIlExLC3z1q72j8xmCbk5KUhCd452pq4MZM9IuhUgF6qx5KcQRS1lDVntTc1KSgguOqrjEjY0wa1ZF1hJFyqezkUshBUS+YasJDVntzYKb5HCPPWDVKmhtTbskIr1I6P0PFdzfkIbgahxmunJcpMs6q0GEEBq5ag4pXtNQiYKrcUD0ORGRHEK+/mHqVDUf9XBBBgdE4WGWdilEeoAQm5k0WiloQTZVgZqrpAKF2MzU2YglhUbQgq1xbNsG1dVpl0IkIaE1Nal5qaIEFxyqcUivE0pT04ABMHOmOqElvODIUHBIkEIICfU/SB7B9XFkKDikx+voTnI9KTQ6G96q0JA8ggsONVVJj9RRx3VPCYnOAkLXPkgXBdtUpWs5JDU9eSI/NTNJGQRX48hQjUPKpn1toifM06RmJklRcDUONVVJ4npaB7bmYZIeJrjgyFBwSEn0tGYnNTVJAIJrqlKNQ7qlJzU7jR+vpiYJkmoc0rv1lGYn1SSkFwmuxpGh4JAOtb92Io3Q6KjjWqEhvUhwwaGmKnmf9k1PaQRF+4n8dH2E9HLBNlXpOo4KlfbkfxrhJBJucKjGUSHSHvWkvgmRnaipSnqe7H6Kco96at/spNAQ2UlwwZGh4OhFWlqgpqb8/RQDBuzcia17SojkFVxTlWocvUQafRVqdhIpieCCI0PBEaByX1OhoBBJhJqqJDnlboJqf/2EQkMkEcHVODJNVRqO20OVcxSUhsaKpEI1Dum+7JpF0qOgskc96UI7kVQEW+NQcKSsXDUL9VOI9DiqcUjhylWzyK5VKDREepzgahwZCo4yKUfNQn0VIkEJLjjUVFUmSQ+dVROUSLASbaoys6PNbLGZLTGz8zvYPsLMHjGzP5vZAjM7ptBjKzgSkD3TbBKhoSYokV4hseAws2rgauDTwCjgZDMb1W637wK3u/sBwElAwfM9aDhuiWT3WyRxJXd2WGg6D5FeIckax0HAEndf6u6bgFuB49vt48AH4ueDgJfzHVRNVSWSqV0k0cmtsBDp1ZLs46gHVmQttwHj2u1zEfBbMzsT6A9MKPTgCo4uSLKje+pUhYRIhUh7OO7JwPXu3gAcA9xoZjuVycwmm9k8M5u3bt06QMFRlKRqF6pZiFSkJINjJTA8a7khXpftNOB2AHd/HKgFdmt/IHef5e7N7t48ePAgQMFRkMx9LUrZd6GwEKl4SQbHn4CRZranmfUj6vy+t90+y4HxAGb2UaLgWFXIwRUcOWQCo1Qjo8aPV1iIyHaJBYe7bwG+ATwAPE80emqRmV1sZsfFu30L+JqZPQvcApzqnnu8lDrHO5E9OqoUgZE906yGzopIlkQvAHT3OcCcdusuzHr+HPCJrhxbwRFraYFJk2Dr1tIcT53cIpJHcFeOZ1T8dRylvLJbU36ISBHSHlVVtLfeiv49+mhoaoq+cFeUUvZfZDq6NT25iBQhuBrHq69G/7rDsmUweXK03Ov/7pWqhqHahYh0U3A1jvZNVBs2wPTp6ZSlLDLXYHQ3NDIjo1S7EJFuCq7G0ZHly9MuQQLOOKM0119oFloRKbHgahwdGTEi7RKUUEsLVFV1PzQy/RcKDREpseBqHGbvb66qq4MZM9IrT0ntuy8891zXf94MpkzRcFoRSVRwNY5hw6J/zaCxEWbN6gVN9pmRUl0NjUz/xbZtCg0RSVxwwTEomqqK226D1tbAQ6OlpXsd35nAUHOUiJRRkE1V0AuuHO9Os9SoUbBoUWnLIyJSoOBqHBnBBkdmeG1XQqNPn2j+KIWGiKRINY5yqq+Hl/Pe5HBn1dVwww2Bt8uJSG+hGkc5ZGoZXQmNqVNhyxaFhoj0GMHVODKCCY6u1jJ04Z6I9FDB1TiCaarKjJgqNjSGDdNIKRHp0QoKDjPrn7kXuJntbWbHmVnfZIuWW4+eVn3ChOj+3sWaOhVWtr+7rohIz1JoU9WjwKFmtivwW6Lbwn4BSK3hvcfWOLrSNKXhtSISkEKbqszdNwAnANe4++eBfZMrVo6C9NSmqq40TZlpeK2IBKfQGoeZ2cFENYzT4nXVyRSpMD0qOLpyrwzVMkQkUIXWOM4GLgDucvdFZrYX8Ehipcqhx9U49t23uNBQLUNEAldQjcPd/wD8ASDuJH/D3aclWbB8ekRwFNufMWyYOr9FJHiFjqq62cw+YGb9gYXAc2Z2brJF61ifZ+fzEk185KmUbza+667Fhcb48QoNEekVCm2qGuXubwH/BPwG2BP4UlKFyqeJZYy/dXLUIZ2GXXeFtWsL2zfTNKXrMkSklyg0OPrG1238E3Cvu28GUr2Sou/mlG42XkxoDBsWtalpuhAR6UUKDY5rgVagP/ComTUCbyVVqIKV+2bjxYSGmqZEpJcqKDjc/Qp3r3f3YzyyDDgi4bLlV86bjRcTGlOnqmlKRHqtQjvHB5nZpWY2L378N1HtIzWb+5bxZuOFhkamP0O3bxWRXqzQCwBnE42mOjFe/hJwHdGV5GXnwOa+u1CWybIKDY3Bg+HNN5MujYhI6goNjr9z93/JWv6BmT2TQHkKYkDdhtUweXK0IqnOZ4WGiMhOCu0cf9fMPplZMLNPAO8mU6QibEhwZJVCQ0SkQ4XWOKYAvzCzQfHym8CkZIpUpCRGVtXXKzRERDpR6JQjzwL7m9kH4uW3zOxsYEGCZStMqUdW7btvYVeEKzREpEIVdQdAd38rvoIc4JwEylOcuhKPrJowAZ57Lv9+Cg0RqWDduXWslawURXLgzQ80wqxZpesYb2kpbJZbhYaIVLjuBEfeKUfM7GgzW2xmS8zs/E72OdHMnjOzRWZ2cyEnPqfqcn789dbSjqaaVECXjUJDRCR3H4eZrafjgDBglzw/Ww1cDRwFtAF/MrN73f25rH1GEt3n4xPu/qaZ7VFIoXexd0s7rXp9PWzdmnsfM4WGiAh5gsPdB3bj2AcBS9x9KYCZ3QocD2R3InwNuNrd34zP93ohB97FNrK+VMExYUJhneE33liiE4qIhK07TVX51AMrspbb4nXZ9gb2NrP/M7MnzOzojg5kZpMz050AfHfLRVxwbVP3p1UvtF9j6lTNcCsiEiv0Oo4kzz8SOBxoIJp5dz93X5u9k7vPAmYBNJu5Abu+taz7V46femr+fcaP19xTIiJZkqxxrASGZy03xOuytRHf38PdXwL+ShQkhenOleMTJsCWLbn3GTZMs9yKiLSTZHD8CRhpZnuaWT/gJODedvvcTVTbwMx2I2q6WlrUWbpy5XghTVRmup+GiEgHEgsOd98CfAN4AHgeuN3dF5nZxWZ2XLzbA8BqM3sOeAQ4191XF3Wirlw5XkgTlTrDRUQ6lGgfh7vPAea0W3dh1nMnugK9a1ehd+XK8TPOyN9ENX68OsNFRDph0d/ucDRXVfmf3FkzoJGhM2cU/wfe8lzwXl2dP1hERAJjZvPdvbkUx0qyjyMZdXX8od9RTJ/YWnxoTJiQf58bbuhSsUREKkV4wWFGPzYVf+V4IR3iaqISEcmrcoJjypTc26urNfRWRKQAYQaHFxkcLS3w9tu591ETlYhIQcILjqoq+hZb48hX2+jXT01UIiIFCi84im2qKqS2MXt2t4slIlIpggyOvsU0VeWrbfTvr9qGiEgRwguOtWsZvuUlLrurKf/suIXUNq69tmRFExGpBOFdAGjm8+LnG6yOp6fM4pPXdFJj2G03WJ1jBpP+/fMHi4hIL1DZFwBmqfMNjJg5vfOKR67QANU2RES6IOjgAGjw5R3PrJ6vGUt9GyIiXRJ8cCxnRMczq59+eu4fVG1DRKRLgg6Od6jjO8zYeWb1lhbYuLHzH1RtQ0Sky4ILjq1UA7CM4XyNWdxTN3HnmdXPOiv3QVTbEBHpsuBGVY0aOtyfW9PGB1jHkMYPMKOjmdXzTZ0e2GsWEemuUo6qSvRGTkmo62+wBj474T1ufrCDHfJ1ik+dmki5REQqRXBNVZnaRPXWTR1vz9dMdc01JS6QiEhlCS84qqIiV23pJDhyXbsxdGgCBRIRqSzhBUeuGke+ZqrLL0+gQCIilaV3BUe+ZioNwRUR6bZgg6Oqo+BQM5WISOLCC464j6O6fR+HmqlERMoivOCIaxx9trULDjVTiYiURXjBsX49AJcvOAKamnbUNNRMJSJSFsFdAMirrwJgOCxbBpMn5/8ZNVOJiJRMcFOOZN/IabuhQ3PXOAJ7jSIipaYbObWX74ZNIiJSMr0jOHJpbEy7BCIivUp4wdF+5tu6utz77zTnuoiIdEd4wTF8OAAOUW1i0qTc+2sYrohISYUXHEOGAPBfwy6D1laYMyfd8oiIVJjwgqP9BYDLlnW+r/o3RERKLtHgMLOjzWyxmS0xs/Nz7PcvZuZmln+oWGaSw0xwVOV4CerfEBEpucSCw8yqgauBTwOjgJPNbFQH+w0EzgKeLPDAQFaNY9u2zvdV/4aISMklWeM4CFji7kvdfRNwK3B8B/v9G/AjYGOhB95c1S8KjnwTG4qISMklGRz1wIqs5bZ43XZm9jFguLvfX/BR16yhettmvrbmR7lHVGl+KhGRRKQ2V5WZVQGXAqcWsO9kYDLAx8yoIp5CZOvWzn9I81OJiCQiyRrHSmB41nJDvC5jIDAa+L2ZtQIfB+7tqIPc3We5e7O7N1sh806ZqX9DRCQhSQbHn4CRZranmfUDTgLuzWx093Xuvpu7N7l7E/AEcJz7znMYFk2TGoqIJCax4HD3LcA3gAeA54Hb3X2RmV1sZscldV4AqqsTPbyISCULb1r16mqfl2sIbkZgr0tEJEmVPa16YyObqmvJGQu6YlxEJDHhBceQISwa/unc++iKcRGRxIR369g1axjV9kLn2zWiSkQkUeEFx7Jl1OTq41DfhohIosJrqsrXMa4rxkVEEhVecIiISKp6X3CsWZN2CUREerXggmNbviKPGFGegoiIVKjggmMZjbmv4dBQXBGRRAUXHDn176+huCIiCQsuOOpZiXW2sba2nEUREalIwQVHPzZ1vlEd4yIiiQsuOLZV9+t845Ah5SuIiEiFCi44qoYMyt05LiIiiQouOFizpvM+DjVViYgkLrzgyHWfcV3DISKSuPCCIxddwyEikrjwgqOz28LqGg4RkbIILzhGjGBr+5FV/frBtdemUx4RkQoTXnAMGcLcr86mlUbcLLpN7OzZqm2IiJRJeMEBrDh0InvSytIXt0Frq0JDRKSMggyOPvF9C7dsSbccIiKVSMEhIiJFUXCIiEhRFBwiIlIUBYeIiBRFwSEiIkVRcIiISFEUHCIiUhQFh4iIFEXBISIiRQkyOH772+jfY4+FpiZoaUm1OCIiFSW44FizBi65JHruDsuWweTJCg8RkXIJLjhWroSNG9+/bsMGmD49nfKIiFSaRIPDzI42s8VmtsTMzu9g+zlm9pyZLTCzh82sMd8xN23qeP3y5d0vr4iI5JdYcJhZNXA18GlgFHCymY1qt9ufgWZ3HwPcAfxnvuP269fxet1uXESkPJKscRwELHH3pe6+CbgVOD57B3d/xN03xItPAA35DlpfD7vs8v51dXW63biISLkkGRz1wIqs5bZ4XWdOA37T0QYzm2xm88xs3tatq/jxj3dsa2yEWbN0LycRkXLpEZ3jZnYK0Az8uKPt7j7L3ZvdvXn33XfnxBOj9VddpRsAioiUW58Ej70SGJ613BCvex8zmwBMBw5z9/cKObAuABQRSU+SNY4/ASPNbE8z6wecBNybvYOZHQBcCxzn7q8XemAFh4hIehILDnffAnwDeAB4Hrjd3ReZ2cVmdly824+BAcAvzewZM7u3k8O9j4JDRCQ9STZV4e5zgDnt1l2Y9XxCV46r4BDpPTZv3kxbWxsb21/ZK11SW1tLQ0MDffv2TewciQZHUqqro38VHCLha2trY+DAgTQ1NWFmaRcnaO7O6tWraWtrY88990zsPD1iVFWxqqqih4JDJHwbN25k6NChCo0SMDOGDh2aeO0tyOCAqLlKwSHSOyg0Sqcc76WCQ0Qq2urVqxk7dixjx47lQx/6EPX19duXN3U2OV5s3rx5TJs2rajzNTU18cYbb3SnyKkLso8DFBwilaqlJZoNe/nyaI66GTO6dxHw0KFDeeaZZwC46KKLGDBgAP/6r/+6ffuWLVvo06fjP5XNzc00Nzd3/eSBUo1DRILR0hLdf2fZsmTvx3PqqacyZcoUxo0bx3nnncdTTz3FwQcfzAEHHMAhhxzC4sWLAfj973/PZz/7WSAKna9+9ascfvjh7LXXXlxxxRUFn6+1tZUjjzySMWPGMH78eJbH033/8pe/ZPTo0ey///78wz/8AwCLFi3ioIMOYuzYsYwZM4YXX3yxtC++AEHWOFpaYO3aaMqRX/+6+984RKRnOPtsiL/8d+iJJ+C9dvNLbNgAp50GP/tZxz8zdiz85CfFl6WtrY3HHnuM6upq3nrrLebOnUufPn146KGH+M53vsOvfvWrnX7mhRde4JFHHmH9+vXss88+TJ06taBhsWeeeSaTJk1i0qRJzJ49m2nTpnH33Xdz8cUX88ADD1BfX8/atWsBmDlzJmeddRYTJ05k06ZNbN26tfgX103BBceaNdE3jG3bouXMNw5QeIj0du1DI9/67vj85z9PdTz2f926dUyaNIkXX3wRM2Pz5s0d/sxnPvMZampqqKmpYY899uC1116joSHvpN88/vjj3HnnnQB86Utf4rzzzgPgE5/4BKeeeionnngiJ5xwAgAHH3wwM2bMoK2tjRNOOIGRI0eW4uUWJbjgWLly55s5Ze4AqOAQCVu+mkFTU/Rlsb3GRvj970tblv79+29//r3vfY8jjjiCu+66i9bWVg4//PAOf6ampmb78+rqarZ0sz195syZPPnkk9x///0ceOCBzJ8/ny9+8YuMGzeO+++/n2OOOYZrr72WI488slvnKVZwfRy6A6BI5ZoxI7r/TrZy3I9n3bp11NdHd4W4/vrrS378Qw45hFtvvRWAlpYWDj30UAD+9re/MW7cOC6++GJ23313VqxYwdKlS9lrr72YNm0axx9/PAsWLCh5efIJLjh0B0CRyjVxYnT/ncZGMCvf/XjOO+88LrjgAg444IBu1yIAxowZQ0NDAw0NDZxzzjlceeWVXHfddYwZM4Ybb7yRyy+/HIBzzz2X/fbbj9GjR3PIIYew//77c/vttzN69GjGjh3LwoUL+fKXv9zt8hTL3L3sJ+2OvfZq9tdem8eGDTvW1dXpZk4ioXr++ef56Ec/mnYxepWO3lMzm+/uJRk7HFyNY8iQKCQyNQ/dAVBEpLyC6xyHHdVVs9J3iImISG7B1TgyamqSGYInIiK5KThERKQoQQdHnvnHREQkAUEHh2ocIiLlF2RwtLTAPffAkiXRlaSlnuBMRCpHd6ZVh2iiw8cee6zDbddffz3f+MY3Sl3k1AUXHJm5qt55J1pOanZMEemhWlqib4xVVSX55piZVv2ZZ55hypQpfPOb39y+3K+zK46z5AqO3iq44Fi5kvdd/Ac75qoSkV6uTPOqz58/n8MOO4wDDzyQT33qU7zyyisAXHHFFYwaNYoxY8Zw0kkn0draysyZM7nssssYO3Ysc+fOLej4l156KaNHj2b06NH8JJ6g65133uEzn/kM+++/P6NHj+a2224D4Pzzz99+zuz7hKQpuOs4NFeVSC/WA+ZVd3fOPPNM7rnnHnbffXduu+02pk+fzuzZs/nhD3/ISy+9RE1NDWvXrmXw4MFMmTJlp5s/5TJ//nyuu+46nnzySdydcePGcdhhh7F06VKGDRvG/fffD0TzY61evZq77rqLF154ATPbPrV62oKrcWiuKpEKVoZ51d977z0WLlzIUUcdxdixY7nkkktoa2sDojmmJk6cyE033dTpXQHz+eMf/8g///M/079/fwYMGMAJJ5zA3Llz2W+//XjwwQf59re/zdy5cxk0aBCDBg2itraW0047jTvvvJO69jM8piS4Gkd9Pbz2GjvNVZX07JgiUgY9YF51d2fffffl8ccf32nb/fffz6OPPsqvf/1rZsyYwV/+8peSnBNg77335umnn2bOnDl897vfZfz48Vx44YU89dRTPPzww9xxxx1cddVV/O53vyvZObsquBpHZq6qIUOi5fp6zVUlUjHKMK96TU0Nq1at2h4cmzdvZtGiRWzbto0VK1ZwxBFH8KMf/Yh169bx9ttvM3DgQNavX1/w8Q899FDuvvtuNmzYwDvvvMNdd93FoYceyssvv0xdXR2nnHIK5557Lk8//TRvv/0269at45hjjuGyyy7j2WefLdnr7I7gahwQhURVFXzxi/Dww7DPPmmXSETKIvMNcfr0qGNzxIiS3zu6qqqKO+64g2nTprFu3Tq2bNnC2Wefzd57780pp5zCunXrcHemTZvG4MGDOfbYY/nc5z7HPffcw5VXXrn9XhoZ119/PXfffff25SeeeIJTTz2Vgw46CIDTTz+dAw44gAceeIBzzz2Xqqoq+vbty09/+lPWr1/P8ccfz8aNG3F3Lr300pK9zu4Iblr15uZmnzdvHt/6Flx6aTTRYQKfHREpE02rXnqaVr0DLS1w9dXR8wRH5ImISAeCDI7p0zsekadrOUREkhdkcHR2zYau5RARSV6QwZEZUVXoehHp2ULra+3JyvFeBhkcItJ71NbWsnr1aoVHCbg7q1evpra2NtHzBDkcd/Xq4taLSM/V0NBAW1sbq1atSrsovUJtbS0NDQ2JniPI4Kiuhq1bO95mtuP51KlwzTXlKZOIdE3fvn3Zc8890y6GFCHI6zjmz5+XdjFERALTjPs8y79ffkH2cTQ2pl0CEZHKFWRwaEJDEZH0BNdUZWbrgcWw7yio3SXt8oiIhKEV9zdK0lQVYuf44lLNtxI6M5un9yKi92IHvRc76L3YwcxK1jkcZFOViIikR8EhIiJFCTE4ZqVdgB5E78UOei920Huxg96LHUr2XgTXOS4iIukKscYhIiIpCio4zOxoM1tsZkvM7Py0y5MkMxtuZo+Y2XNmtsjMzorXDzGzB83sxfjfXeP1ZmZXxO/NAjP7WLqvoPTMrNrM/mxm98XLe5rZk/Frvs3M+sXra+LlJfH2plQLXmJmNtjM7jCzF8zseTM7uFI/F2b2zfj/x0Izu8XMaivpc2Fms83sdTNbmLWu6M+CmU2K93/RzCblO28wwWFm1cDVwKeBUcDJZjYq3VIlagvwLXcfBXwc+Hr8es8HHnb3kcDD8TJE78vI+DEZ+Gn5i5y4s4Dns5Z/BFzm7h8B3gROi9efBrwZr78s3q83uRz4X3f/f8D+RO9JxX0uzKwemAY0u/tooBo4icr6XFwPHN1uXVGfBTMbAnwfGAccBHw/EzadcvcgHsDBwANZyxcAF6RdrjK+/nuAo4DFwIfjdR8muq4F4Frg5Kz9t+/XGx5AQ/yf4EjgPsCAN4A+7T8fwAPAwfHzPvF+lvZrKNH7MAh4qf3rqcTPBVAPrACGxL/n+4BPVdrnAmgCFnb1swCcDFybtf59+3X0CKbGwY4PSUZbvK7Xi6vUBwBPAh9091fiTa8CH4yf9/b35yfAecC2eHkosNbdt8TL2a93+3sRb18X798b7AmsAq6Lm+1+bmb9qcDPhbuvBP4LWA68QvR7nk9lfi6yFftZKPozElJwVCQzGwD8Cjjb3d/K3ubR14NePyzOzD4LvO7u89MuSw/QB/gY8FN3PwB4hx1NEUBFfS52BY4nCtNhQH92brapaEl9FkIKjpXA8Kzlhnhdr2VmfYlCo8Xd74xXv2ZmH463fxh4PV7fm9+fTwDHmVkrcCtRc9XlwGAzy0ybk/16t78X8fZBQG+5zVcb0ObuT8bLdxAFSSV+LiYAL7n7KnffDNxJ9FmpxM9FtmI/C0V/RkIKjj8BI+MRE/2IOsHuTblMiTEzA/4HeN7dL83adC+QGfUwiajvI7P+y/HIiY8D67Kqq0Fz9wvcvcHdm4h+779z94nAI8Dn4t3avxeZ9+hz8f694hu4u78KrDCzfeJV44HnqMDPBVET1cfNrC7+/5J5Lyruc9FOsZ+FB4B/NLNd41rcP8brOpd2x06RnUDHAH8F/gZMT7s8Cb/WTxJVMRcAz8SPY4jaZB8GXgQeAobE+xvRqLO/AX8hGmmS+utI4H05HLgvfr4X8BSwBPglUBOvr42Xl8Tb90q73CV+D8YC8+LPxt3ArpX6uQB+ALwALARuBGoq6XMB3ELUv7OZqDZ6Wlc+C8BX4/dlCfCVfOfVleMiIlKUkJqqRESkB1BwiIhIURQcIiJSFAWHiIgURcEhIiJFUXCItGNmW83smaxHyWZiNrOm7JlMRULUJ/8uIhXnXXcfm3YhRHoq1ThECmRmrWb2n2b2FzN7ysw+Eq9vMrPfxfc4eNjMRsTrP2hmd5nZs/HjkPhQ1Wb2s/g+Er81s11Se1EiXaDgENnZLu2aqr6QtW2du+8HXEU0Yy/AlcAN7j4GaAGuiNdfAfzB3fcnmk9qUbx+JHC1u+8LrAX+JdFXI1JiunJcpB0ze9vdB3SwvhU40t2XxhNQvuruQ83sDaL7H2yO17/i7ruZ2Sqgwd3fyzpGE/CgRzfZwcy+DfR190vK8NJESkI1DpHieCfPi/Fe1vOtqK9RAqPgECnOF7L+fTx+/hjRrL0AE4G58fOHgamw/X7pg8pVSJEk6ZuOyM52MbNnspb/190zQ3J3NbMFRLWGk+N1ZxLdke9corvzfSVefxYwy8xOI6pZTCWayVQkaOrjEClQ3MfR7O5vpF0WkTSpqUpERIqiGoeIiBRFNQ4RESmKgkNERIqi4BARkaIoOEREpCgKDhERKYqCQ0REivL/AUKnPIBf5Dh0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 27.12 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([165])\n",
      "165 vs 165\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class True Evaluation\n",
      "- Precision : 90.805 %\n",
      "- Recall : 92.941 %\n",
      "- F1 : 0.9186\n",
      "\n",
      "Class False Evaluation\n",
      "- Precision : 92.308 %\n",
      "- Recall : 90.0 %\n",
      "- F1 : 0.91139\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 91.515 %\n",
      "- Precision : 91.556 %\n",
      "- Recall : 91.471 %\n",
      "- F1 : 0.91513\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,True,,,False,,,\n",
      "Twitter15-TF_4LayerNet_DistilBERT_Finetuned Validation, 91.515, 91.556, 91.471, 0.91513, 90.805, 92.941, 0.9186, 92.308, 90.0, 0.91139, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([63])\n",
      "63 vs 63\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class True Evaluation\n",
      "- Precision : 90.909 %\n",
      "- Recall : 100.0 %\n",
      "- F1 : 0.95238\n",
      "\n",
      "Class False Evaluation\n",
      "- Precision : 100.0 %\n",
      "- Recall : 90.909 %\n",
      "- F1 : 0.95238\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 95.238 %\n",
      "- Precision : 95.455 %\n",
      "- Recall : 95.455 %\n",
      "- F1 : 0.95455\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,True,,,False,,,\n",
      "Twitter15-TF_4LayerNet_DistilBERT_Finetuned Test, 95.238, 95.455, 95.455, 0.95455, 90.909, 100.0, 0.95238, 100.0, 90.909, 0.95238, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=2, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55461251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
