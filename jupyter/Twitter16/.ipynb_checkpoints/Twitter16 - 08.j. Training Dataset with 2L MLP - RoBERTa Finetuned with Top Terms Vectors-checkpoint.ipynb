{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Twitter16-Multi\"\n",
    "unique_name = \"RoBERTa_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "bigram_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(818, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter16_RoBERTa_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>656955120626880512</td>\n",
       "      <td>correct predictions in back to the future ii U...</td>\n",
       "      <td>false</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>615689290706595840</td>\n",
       "      <td>.@whitehouse in rainbow colors for #scotusmarr...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>613404935003217920</td>\n",
       "      <td>cops bought the alleged church shooter burger ...</td>\n",
       "      <td>false</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  656955120626880512  correct predictions in back to the future ii U...   \n",
       "1  615689290706595840  .@whitehouse in rainbow colors for #scotusmarr...   \n",
       "2  613404935003217920  cops bought the alleged church shooter burger ...   \n",
       "3  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "4  714598641827246081  an open letter to trump voters from his top st...   \n",
       "\n",
       "        label       tvt  cv_fold        tt        tvt2      tvt2_1    tvt2_2  \\\n",
       "0       false  training        1  training  validation    training  training   \n",
       "1        true  training        3  training    training  validation  training   \n",
       "2       false  training        2      test    training    training  training   \n",
       "3  unverified  training        3      test    training    training  training   \n",
       "4  unverified  training        1      test    training  validation  training   \n",
       "\n",
       "       tvt2_3  \n",
       "0  validation  \n",
       "1    training  \n",
       "2    training  \n",
       "3    training  \n",
       "4    training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter16_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['false', 'true', 'unverified', 'non-rumor']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = data['label'].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 2, 2, 1, 2, 3, 3, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d['label'])\n",
    "    labs = [1 if idx == lab else 0 for idx in range(len(labels_str))]\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['el chapo', '#opkkk #hoodsoff', 'mass shootings', 'red cross', 'burger king', 'the future', 'new cnn', 'new orleans', 'poll @hillaryclinton', 'that he']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_terms = []\n",
    "with open(\"../../data/processed/twitter16-multi_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        vector_terms.append(t.strip())\n",
    "\n",
    "print(vector_terms[:10])\n",
    "len(vector_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2unigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(text)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def text2trigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    trigrams = nltk.trigrams(text)\n",
    "    trigrams = map(' '.join, trigrams)\n",
    "    trigrams = [bgr for bgr in trigrams]\n",
    "    \n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def custom_vectors_generation(texts, vector_terms):\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "        trigrams = text2trigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(vector_terms) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in vector_terms:\n",
    "                idx = vector_terms.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        for tgr in trigrams:\n",
    "            if tgr in vector_terms:\n",
    "                idx = vector_terms.index(tgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        vectors.append(init_vec)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(818, 1519)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "terms_vectors = custom_vectors_generation(texts, vector_terms)\n",
    "\n",
    "vectors = np.concatenate([vectors, terms_vectors], axis=1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(564, 1519)\n",
      "(172, 1519)\n",
      "(82, 1519)\n",
      "(564,)\n",
      "(172,)\n",
      "(82,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, n_output)\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 79.651\n",
      "Saving after new best accuracy : 81.977\n",
      "Saving after new best accuracy : 82.558\n",
      "-- Epoch 50, Train Loss : 0.00508832698687911, Test Loss : 0.9103626012802124\n",
      "-- Epoch 100, Train Loss : 0.0010391960968263447, Test Loss : 1.0904768705368042\n",
      "-- Epoch 150, Train Loss : 0.000410592183470726, Test Loss : 1.2018394470214844\n",
      "-- Epoch 200, Train Loss : 0.00020294857677072287, Test Loss : 1.286513328552246\n",
      "-- Epoch 250, Train Loss : 0.00012310294914641418, Test Loss : 1.348557949066162\n",
      "-- Epoch 300, Train Loss : 8.39058448036667e-05, Test Loss : 1.3972793817520142\n",
      "-- Epoch 350, Train Loss : 5.593572132056579e-05, Test Loss : 1.4473412036895752\n",
      "-- Epoch 400, Train Loss : 3.939945327147143e-05, Test Loss : 1.4934020042419434\n",
      "-- Epoch 450, Train Loss : 3.00209521810757e-05, Test Loss : 1.5298810005187988\n",
      "-- Epoch 500, Train Loss : 2.3742494704492856e-05, Test Loss : 1.5615020990371704\n",
      "-- Epoch 550, Train Loss : 1.9269154108769726e-05, Test Loss : 1.5898818969726562\n",
      "-- Epoch 600, Train Loss : 1.5922950296953786e-05, Test Loss : 1.6157567501068115\n",
      "-- Epoch 650, Train Loss : 1.3381251847022213e-05, Test Loss : 1.6396418809890747\n",
      "-- Epoch 700, Train Loss : 1.1375456324458355e-05, Test Loss : 1.6618859767913818\n",
      "-- Epoch 750, Train Loss : 9.76742467173608e-06, Test Loss : 1.6827442646026611\n",
      "-- Epoch 800, Train Loss : 8.464980055578053e-06, Test Loss : 1.702436089515686\n",
      "-- Epoch 850, Train Loss : 7.378577947747544e-06, Test Loss : 1.7211227416992188\n",
      "-- Epoch 900, Train Loss : 6.493209411928547e-06, Test Loss : 1.738929271697998\n",
      "-- Epoch 950, Train Loss : 5.726133849748294e-06, Test Loss : 1.7559651136398315\n",
      "-- Epoch 1000, Train Loss : 5.063221351520042e-06, Test Loss : 1.7722876071929932\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 33.66 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : (172,)\n",
      "172 vs 172\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 73.913 %\n",
      "- Recall : 85.0 %\n",
      "- F1 : 0.7907\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 87.755 %\n",
      "- Recall : 91.489 %\n",
      "- F1 : 0.89583\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 87.805 %\n",
      "- Recall : 78.261 %\n",
      "- F1 : 0.82759\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 80.556 %\n",
      "- Recall : 74.359 %\n",
      "- F1 : 0.77333\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 82.558 %\n",
      "- Precision : 82.507 %\n",
      "- Recall : 82.277 %\n",
      "- F1 : 0.82392\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,false,,,true,,,unverified,,,non-rumor,,,\n",
      "Twitter16-Multi_4LayerNet_RoBERTa_Finetuned_with_TopTermsVectors Validation, 82.558, 82.507, 82.277, 0.82392, 73.913, 85.0, 0.7907, 87.755, 91.489, 0.89583, 87.805, 78.261, 0.82759, 80.556, 74.359, 0.77333, \n",
      "\n",
      "Test Set\n",
      "Predictions : (82,)\n",
      "82 vs 82\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 73.077 %\n",
      "- Recall : 90.476 %\n",
      "- F1 : 0.80851\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 81.818 %\n",
      "- Recall : 85.714 %\n",
      "- F1 : 0.83721\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 78.947 %\n",
      "- Recall : 78.947 %\n",
      "- F1 : 0.78947\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 86.667 %\n",
      "- Recall : 61.905 %\n",
      "- F1 : 0.72222\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 79.268 %\n",
      "- Precision : 80.127 %\n",
      "- Recall : 79.261 %\n",
      "- F1 : 0.79692\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,false,,,true,,,unverified,,,non-rumor,,,\n",
      "Twitter16-Multi_4LayerNet_RoBERTa_Finetuned_with_TopTermsVectors Test, 79.268, 80.127, 79.261, 0.79692, 73.077, 90.476, 0.80851, 81.818, 85.714, 0.83721, 78.947, 78.947, 0.78947, 86.667, 61.905, 0.72222, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "preds = preds.cpu().numpy()\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "preds = preds.cpu().numpy()\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55461251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
