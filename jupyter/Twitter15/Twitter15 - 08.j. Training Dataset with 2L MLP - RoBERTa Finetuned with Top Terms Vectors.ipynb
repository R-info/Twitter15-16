{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Twitter15-Multi\"\n",
    "unique_name = \"RoBERTa_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "bigram_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter15_RoBERTa_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>691809004356501505</td>\n",
       "      <td>america is a nation of second chances â€”@potus ...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693204708933160960</td>\n",
       "      <td>brandon marshall visits and offers advice, sup...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>551099691702956032</td>\n",
       "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "1  714598641827246081  an open letter to trump voters from his top st...   \n",
       "2  691809004356501505  america is a nation of second chances â€”@potus ...   \n",
       "3  693204708933160960  brandon marshall visits and offers advice, sup...   \n",
       "4  551099691702956032  rip elly may clampett: so sad to learn #beverl...   \n",
       "\n",
       "        label       tvt  cv_fold        tt        tvt2      tvt2_1  \\\n",
       "0  unverified  training        1  training    training  validation   \n",
       "1  unverified  training        1      test    training    testting   \n",
       "2   non-rumor  training        2  training  validation  validation   \n",
       "3   non-rumor  training        1  training    testting    testting   \n",
       "4        true  training        3  training  validation    training   \n",
       "\n",
       "       tvt2_2    tvt2_3  \n",
       "0    training  training  \n",
       "1    training  training  \n",
       "2  validation  testting  \n",
       "3    training  training  \n",
       "4  validation  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter15_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unverified', 'non-rumor', 'true', 'false']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = data['label'].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 2, 1, 0, 2, 0, 3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d['label'])\n",
    "    labs = [1 if idx == lab else 0 for idx in range(len(labels_str))]\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#ferguson pd', 'bathroom policy', 'institutional racism', 'want to', 'bag charge', 'ios 8', 'can be', 'clinton campaign', 'new transgender', 'protest at']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_terms = []\n",
    "with open(\"../../data/processed/twitter15-multi_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        vector_terms.append(t.strip())\n",
    "\n",
    "print(vector_terms[:10])\n",
    "len(vector_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2unigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(text)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def text2trigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    trigrams = nltk.trigrams(text)\n",
    "    trigrams = map(' '.join, trigrams)\n",
    "    trigrams = [bgr for bgr in trigrams]\n",
    "    \n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def custom_vectors_generation(texts, vector_terms):\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "        trigrams = text2trigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(vector_terms) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in vector_terms:\n",
    "                idx = vector_terms.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        for tgr in trigrams:\n",
    "            if tgr in vector_terms:\n",
    "                idx = vector_terms.index(tgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        vectors.append(init_vec)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 1519)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "terms_vectors = custom_vectors_generation(texts, vector_terms)\n",
    "\n",
    "vectors = np.concatenate([vectors, terms_vectors], axis=1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1004, 1519)\n",
      "(355, 1519)\n",
      "(131, 1519)\n",
      "(1004,)\n",
      "(355,)\n",
      "(131,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, n_output)\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 82.817\n",
      "-- Epoch 50, Train Loss : 0.004090497735887766, Test Loss : 0.9403989315032959\n",
      "-- Epoch 100, Train Loss : 0.0009527792572043836, Test Loss : 1.1255251169204712\n",
      "Saving after new best accuracy : 83.099\n",
      "-- Epoch 150, Train Loss : 0.0004032130818814039, Test Loss : 1.2367823123931885\n",
      "-- Epoch 200, Train Loss : 0.00021671856666216627, Test Loss : 1.3180086612701416\n",
      "-- Epoch 250, Train Loss : 0.00013314091484062374, Test Loss : 1.38587486743927\n",
      "-- Epoch 300, Train Loss : 8.751413770369254e-05, Test Loss : 1.4480395317077637\n",
      "-- Epoch 350, Train Loss : 5.986334144836292e-05, Test Loss : 1.4983936548233032\n",
      "-- Epoch 400, Train Loss : 3.624021883297246e-05, Test Loss : 1.5564234256744385\n",
      "-- Epoch 450, Train Loss : 2.6160482775594573e-05, Test Loss : 1.6012272834777832\n",
      "-- Epoch 500, Train Loss : 2.0231379494362045e-05, Test Loss : 1.637131929397583\n",
      "-- Epoch 550, Train Loss : 1.616029203432845e-05, Test Loss : 1.6683237552642822\n",
      "-- Epoch 600, Train Loss : 1.289043666474754e-05, Test Loss : 1.698023796081543\n",
      "-- Epoch 650, Train Loss : 1.0362963166699046e-05, Test Loss : 1.7258274555206299\n",
      "-- Epoch 700, Train Loss : 8.470692591799889e-06, Test Loss : 1.7514519691467285\n",
      "-- Epoch 750, Train Loss : 6.539848300235462e-06, Test Loss : 1.7769863605499268\n",
      "-- Epoch 800, Train Loss : 4.98691542816232e-06, Test Loss : 1.8009321689605713\n",
      "-- Epoch 850, Train Loss : 4.035760639453656e-06, Test Loss : 1.822074055671692\n",
      "-- Epoch 900, Train Loss : 3.350229121679149e-06, Test Loss : 1.841603398323059\n",
      "-- Epoch 950, Train Loss : 2.818133452819893e-06, Test Loss : 1.8598846197128296\n",
      "-- Epoch 1000, Train Loss : 2.399928916929639e-06, Test Loss : 1.877070426940918\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 41.01 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : (355,)\n",
      "355 vs 355\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 78.082 %\n",
      "- Recall : 73.077 %\n",
      "- F1 : 0.75497\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 73.737 %\n",
      "- Recall : 83.908 %\n",
      "- F1 : 0.78495\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 91.398 %\n",
      "- Recall : 91.398 %\n",
      "- F1 : 0.91398\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 88.889 %\n",
      "- Recall : 82.474 %\n",
      "- F1 : 0.85561\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 83.099 %\n",
      "- Precision : 83.027 %\n",
      "- Recall : 82.714 %\n",
      "- F1 : 0.8287\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Twitter15-Multi_4LayerNet_RoBERTa_Finetuned_with_TopTermsVectors Validation, 83.099, 83.027, 82.714, 0.8287, 78.082, 73.077, 0.75497, 73.737, 83.908, 0.78495, 91.398, 91.398, 0.91398, 88.889, 82.474, 0.85561, \n",
      "\n",
      "Test Set\n",
      "Predictions : (131,)\n",
      "131 vs 131\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 75.61 %\n",
      "- Recall : 86.111 %\n",
      "- F1 : 0.80519\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 89.655 %\n",
      "- Recall : 83.871 %\n",
      "- F1 : 0.86667\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 87.879 %\n",
      "- Recall : 85.294 %\n",
      "- F1 : 0.86567\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 85.714 %\n",
      "- Recall : 80.0 %\n",
      "- F1 : 0.82759\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 83.969 %\n",
      "- Precision : 84.715 %\n",
      "- Recall : 83.819 %\n",
      "- F1 : 0.84265\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Twitter15-Multi_4LayerNet_RoBERTa_Finetuned_with_TopTermsVectors Test, 83.969, 84.715, 83.819, 0.84265, 75.61, 86.111, 0.80519, 89.655, 83.871, 0.86667, 87.879, 85.294, 0.86567, 85.714, 80.0, 0.82759, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "preds = preds.cpu().numpy()\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "preds = preds.cpu().numpy()\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55461251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
