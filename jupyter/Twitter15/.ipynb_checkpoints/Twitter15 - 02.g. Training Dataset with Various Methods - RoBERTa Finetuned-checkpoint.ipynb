{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "random.seed(33)\n",
    "\n",
    "unique_name = \"RoBERTa_Finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter15_RoBERTa_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>691809004356501505</td>\n",
       "      <td>america is a nation of second chances â€”@potus ...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693204708933160960</td>\n",
       "      <td>brandon marshall visits and offers advice, sup...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>551099691702956032</td>\n",
       "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "1  714598641827246081  an open letter to trump voters from his top st...   \n",
       "2  691809004356501505  america is a nation of second chances â€”@potus ...   \n",
       "3  693204708933160960  brandon marshall visits and offers advice, sup...   \n",
       "4  551099691702956032  rip elly may clampett: so sad to learn #beverl...   \n",
       "\n",
       "        label       tvt  cv_fold        tt      tvt2  \n",
       "0  unverified  training        1  training  training  \n",
       "1  unverified  training        1      test  training  \n",
       "2   non-rumor  training        2  training  training  \n",
       "3   non-rumor  training        1  training  testting  \n",
       "4        true  training        3  training  testting  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter15_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unverified', 'non-rumor', 'true', 'false']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = data['label'].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 2, 1, 0, 2, 0, 3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d['label'])\n",
    "#     labels.append([1 if j == lab else 0 for j in range(len(labels_str))])\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1017, 768)\n",
      "(328, 768)\n",
      "(145, 768)\n",
      "(1017,)\n",
      "(328,)\n",
      "(145,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, n_output),\n",
    "#             nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ce67903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from library.classification import SKLearnClassification\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Twitter15\"\n",
    "\n",
    "logres_model = LogisticRegression(random_state=0, solver='liblinear', multi_class='ovr', max_iter=10000)\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "svm = LinearSVC()\n",
    "\n",
    "models = [\n",
    "    SKLearnClassification(logres_model, \"Logistic Regression\"),\n",
    "    SKLearnClassification(neigh, \"K-Nearest Neighbor\"),\n",
    "    SKLearnClassification(svm, \"Support Vector Machine\"),\n",
    "]\n",
    "# for model in models:\n",
    "#     print(f\"\\n--- {model.model_name.upper()} ---\")\n",
    "#     model.train(train_vectors, train_labels, dataset_name)\n",
    "    \n",
    "#     print(\"Validation Set\")\n",
    "#     preds = model.predict(val_vectors)\n",
    "\n",
    "#     conf_mat = ConfusionMatrix(\n",
    "#         labels=val_labels,\n",
    "#         predictions=preds,\n",
    "#         binary=True\n",
    "#     )\n",
    "#     conf_mat.evaluate()\n",
    "    \n",
    "#     print(\"Test Set\")\n",
    "#     preds = model.predict(test_vectors)\n",
    "\n",
    "#     conf_mat = ConfusionMatrix(\n",
    "#         labels=test_labels,\n",
    "#         predictions=preds,\n",
    "#         binary=False\n",
    "#     )\n",
    "#     conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "#     print(\"--- END ---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd07cc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 79.268\n",
      "Saving after new best accuracy : 81.402\n",
      "Saving after new best accuracy : 82.622\n",
      "Saving after new best accuracy : 82.927\n",
      "-- Epoch 50, Train Loss : 0.0007883306534495205, Test Loss : 1.3253021240234375\n",
      "-- Epoch 100, Train Loss : 0.00019741702999453992, Test Loss : 1.5203194618225098\n",
      "-- Epoch 150, Train Loss : 8.927570161176845e-05, Test Loss : 1.632460117340088\n",
      "-- Epoch 200, Train Loss : 5.084488475404214e-05, Test Loss : 1.712257981300354\n",
      "-- Epoch 250, Train Loss : 3.281157114543021e-05, Test Loss : 1.77460777759552\n",
      "-- Epoch 300, Train Loss : 2.2947871912037954e-05, Test Loss : 1.8256560564041138\n",
      "-- Epoch 350, Train Loss : 1.695376431598561e-05, Test Loss : 1.8689484596252441\n",
      "-- Epoch 400, Train Loss : 1.3023061001149472e-05, Test Loss : 1.9066884517669678\n",
      "-- Epoch 450, Train Loss : 1.0295249467162648e-05, Test Loss : 1.940256953239441\n",
      "-- Epoch 500, Train Loss : 8.323653673869558e-06, Test Loss : 1.9706792831420898\n",
      "-- Epoch 550, Train Loss : 6.862564532639226e-06, Test Loss : 1.9985113143920898\n",
      "-- Epoch 600, Train Loss : 5.75215335629764e-06, Test Loss : 2.0241219997406006\n",
      "-- Epoch 650, Train Loss : 4.846524916501949e-06, Test Loss : 2.047917604446411\n",
      "-- Epoch 700, Train Loss : 4.185048624094634e-06, Test Loss : 2.070296049118042\n",
      "-- Epoch 750, Train Loss : 3.5801865578832803e-06, Test Loss : 2.091233730316162\n",
      "-- Epoch 800, Train Loss : 3.123446049357881e-06, Test Loss : 2.110886573791504\n",
      "-- Epoch 850, Train Loss : 2.7742318025048007e-06, Test Loss : 2.1296205520629883\n",
      "-- Epoch 900, Train Loss : 2.4570645109633915e-06, Test Loss : 2.147700309753418\n",
      "-- Epoch 950, Train Loss : 2.1335962969715183e-06, Test Loss : 2.1650826930999756\n",
      "-- Epoch 1000, Train Loss : 1.8960526517730614e-06, Test Loss : 2.181574821472168\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 40.74 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([328])\n",
      "328 vs 328\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 84.615 %\n",
      "- Recall : 78.571 %\n",
      "- F1 : 0.81481\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 75.258 %\n",
      "- Recall : 84.884 %\n",
      "- F1 : 0.79781\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 94.366 %\n",
      "- Recall : 84.81 %\n",
      "- F1 : 0.89333\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 80.488 %\n",
      "- Recall : 83.544 %\n",
      "- F1 : 0.81988\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 82.927 %\n",
      "- Precision : 83.682 %\n",
      "- Recall : 82.952 %\n",
      "- F1 : 0.83315\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Twitter15_4LayerNet_RoBERTa_Finetuned Validation, 82.927, 83.682, 82.952, 0.83315, 84.615, 78.571, 0.81481, 75.258, 84.884, 0.79781, 94.366, 84.81, 0.89333, 80.488, 83.544, 0.81988, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([145])\n",
      "145 vs 145\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 75.0 %\n",
      "- Recall : 60.0 %\n",
      "- F1 : 0.66667\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 72.727 %\n",
      "- Recall : 84.211 %\n",
      "- F1 : 0.78049\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 83.784 %\n",
      "- Recall : 86.111 %\n",
      "- F1 : 0.84932\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 66.667 %\n",
      "- Recall : 66.667 %\n",
      "- F1 : 0.66667\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 74.483 %\n",
      "- Precision : 74.544 %\n",
      "- Recall : 74.247 %\n",
      "- F1 : 0.74395\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Twitter15_4LayerNet_RoBERTa_Finetuned Test, 74.483, 74.544, 74.247, 0.74395, 75.0, 60.0, 0.66667, 72.727, 84.211, 0.78049, 83.784, 86.111, 0.84932, 66.667, 66.667, 0.66667, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "start = time.time()\n",
    "model_name = f\"Twitter15_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55461251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
