{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Twitter15-RNR\"\n",
    "unique_name = \"RoBERTa_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "terms_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter15-RNR_RoBERTa_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>691809004356501505</td>\n",
       "      <td>america is a nation of second chances â€”@potus ...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693204708933160960</td>\n",
       "      <td>brandon marshall visits and offers advice, sup...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>551099691702956032</td>\n",
       "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "1  714598641827246081  an open letter to trump voters from his top st...   \n",
       "2  691809004356501505  america is a nation of second chances â€”@potus ...   \n",
       "3  693204708933160960  brandon marshall visits and offers advice, sup...   \n",
       "4  551099691702956032  rip elly may clampett: so sad to learn #beverl...   \n",
       "\n",
       "        label       tvt  cv_fold        tt        tvt2      tvt2_1  \\\n",
       "0  unverified  training        1  training    training  validation   \n",
       "1  unverified  training        1      test    training    testting   \n",
       "2   non-rumor  training        2  training  validation  validation   \n",
       "3   non-rumor  training        1  training    testting    testting   \n",
       "4        true  training        3  training  validation    training   \n",
       "\n",
       "       tvt2_2    tvt2_3  \n",
       "0    training  training  \n",
       "1    training  training  \n",
       "2  validation  testting  \n",
       "3    training  training  \n",
       "4  validation  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter15_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rumour', 'non-rumour']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = ['rumour', 'non-rumour']\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [0], [1], [1], [0], [1], [0], [0], [0], [0]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "#     lab = labels_str.index(d['label'])\n",
    "    if d['label'] in ['true', 'false', 'unverified']:\n",
    "        lab = 0\n",
    "    else:\n",
    "        lab = 1\n",
    "    labels.append([lab])\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"paul walker's\", 'us to', 'to watch', 'plan to', 'steps to', 'of the day', 'paul walker', 'want to', 'in ukraine', 'woman who']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_terms = []\n",
    "with open(\"../../data/processed/twitter15-rnr_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        vector_terms.append(t.strip())\n",
    "\n",
    "print(vector_terms[:10])\n",
    "len(vector_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2unigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(text)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def text2trigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    trigrams = nltk.trigrams(text)\n",
    "    trigrams = map(' '.join, trigrams)\n",
    "    trigrams = [bgr for bgr in trigrams]\n",
    "    \n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def bigrams_vectors_generation(texts):\n",
    "    bigram_vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(bigram_vector_base) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in bigram_vector_base:\n",
    "                idx = bigram_vector_base.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        bigram_vectors.append(init_vec)\n",
    "    \n",
    "    return bigram_vectors\n",
    "\n",
    "\n",
    "def custom_vectors_generation(texts, vector_terms):\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "        trigrams = text2trigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(vector_terms) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in vector_terms:\n",
    "                idx = vector_terms.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        for tgr in trigrams:\n",
    "            if tgr in vector_terms:\n",
    "                idx = vector_terms.index(tgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        vectors.append(init_vec)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 1519, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "terms_vectors = custom_vectors_generation(texts, vector_terms)\n",
    "\n",
    "vectors = np.concatenate([vectors, terms_vectors], axis=1)\n",
    "vectors = vectors.reshape(vectors.shape[0], vectors.shape[1], 1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1004, 1519, 1)\n",
      "(355, 1519, 1)\n",
      "(131, 1519, 1)\n",
      "(1004, 1)\n",
      "(355, 1)\n",
      "(131, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv1d(n_input, 512, 1, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 128, 1, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=1, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, n_output),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        binary: bool = False,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                \n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x, binary=binary)\n",
    "                if binary:\n",
    "                    preds = np.array([p[0] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([v[0] for v in test_y])\n",
    "                else:\n",
    "                    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y])\n",
    "                \n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=label_target,\n",
    "                    predictions=preds,\n",
    "                    binary=binary\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x, binary=False):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            \n",
    "            if binary:\n",
    "                return preds\n",
    "            else:\n",
    "                _, preds = torch.max(preds, dim = 1)\n",
    "                return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 85.07\n",
      "Saving after new best accuracy : 85.352\n",
      "-- Epoch 50, Train Loss : 0.1528964638710022, Test Loss : 0.5296916365623474\n",
      "Saving after new best accuracy : 85.634\n",
      "Saving after new best accuracy : 85.915\n",
      "-- Epoch 100, Train Loss : 0.11662543565034866, Test Loss : 0.4709246754646301\n",
      "Saving after new best accuracy : 86.197\n",
      "Saving after new best accuracy : 86.479\n",
      "-- Epoch 150, Train Loss : 0.05909607745707035, Test Loss : 0.5567734837532043\n",
      "Saving after new best accuracy : 86.761\n",
      "-- Epoch 200, Train Loss : 0.03132927697151899, Test Loss : 0.6860606074333191\n",
      "-- Epoch 250, Train Loss : 0.020751462318003178, Test Loss : 0.7882856726646423\n",
      "-- Epoch 300, Train Loss : 0.015360648278146982, Test Loss : 0.8710909485816956\n",
      "-- Epoch 350, Train Loss : 0.012066236697137356, Test Loss : 0.9383959174156189\n",
      "-- Epoch 400, Train Loss : 0.01006142096593976, Test Loss : 1.2324535846710205\n",
      "-- Epoch 450, Train Loss : 0.00880840397439897, Test Loss : 1.2830930948257446\n",
      "-- Epoch 500, Train Loss : 0.008004782255738974, Test Loss : 1.3199338912963867\n",
      "-- Epoch 550, Train Loss : 0.0074596216436475515, Test Loss : 2.0661909580230713\n",
      "-- Epoch 600, Train Loss : 0.007047711173072457, Test Loss : 2.3348770141601562\n",
      "-- Epoch 650, Train Loss : 0.006732081295922399, Test Loss : 2.6020920276641846\n",
      "-- Epoch 700, Train Loss : 0.006464000325649977, Test Loss : 2.6287600994110107\n",
      "-- Epoch 750, Train Loss : 0.00622633402235806, Test Loss : 2.653000831604004\n",
      "-- Epoch 800, Train Loss : 0.006007648538798094, Test Loss : 2.676117181777954\n",
      "-- Epoch 850, Train Loss : 0.0058006723411381245, Test Loss : 2.938046932220459\n",
      "-- Epoch 900, Train Loss : 0.005595994996838272, Test Loss : 2.960087299346924\n",
      "-- Epoch 950, Train Loss : 0.005406683660112321, Test Loss : 2.9895389080047607\n",
      "-- Epoch 1000, Train Loss : 0.005202355328947306, Test Loss : 3.009216785430908\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 21.13 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([355, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 59\n",
      "False Positive : 19\n",
      "False Negative : 28\n",
      "True Negative : 249\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 75.641 %\n",
      "- Recall : 67.816 %\n",
      "- F1 : 0.71515\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 89.892 %\n",
      "- Recall : 92.91 %\n",
      "- F1 : 0.91376\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 86.761 %\n",
      "- Precision : 82.766 %\n",
      "- Recall : 80.363 %\n",
      "- F1 : 0.81547\n",
      "- Average Confidence : 93.59 %\n",
      "Model, Combined,,,,non-rumour,,,rumour,,,\n",
      "Twitter15-RNR_1DCNN_RoBERTa_Finetuned_with_TopTermsVectors Validation, 86.761, 82.766, 80.363, 0.81547, 75.641, 67.816, 0.71515, 89.892, 92.91, 0.91376, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([131, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 24\n",
      "False Positive : 2\n",
      "False Negative : 7\n",
      "True Negative : 98\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 92.308 %\n",
      "- Recall : 77.419 %\n",
      "- F1 : 0.84211\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 93.333 %\n",
      "- Recall : 98.0 %\n",
      "- F1 : 0.9561\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 93.13 %\n",
      "- Precision : 92.821 %\n",
      "- Recall : 87.71 %\n",
      "- F1 : 0.90193\n",
      "- Average Confidence : 93.68 %\n",
      "Model, Combined,,,,non-rumour,,,rumour,,,\n",
      "Twitter15-RNR_1DCNN_RoBERTa_Finetuned_with_TopTermsVectors Test, 93.13, 92.821, 87.71, 0.90193, 92.308, 77.419, 0.84211, 93.333, 98.0, 0.9561, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "binary = True\n",
    "\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_1DCNN_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=1, criterion=nn.BCELoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                binary=binary,\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in val_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in test_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b4d368",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
