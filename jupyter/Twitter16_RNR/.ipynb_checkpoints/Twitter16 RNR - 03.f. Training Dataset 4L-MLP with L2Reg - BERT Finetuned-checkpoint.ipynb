{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# random.seed(33)\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Twitter16-RNR\"\n",
    "unique_name = \"BERT_Finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(818, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter16-RNR_BERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>656955120626880512</td>\n",
       "      <td>correct predictions in back to the future ii U...</td>\n",
       "      <td>false</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>615689290706595840</td>\n",
       "      <td>.@whitehouse in rainbow colors for #scotusmarr...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>613404935003217920</td>\n",
       "      <td>cops bought the alleged church shooter burger ...</td>\n",
       "      <td>false</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  656955120626880512  correct predictions in back to the future ii U...   \n",
       "1  615689290706595840  .@whitehouse in rainbow colors for #scotusmarr...   \n",
       "2  613404935003217920  cops bought the alleged church shooter burger ...   \n",
       "3  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "4  714598641827246081  an open letter to trump voters from his top st...   \n",
       "\n",
       "        label       tvt  cv_fold        tt        tvt2  \n",
       "0       false  training        1  training  validation  \n",
       "1        true  training        3  training    training  \n",
       "2       false  training        2      test    training  \n",
       "3  unverified  training        3      test    training  \n",
       "4  unverified  training        1      test    training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter16_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5f76a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rumour', 'non-rumour']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = ['rumour', 'non-rumour']\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "maritime-bradley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 1, 1, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "#     lab = labels_str.index(d['label'])\n",
    "    if d['label'] in ['true', 'false', 'unverified']:\n",
    "        lab = 0\n",
    "    else:\n",
    "        lab = 1\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(545, 768)\n",
      "(192, 768)\n",
      "(81, 768)\n",
      "(545,)\n",
      "(192,)\n",
      "(81,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1\n",
    "    ):\n",
    "        super(NNModel, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(128, n_output)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "    \n",
    "\n",
    "class NNClassifier:\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = NNModel(n_input, n_output)\n",
    "\n",
    "        self.criterion = criterion()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)\n",
    "\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        print(f\"loading model from {filepath}...\")\n",
    "#         print(checkpoint[key])\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def save_model(self, saves: str):\n",
    "        print(f\"Saving model...\")\n",
    "        state = {\n",
    "            'net': self.model.state_dict()\n",
    "        }\n",
    "        if not os.path.isdir('models'):\n",
    "            os.mkdir('models')\n",
    "        torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        current_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "#                 for i, output in enumerate(outputs.tolist()):\n",
    "#                     if targets[i,0].tolist() == round(output[0]):\n",
    "#                         correct += 1\n",
    "\n",
    "#             train_acc = round(100*correct/total, 4)\n",
    "#             train_accs.append(train_acc)\n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d69d25f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 89.062\n",
      "Saving after new best accuracy : 89.583\n",
      "-- Epoch 50, Train Loss : 0.0006889066135045141, Test Loss : 0.8988397717475891\n",
      "-- Epoch 100, Train Loss : 0.0001662024442339316, Test Loss : 1.0800955295562744\n",
      "-- Epoch 150, Train Loss : 5.532703289645724e-05, Test Loss : 1.184665560722351\n",
      "-- Epoch 200, Train Loss : 3.1089964068087284e-05, Test Loss : 1.2510722875595093\n",
      "-- Epoch 250, Train Loss : 1.7318426671408815e-05, Test Loss : 1.3092478513717651\n",
      "-- Epoch 300, Train Loss : 1.814589313653414e-05, Test Loss : 1.3588205575942993\n",
      "-- Epoch 350, Train Loss : 9.553783684168593e-06, Test Loss : 1.401534914970398\n",
      "-- Epoch 400, Train Loss : 3.09959423248074e-05, Test Loss : 1.4260777235031128\n",
      "-- Epoch 450, Train Loss : 1.5884249478403945e-05, Test Loss : 1.4514256715774536\n",
      "-- Epoch 500, Train Loss : 6.190721705934266e-06, Test Loss : 1.4647828340530396\n",
      "-- Epoch 550, Train Loss : 1.2371840966807213e-05, Test Loss : 1.4793602228164673\n",
      "-- Epoch 600, Train Loss : 5.465184472086548e-06, Test Loss : 1.4936774969100952\n",
      "-- Epoch 650, Train Loss : 6.8753503228435875e-06, Test Loss : 1.50849449634552\n",
      "-- Epoch 700, Train Loss : 7.2235416155308485e-06, Test Loss : 1.5259008407592773\n",
      "-- Epoch 750, Train Loss : 4.592031928041251e-06, Test Loss : 1.5224695205688477\n",
      "-- Epoch 800, Train Loss : 3.372724904693314e-06, Test Loss : 1.5268568992614746\n",
      "-- Epoch 850, Train Loss : 9.062086746780551e-06, Test Loss : 1.526668906211853\n",
      "-- Epoch 900, Train Loss : 5.633420187223237e-06, Test Loss : 1.5299429893493652\n",
      "-- Epoch 950, Train Loss : 9.73246710600506e-06, Test Loss : 1.5418610572814941\n",
      "-- Epoch 1000, Train Loss : 3.6509671872408944e-06, Test Loss : 1.5468721389770508\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAFXCAYAAAC1NambAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAr9ElEQVR4nO3de3xcdZ3/8de76SW0dIst6NKENqDgz1JK0SwVlOXS+hOrguJlwaIguP1RVgrigmBdddHu6l5QwAtULVWIoCIgK3VRERdcbrYKSEGk1rRNUS6FlkLp/fP745wp0zTJzCRzZnKS9/PxmEfnXOac70ymeed7Od+jiMDMzKxcQ+pdADMzyxcHh5mZVcTBYWZmFXFwmJlZRRwcZmZWEQeHmZlVxMFh1keSjpL0WA3P96+SzqvV+bo4/2clXdvD9vslHVzLMlltOTisTyS1S5pR73LUkqSQ9JrCckTcFRGvrdG59wE+BFxVi/P10n8Al9S7EJYdB4dZNyQNrXcZunA6sDgiXqp3QXpwC3CspL+ud0EsGw4Oy4SkEZK+LOmJ9PFlSSPSbXtL+rGkdZKelXSXpCHptk9IWiNpg6THJE3v5vhjJH1H0tOSVkr6lKQh6XnXSZpctO8+kl6S9Mp0+R2SHkj3u1vSlKJ929MyPAS82Dk8JN2ZPn1Q0guS/k7SMZI6Oh3jAkkPSXpR0rckvUrST9L39XNJryja/41pOdZJelDSMT18tG8D/qdTmUq9n4slPSLpOUlXS2os2v73kpanP4dbJI0v2nawpJ+l256U9Mmi0w5PP/8NkpZJai1siIhNwFLgrT28D8uziPDDj14/gHZgRhfrLwHuBV4J7APcDXwu3favwJXAsPRxFCDgtcBqYHy6Xwvw6m7O+x3gR8DodL8/AGem2xYC84v2/Qfgv9PnhwFPAdOABuC09D2MKHo/DwD7AXt0c+4AXlO0fAzQ0ekzuRd4FdCUnu836bkbgV8An0n3bQLWAjNJ/pB7S7q8Tzfnfhr4m6Llct7Pw+n7GQv8L/D5dNtxwDPA64ERwBXAnem20cCfgY+nZR4NTEu3fRbYlJa5If153tupnJcDl9b7++lHNg/XOCwrs4BLIuKpiHga+Gfgg+m2rcC+wMSI2BpJH0EA20l+gU2SNCwi2iPij50PLKkBOBm4OCI2REQ78J9Fx/9uur3gA+k6gNnAVRFxX0Rsj4hvA5uBNxbtf3lErI6+NQddERFPRsQa4C7gvoj4bSR/jd9E8gsf4FSSpqfFEbEjIn4GLCH5pdyVvYANRcvlvJ+vpO/nWWA+cEq6fhawMCJ+ExGbgYuBIyS1AO8A/hIR/xkRm9LP+b6iY/4qLfN24Brg0E7l3JCW1QYgB4dlZTywsmh5ZboO4N+B5cBPJa2QdBFARCwHziP5i/YpSdcXN50U2ZukptL5+E3p8zuAkZKmpb8Ep5L8sgaYCHw8bdZZJ2kdyV/jxedZXemb7cKTRc9f6mJ5z6LyvK9Ted5MEqxdeY7kr/+CSt9P8c9hl59RRLxAUttpSo+xW2gX+UvR841AY6dmvdHAuh5ebznm4LCsPEHyS61gQrqO9K/Xj0fEAcAJwPmFvoyI+G5EvDl9bQBf7OLYz5DUWjoff016jO3A90n+sj4F+HFEFP5KX03SjLVX0WNkRFxXdKxaThm9GrimU3lGRcQXutn/IeCgTq8v9X72K3q+8+dAp5+RpFHAOJLPcTVwQB/e1+uAB/vweuvHHBxWDcMkNRY9hgLXAZ9KO6b3Bj4NXAs7O3NfI0nAepImqh2SXivpuLQTfRPJX+Y7Op+sKBjmSxotaSJwfuH4qe8Cf0fSHPPdovXfAM5KayOSNErS2yUV/xVfypP07ZdqsWuBd0p6q6SG9PM7RlJzN/svBo4uWi7n/fyDpGZJY4F5wPfS9dcBH5Y0Nf3M/4WkSa0d+DGwr6Tz0gEHoyVNK+cNpZ3vbwB+VuZnYDnj4LBqWEzyS77w+CzweZK2+oeA35F0Dn8+3f9A4OfAC8A9wNci4g6S/o0vkNQo/kLSsX5xN+c8B3gRWAH8iiQcFhY2pu3xL5I0x/ykaP0S4O+Br5A0+ywnGeJaic8C306bht5f4Wt3ERGrgROBT5J0fK8GLqD7/5vfAWZK2iN9fTnv57vAT0k+qz+S/hwi4ufAPwE/JOkIfzVp31BaQ3sL8E6Sn8XjwLFlvq13Ar+MiCdK7mm5pKRP0szyQtK/AE9FxJfL2Lcd+EgaEjUh6T6SEW4P1+qcVlv98QInM+tBRHyy9F71ExFlNWlZfrmpyszMKuKmKjMzq4hrHGZmVhEHh5mZVSR3neN77713tLS01LsYZpYXzz4L7e1QabO8BCNGwKZNmRSr1tqBZyJUjWPlLjhaWlpYsmRJvYthZm1tcMYZsGVLtueZPh0OOggWLIDt27M9V7GIARMaAK2ldylb7oLDzOpgxgy4/fb6nPv22+t3buuS+zjMbFdnn5000xQ//Ivbijg4zAazrkLi61+vd6msXHPmJE1qZTyWJjfXqgo3VZkNNmef7XDIi/HjYc2aepdiN65xmA1EbW3JiKDOtQnXKPJjzpx+GRrg4DDLvxkzdg+HU0/NfrRTXnXVvHPttTBxYunXNjR0//pRo3bdd889k/VlNiXt9vja17J5/1WQuylHWltbw8NxbUDLa1PSnDl9/2VXyeitxkb48IfhW9/aPSSnT4ef12xC4FyQtDQiqjIq130cZvVUq2shqinLX8q9OW4//st8oHJTlVk9FEYz9fcmpcbG3Ztb/Jf8oOcah1lW8labaGyEb34TZs2qd0msn3NwmJWS1z6HcjgsrBccHGZdqecUG1moRse1WcrBYYPXQKxJeDSR1YCDwwa+gRQQDgbrBxwcNrDlrcnJTUqWAx6OawNP8cR9eQiN4iGvDg3LAdc4bODo77UL1yZsgHCNw/Kpq0n8ahEaXV0QNwDmHjKrhGsclh/16uR2h7TZLhwc1n/VsunJF8KZlc3BYf1DLWsTrkGY9UlmfRySFkp6StLDJfb7G0nbJL03q7JYP1U8+qlWoTFnjkPDrI+y7BxfBBzf0w6SGoAvAj/NsBzWn9Q6LDp3ZruD2qzPMmuqiog7JbWU2O0c4IfA32RVDusH6tGp7eYos8zUrY9DUhPwbuBYHBwDV1MTPPFE9ufxNRJmNVPP6zi+DHwiInaU2lHSbElLJC15+umnsy+Z9V7n+19nFRpugjKrm3qOqmoFrpcEsDcwU9K2iLi5844RsQBYAMk9x2tZSCtT1kNn3fRk1m/ULTgiYv/Cc0mLgB93FRqWA9VujvI1FWb9WmbBIek64Bhgb0kdwGeAYQARcWVW57UaO/jg6oSGw8IsN7IcVXVKBfuenlU5LCPVGCnlsDDLJV85buVra4MzzoAtW3p/DAmuucZhYZZjDg4rT1sbnHpq347hDm6zASF306ovXQotLcnvMauBwpXevQmN6dN3nVbcoWE2IOSyxrFyJcyenTx3i0eG+jJa6tpr/cMxG6ByV+Mo2LgR5s2rdykGqEIto7ehMWeOQ8NsAMtljaNg1ap6l2CA6etIqaFDYdEih4bZAJfbGgfAhAn1LsEAUahh9DY0CtN/bN3q0DAbBHJb4xg5EubPr3cpBoC+9GOMHw9r1lS3PGbW7+WyxrHffrBggf+47bXie2L0NjSmT3domA1SuaxxPPggvOIV9S5FzvjiPTOrklwGR19+9w1K1Zi5dtIkWLasOuUxs1zLZVOVg6NMhXtj9CU0hg5NOr4dGmaWymVwbN5c7xL0c21t1QsMj5Qys05yGRyucfTg7LP7NqeU5MAwsx65j2Mg6WtfhichNLMy5LLG8frXe6LD3fQ2NIrv3e3QMLMy5LLGEeGJDnfRm9Bw7cLMeimXNY4CT3RIcuV3JaFRqGE4NMysl3JZ4yg2KCc67M3FfJ4exMyqJPfBMegmOuxNs5Qv3jOzKsp1U9WgmuiwML9Ub/oyHBpmVkW5DA4JJk4cJBMd9mXKc3eAm1kGctlUNWjm2evLlOcODTPLSC5rHNu21bsEGStMGdKb0Gho8KgpM8uUg6O/6cuUIXPmJB/OoKiOmVm95LKpauvWepcgI729+tvNUmZWQ65x9BcHH1x5aBRmsHVomFkN5bLGMeCC4+CD4ZFHyt9/6FBYtMhNUmZWF5nVOCQtlPSUpIe72T5L0kOSfifpbkmHlnvsAdNU1dYGQ4aUHxqe8tzM+oEsm6oWAcf3sP1PwNERcQjwOWBBuQceEDWOQid4RHn7jx8PO3Y4MMys7jJrqoqIOyW19LD97qLFe4Hmco+d++CotBPcU4aYWT/SXzrHzwR+0t1GSbMlLZG0BHLcVFVomqokNDxliJn1M3UPDknHkgTHJ7rbJyIWRERrRLRCTmsclTZNQXJdhkdMmVk/U9dRVZKmAN8E3hYRa8t7TQ6Do62t8rmm5syBr30tm/KYmfVB3YJD0gTgRuCDEfGH8l+Xs6aqtrbKrgRvaIBvf9ud4GbWbykqaTqp5MDSdcAxwN7Ak8BngGEAEXGlpG8C7wFWpi/ZVmiK6vm4rQFLmDgxmVK9X/9+rTQ03AluZhmRtLSc37FlHSur4MhKITgguR9Hv51avdLQ8LQhZpahagZH3TvH+6Lf3nO8ktDwbLZmljO5rnEky8l1cf3KsGHl9eC7acrMasQ1jiL97p7jTU3lhcb48Q4NM8ulXAdHv7vn+IwZ5d18afx4WLMm+/KYmWUgt8HR7+45Xu40Ig4NM8u53E2rPmIEvOtdcP319S5JkXKnRW9ocGiYWe7lrsbR7zrDZ8wof1r0b38727KYmdVA7oIDYPv2epcg1dZW/oSF117bj9rVzMx6L3fB0a9qHB/5SHn7OTTMbADJXXBAPwmOs8+GTZtK7zd9ukPDzAaU3AVHv6hxlDvbracRMbMBKHfBAf2gj+P000vv43tpmNkAlbvgqHuN4+CDS18ZPn2676VhZgNW7oID6hgc5Q69dU3DzAYwB0e5zj67vKG3c+ZkXxYzszrKXXDUpamq3M7wSZPcRGVmA17uggPq0Dl+1lml92lo8Gy3ZjYo5C44al7jaGuDF14ovZ+nEzGzQSJ3wQE1Do5yh976Ij8zGyRyFxw1rXF46K2Z2W5yFxxQoz6OcobeDh/uobdmNujkLjhqUuMod9bbhQszLoiZWf+Tu+CAGgRHObPeevJCMxukHBydtbWVnvW2ocFNVGY2aOUuODJvqipnFJWH3prZIJa74IAMO8fPPrv0KCoPvTWzQS53wZFpjePKK3ve7qG3ZmbZBYekhZKekvRwN9sl6XJJyyU9JOn15R47k+Boa4OInvdxv4aZWaY1jkXA8T1sfxtwYPqYDZQxi2CGNY5SfRue9dbMDMgwOCLiTuDZHnY5EfhOJO4F9pK0bznHrnofR6m+jYYGN1GZmaXq2cfRBKwuWu5I1/UokxpHqb4Nj6IyM9spF53jkmZLWiJpyaZNm6obHOX0bXgUlZnZTvUMjjXAfkXLzem63UTEgohojYjWPfZorG5wlLpK3H0bZma7qGdw3AJ8KB1d9UZgfUT8udSLnn0W1qyBlpakstAnpa4Sd9+GmdluhmZ1YEnXAccAe0vqAD4DDAOIiCuBxcBMYDmwEfhwOcct1DZWroTZs5PnvW5JOvfcnre7b8PMbDeKUu37/YzUGrBk5/LEidDe3uuD9bw9Z5+NmVl3JC2NiNZqHCsXneM9WbWqly+cMaPn7e7bMDPrUu6DY8KEXryonPttuG/DzKxLuQ6OkSNh/vxevLBU38a4cb0qj5nZYJC74BiSlnjiRFiwoJcd42vX9rz9sst6cVAzs8Ehs1FVWdlnH3j++T50iJ99ds/bhw/3BX9mZj3IXY2jz1OOlJpexPcRNzPrUe6CA/oQHKWmFxk1yrUNM7MSchkcvZ4dt1Sn+FVX9fLAZmaDR+6Co09NVT11irtvw8ysLLkLjoKKL+ouNbGV+zbMzMqSu+AozBJSca2jVDOVaxtmZmXJXXAUVNzP0VMzlS/4MzMrW+6Co1c1jlLNVL7gz8ysbLkLjoKKgsPNVGZmVZO74OhVjcPNVGZmVZO74CgoOzjcTGVmVlW5DY6yO8fdTGVmVlW5C46Km6rcTGVmVlW5C46CPk10WOBmKjOziuUuOCqqcZTq33AzlZlZxXIXHAVl9XH01L/hZiozs17JXXBUVOPoqX/DzVRmZr2Su+Ao6HMfh5upzMx6JXfBUXaNo6f+jcJBzMysYrkLjoKSwdFT/0bFc7KbmVlB7oKjUFko2TneU//GxIlVK4+Z2WCTu+Ao6LHGUWoY7vz5VS2LmdlgUlZwSBolaUj6/CBJJ0galm3RuitL8m+PweFpRszMMlNujeNOoFFSE/BT4IPAolIvknS8pMckLZd0URfbJ0i6Q9JvJT0kaWa5Be8xODzNiJlZZsoNDkXERuAk4GsR8T7g4B5fIDUAXwXeBkwCTpE0qdNunwK+HxGHAScDXyu34BXfAbDA12+YmfVJ2cEh6QhgFnBruq6hxGsOB5ZHxIqI2AJcD5zYaZ8A/ip9PgZ4onRBkn+7rXF4mhEzs0yVGxznARcDN0XEMkkHAHeUeE0TsLpouSNdV+yzwKmSOoDFwDldHUjSbElLJC15/vnngR6CY968EsUyM7O+KCs4IuJ/IuKEiPhi2kn+TETMrcL5TwEWRUQzMBO4ptAJ3+n8CyKiNSJax4xJKijdBsfKld2fzcNwzcz6rNxRVd+V9FeSRgEPA49IuqDEy9YA+xUtN6frip0JfB8gIu4BGoG9yylTt8HR0EMLmofhmpn1WblNVZMi4nngXcBPgP1JRlb15NfAgZL2lzScpPP7lk77rAKmA0h6HUlwPN3TQUteANhTr7n7N8zM+qzc4BiWXrfxLuCWiNhK0rHdrYjYBnwUuA14lGT01DJJl0g6Id3t48DfS3oQuA44PaK8+UC6rXEM6eYt9VQTMTOzsg0tc7+rgHbgQeBOSROB50u9KCIWk3R6F6/7dNHzR4A3lVtYKDGqqq2t+0Tp9fhdMzMrVlZwRMTlwOVFq1ZKOjabIpWny3zo6Ypxd4ybmVVFuZ3jYyRdWhgSK+k/gVEZl61HXVYgerpi3B3jZmZVUW4fx0JgA/D+9PE8cHVWherJhg3JvzNmQEtL6ev9dnLHuJlZVZTbx/HqiHhP0fI/S3ogg/KU9Je/JP9GJJdszJ6dLPeYC75xk5lZ1ZRb43hJ0psLC5LeBLyUTZF61nnM1caN6cXiPVU9fOMmM7OqKbfGcRbwHUlj0uXngNOyKVLlVq2i56lG3DFuZlY15Y6qehA4VNJfpcvPSzoPeCjDspVtwgR6nmrEHeNmZlVT0R0AI+L59ApygPMzKE9JnbsrRo5Mc6G7C/wkd4ybmVVRX24dW5ce5333TU+upAVqwYI0F7q7wM/9G2ZmVVVuH0dX6vIbea+94Ikn4Ac/gPcUj/MaMqTrqwI91YiZWVX1GBySNtB1QAjYI5MSlWmXjPBUI2ZmNdNjcETE6FoVpFxdzlXlEVVmZjXTlz6OutolODyiysysZnIXHF3WODyiysysZnIXHAW7BIdHVJmZ1czACA7fvMnMrGZyFxy7NVV5RJWZWU3lLjgKdmaFR1SZmdVU7oJjtxqHR1SZmdVU7oJj2ENL+RMt7H9POo26R1SZmdVUX6YcqZsWVtLUNhum4xFVZmY1lrsaR8GwLekdnLqrcXhElZlZJnJZ49hp1aruaxYeUWVmlonc1jgAGDu2+/uJe0SVmVkmchscW4eNTJ50VeOQPKLKzCwjuQyO1TRz23sXwNq1Xe8Q4RFVZmYZyWVwHM3/8MjUWe4YNzOrg0yDQ9Lxkh6TtFzSRd3s835Jj0haJum75Rx3Oa/h//1rS/cd4O4YNzPLTGajqiQ1AF8F3gJ0AL+WdEtEPFK0z4HAxcCbIuI5Sa8s59hDCMas6+GK8XHj+lJ0MzPrQZY1jsOB5RGxIiK2ANcDJ3ba5++Br0bEcwAR8VSG5TEzsyrIMjiagNVFyx3pumIHAQdJ+l9J90o6vqsDSZotaYmkJWWd+dlne1NeMzMrQ70vABwKHAgcAzQDd0o6JCLWFe8UEQuABQCtUum5RCZMqHY5zcwslWWNYw2wX9Fyc7quWAdwS0RsjYg/AX8gCZLeGz7c13CYmWUoy+D4NXCgpP0lDQdOBm7ptM/NJLUNJO1N0nS1otSBA9iubobcjh7tazjMzDKUWXBExDbgo8BtwKPA9yNimaRLJJ2Q7nYbsFbSI8AdwAUR0c1VfS87Z8jXGBLd3PXP/RtmZpnKtI8jIhYDizut+3TR8wDOTx9la9RmNu4xllEvdZExY8f2qqxmZlaeXF453qjNvt2GmVmd5DI49tAmRm3qpknKTVVmZpnKZXCM0GaeG93NkFsPxTUzy1S9r+PolY9v+Vc2bx/V9caZM2tbGDOzQSaXNQ4Bjdtf7Hrj4sVdrzczs6rIZXD0aNWqepfAzGxAG3jB4T4OM7NMDazg8HQjZmaZG1jB4elGzMwyl7/gkOj22j9fw2Fmlrn8Bccee7CJxq63uX/DzCxz+QsOiZVDX83WIcN3Xe/+DTOzmshdcGzbJnZs28H2HZ0arDx5lZlZTeQuOF7aLA5gBY1s3XXD1q0wb159CmVmNojkLjgCMYLNXW/0xX9mZpnLZXBsYVjXG905bmaWuVwGx5O8is24c9zMrB5yGRwNbCM6X83hznEzs5rIXXCMHCVeyTPuHDczq5PcBceIRjGUbV1vdOe4mVnmchccPPdc99vcOW5mlrn8BceOHair9SNHunPczKwG8hccXZk4ERYs8My4ZmY1MDCCY/58h4aZWY0MjOCYPRva2updCjOzQWFgBMfGjR6Ka2ZWIwMjOMBDcc3MaiR/wdHQ0PV6D8U1M6uJTIND0vGSHpO0XNJFPez3HkkhqbXkQceM2X2dh+KamdVMZsEhqQH4KvA2YBJwiqRJXew3GjgXuK+sA48aBcBLQ0Ymyx6Ka2ZWU1nWOA4HlkfEiojYAlwPnNjFfp8DvghsKuuoSi7/e2D030JzM7S3OzTMzGooy+BoAlYXLXek63aS9Hpgv4i4tacDSZotaYmkJRteeAGANzz/C+jogJYWD8U1M6uhunWOSxoCXAp8vNS+EbEgIlojonX0kKTIw2NLsnHlSl/HYWZWQ1kGxxpgv6Ll5nRdwWhgMvBLSe3AG4FbSnaQr1u3+zpfx2FmVjNZBsevgQMl7S9pOHAycEthY0Ssj4i9I6IlIlqAe4ETImJJj0fd5inVzczqKbPgiIhtwEeB24BHge9HxDJJl0g6odcHHjq06/W+jsPMrCa6+S1cHRGxGFjcad2nu9n3mLIOOm4cPPnkrut8HYeZWc3k78pxdbobx7hxvo7DzKyG8hccnWsbL71Un3KYmQ1S+QuOiF2XN26Ec8+tT1nMzAah/AVHV9au9XUcZmY1MjCCA3wdh5lZjQyc4PB1HGZmNZG/4PD9OMzM6ip/wdHUtPs6X8dhZlYz+QuOvfd++bnk+3GYmdVY/oLjuedeft7UlNQ0HBpmZjWTv+Bob3/5eUcHnHGGh+KamdVQ/oKj8wWAW7b4AkAzsxrKX3B0Ze3aepfAzGzQGBDBEaV3MTOzKhkQwfGsxtW7CGZmg0bugiPYdVr1TQxjblxWp9KYmQ0+uQuOdlpoZyI7EO1M5Ayu5n8nejiumVmtZHoHwCysGzKW/Xe8fFvykSNhgS8aNzOrmdzVOCZOhDFjkucTJviicTOzWstdcIwdC+efnzxfscKhYWZWa7kLDnh5gtzt2+tbDjOzwcjBYWZmFXFwmJlZRRwcZmZWEQeHmZlVxMFhZmYVcXCYmVlFMg0OScdLekzSckkXdbH9fEmPSHpI0u2SJpZzXAeHmVn9ZBYckhqArwJvAyYBp0ia1Gm33wKtETEFuAH4t3KO7eAwM6ufLOeqOhxYHhErACRdD5wIPFLYISLuKNr/XuDUcg7s4DAbOLZu3UpHRwebNm2qd1EGhMbGRpqbmxk2bFhm58gyOJqA1UXLHcC0HvY/E/hJVxskzQZmA0yYMMHBYTaAdHR0MHr0aFpaWpBU+gXWrYhg7dq1dHR0sP/++2d2nn7ROS7pVKAV+PeutkfEgohojYjWffbZx8FhNoBs2rSJcePGOTSqQBLjxo3LvPaWZY1jDbBf0XJzum4XkmYA84CjI2JzOQd2cJgNLA6N6qnFZ5lljePXwIGS9pc0HDgZuKV4B0mHAVcBJ0TEU+Ue2MFhZtWydu1apk6dytSpU/nrv/5rmpqadi5v2bKlx9cuWbKEuXPnVnS+lpYWnnnmmb4Uue4yq3FExDZJHwVuAxqAhRGxTNIlwJKIuIWkaWpP4AdpSq6KiBNKHdvBYTZ4tbXBvHmwalVyT5758/t2e4Vx48bxwAMPAPDZz36WPffck3/8x3/cuX3btm0MHdr1r8rW1lZaW1t7f/KcyrSPIyIWR8RBEfHqiJifrvt0GhpExIyIeFVETE0fJUMDHBxmg1VbG8yeDStXQkTy7+zZyfpqOv300znrrLOYNm0aF154Iffffz9HHHEEhx12GEceeSSPPfYYAL/85S95xzveASShc8YZZ3DMMcdwwAEHcPnll5d9vvb2do477jimTJnC9OnTWbVqFQA/+MEPmDx5Moceeih/+7d/C8CyZcs4/PDDmTp1KlOmTOHxxx+v7psvQ+5uHQsODrOB6rzzIP3jv0v33gubO/WEbtwIZ54J3/hG16+ZOhW+/OXKy9LR0cHdd99NQ0MDzz//PHfddRdDhw7l5z//OZ/85Cf54Q9/uNtrfv/733PHHXewYcMGXvva1zJnzpyyhsWec845nHbaaZx22mksXLiQuXPncvPNN3PJJZdw22230dTUxLp16wC48sorOffcc5k1axZbtmxhex1+ETo4zCw3OodGqfV98b73vY+G9JfN+vXrOe2003j88ceRxNatW7t8zdvf/nZGjBjBiBEjeOUrX8mTTz5Jc3NzyXPdc8893HjjjQB88IMf5MILLwTgTW96E6effjrvf//7OemkkwA44ogjmD9/Ph0dHZx00kkceOCB1Xi7FXFwmFm/Uapm0NKSNE91NnEi/PKX1S3LqFGjdj7/p3/6J4499lhuuukm2tvbOeaYY7p8zYgRI3Y+b2hoYNu2bX0qw5VXXsl9993Hrbfeyhve8AaWLl3KBz7wAaZNm8att97KzJkzueqqqzjuuOP6dJ5K9YvrOCrl4DAbnObPh5Ejd103cmSyPkvr16+nqakJgEWLFlX9+EceeSTXX389AG1tbRx11FEA/PGPf2TatGlccskl7LPPPqxevZoVK1ZwwAEHMHfuXE488UQeeuihqpenFAeHmeXGrFmwYEFSw5CSfxcs6NuoqnJceOGFXHzxxRx22GF9rkUATJkyhebmZpqbmzn//PO54ooruPrqq5kyZQrXXHMNl112GQAXXHABhxxyCJMnT+bII4/k0EMP5fvf/z6TJ09m6tSpPPzww3zoQx/qc3kqpYio+Un7orW1NWbOXMLnPpd8caoxHM/M6ufRRx/lda97Xb2LMaB09ZlKWhoRVRk7nLsax7PPwr+lc+hmORzPzMy6lrvgWLOm6+F48+bVpzxmZoNN7oKjuxkA0utlzMwsY7kLjuHDu14/YUJty2FmNljlLjiammCPPXZdV4vheGZmlshdcIwdC//xHy8v12o4npmZJXIXHAAf+EDy76WXQnu7Q8PMeq8v06pDMtHh3Xff3eW2RYsW8dGPfrTaRa67XAZH4ar+LOanMbN+rq0tmXtkyJDk3z6OxS9Mq/7AAw9w1lln8bGPfWzn8vDuOlWL9BQcA1Wug8P3tjcbZGo0r/rSpUs5+uijecMb3sBb3/pW/vznPwNw+eWXM2nSJKZMmcLJJ59Me3s7V155JV/60peYOnUqd911V1nHv/TSS5k8eTKTJ0/my+kEXS+++CJvf/vbOfTQQ5k8eTLf+973ALjooot2nrP4PiH1lMtJDocMgWHDXOMwG3D6wbzqEcE555zDj370I/bZZx++973vMW/ePBYuXMgXvvAF/vSnPzFixAjWrVvHXnvtxVlnnbXbzZ96snTpUq6++mruu+8+IoJp06Zx9NFHs2LFCsaPH8+tt94KJPNjrV27lptuuonf//73SNo5tXq95bLG0dYG27bBF75QlZqqmeVFDeZV37x5Mw8//DBvectbmDp1Kp///Ofp6OgAkjmmZs2axbXXXtvtXQFL+dWvfsW73/1uRo0axZ577slJJ53EXXfdxSGHHMLPfvYzPvGJT3DXXXcxZswYxowZQ2NjI2eeeSY33ngjIzvP8FgnuatxPPtsUjMtTLFVqKmCO8nNcq8fzKseERx88MHcc889u2279dZbufPOO/mv//ov5s+fz+9+97uqnBPgoIMO4je/+Q2LFy/mU5/6FNOnT+fTn/40999/P7fffjs33HADX/nKV/jFL35RtXP2Vu5qHGvWJDXTYp5yxGyQqMG86iNGjODpp5/eGRxbt25l2bJl7Nixg9WrV3PsscfyxS9+kfXr1/PCCy8wevRoNmzYUPbxjzrqKG6++WY2btzIiy++yE033cRRRx3FE088wciRIzn11FO54IIL+M1vfsMLL7zA+vXrmTlzJl/60pd48MEHq/Y++yJ3NQ5POWI2iBWaFebNS/7TZzA99pAhQ7jhhhuYO3cu69evZ9u2bZx33nkcdNBBnHrqqaxfv56IYO7cuey11168853v5L3vfS8/+tGPuOKKK3beS6Ng0aJF3HzzzTuX7733Xk4//XQOP/xwAD7ykY9w2GGHcdttt3HBBRcwZMgQhg0bxte//nU2bNjAiSeeyKZNm4gILr300qq9z77I3bTqQ4e2xvbtS3ZbP24cPPNMHQpkZn3iadWrz9Oqm5lZv5K74Ojurn/PPlvbcpiZDVa5C47uLuQcO7a25TAzG6xyFxxNTcnFf52tW+frOczyKm99rf1ZLT7L3AXH2LFd1zq2b4dzz619ecysbxobG1m7dq3DowoigrVr19LY2JjpeXI3HBfgxRe7Xr92bVLr8IWAZvnR3NxMR0cHTz/9dL2LMiA0NjbS3Nyc6TlyNxy3tbU1li7dfThuT/bcMwmbDIZ8m5nlQjWH4w6K4DAzs1YilqgaR8pdHwckF/uZmVl95DI4Lrus3iUwMxu8ctdUJWkD8BgcPAka96h3eczM8qGdiGeq0lSVx1FVj1WrgyfvJC3xZ5HwZ/EyfxYv82fxMklV6xzOZVOVmZnVj4PDzMwqksfgWFDvAvQj/ixe5s/iZf4sXubP4mVV+yxy1zluZmb1lccah5mZ1VGugkPS8ZIek7Rc0kX1Lk+WJO0n6Q5Jj0haJuncdP1YST+T9Hj67yvS9ZJ0efrZPCTp9fV9B9UnqUHSbyX9OF3eX9J96Xv+nqTh6foR6fLydHtLXQteZZL2knSDpN9LelTSEYP1eyHpY+n/j4clXSepcTB9LyQtlPSUpIeL1lX8XZB0Wrr/45JOK3Xe3ASHpAbgq8DbgEnAKZIm1bdUmdoGfDwiJgFvBP4hfb8XAbdHxIHA7ekyJJ/LgeljNvD12hc5c+cCjxYtfxH4UkS8BngOODNdfybwXLr+S+l+A8llwH9HxP8BDiX5TAbd90JSEzAXaI2IyUADcDKD63uxCDi+07qKvguSxgKfAaYBhwOfKYRNtyIiFw/gCOC2ouWLgYvrXa4avv8fAW8BHgP2TdftS3JdC8BVwClF++/cbyA8gOb0P8FxwI8BAc8AQzt/P4DbgCPS50PT/VTv91Clz2EM8KfO72cwfi+AJmA1MDb9Of8YeOtg+14ALcDDvf0uAKcAVxWt32W/rh65qXHw8pekoCNdN+ClVerDgPuAV0XEn9NNfwFelT4f6J/Pl4ELgR3p8jhgXURsS5eL3+/OzyLdvj7dfyDYH3gauDpttvumpFEMwu9FRKwB/gNYBfyZ5Oe8lMH5vShW6Xeh4u9InoJjUJK0J/BD4LyIeL54WyR/Hgz4YXGS3gE8FRFL612WfmAo8Hrg6xFxGPAiLzdFAIPqe/EK4ESSMB0PjGL3ZptBLavvQp6CYw2wX9Fyc7puwJI0jCQ02iLixnT1k5L2TbfvCzyVrh/In8+bgBMktQPXkzRXXQbsJakwbU7x+935WaTbxwBra1ngDHUAHRFxX7p8A0mQDMbvxQzgTxHxdERsBW4k+a4Mxu9FsUq/CxV/R/IUHL8GDkxHTAwn6QS7pc5lyowkAd8CHo2IS4s23QIURj2cRtL3UVj/oXTkxBuB9UXV1VyLiIsjojkiWkh+7r+IiFnAHcB70906fxaFz+i96f4D4i/wiPgLsFrSa9NV04FHGITfC5ImqjdKGpn+fyl8FoPue9FJpd+F24D/K+kVaS3u/6brulfvjp0KO4FmAn8A/gjMq3d5Mn6vbyapYj4EPJA+ZpK0yd4OPA78HBib7i+SUWd/BH5HMtKk7u8jg8/lGODH6fMDgPuB5cAPgBHp+sZ0eXm6/YB6l7vKn8FUYEn63bgZeMVg/V4A/wz8HngYuAYYMZi+F8B1JP07W0lqo2f25rsAnJF+LsuBD5c6r68cNzOziuSpqcrMzPoBB4eZmVXEwWFmZhVxcJiZWUUcHGZmVhEHh1knkrZLeqDoUbWZmCW1FM9kapZHQ0vvYjbovBQRU+tdCLP+yjUOszJJapf0b5J+J+l+Sa9J17dI+kV6j4PbJU1I179K0k2SHkwfR6aHapD0jfQ+Ej+VtEfd3pRZLzg4zHa3R6emqr8r2rY+Ig4BvkIyYy/AFcC3I2IK0AZcnq6/HPifiDiUZD6pZen6A4GvRsTBwDrgPZm+G7Mq85XjZp1IeiEi9uxifTtwXESsSCeg/EtEjJP0DMn9D7am6/8cEXtLehpojojNRcdoAX4WyU12kPQJYFhEfL4Gb82sKlzjMKtMdPO8EpuLnm/HfY2WMw4Os8r8XdG/96TP7yaZtRdgFnBX+vx2YA7svF/6mFoV0ixL/kvHbHd7SHqgaPm/I6IwJPcVkh4iqTWckq47h+SOfBeQ3J3vw+n6c4EFks4kqVnMIZnJ1CzX3MdhVqa0j6M1Ip6pd1nM6slNVWZmVhHXOMzMrCKucZiZWUUcHGZmVhEHh5mZVcTBYWZmFXFwmJlZRRwcZmZWkf8P80klOHfnCbQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 19.93 seconds\n",
      "loading model from ../../data/models/Twitter16-RNR_4LayerNet_L2Reg_BERT_Finetuned.pth...\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([192])\n",
      "192 vs 192\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 93.793 %\n",
      "- Recall : 92.517 %\n",
      "- F1 : 0.93151\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 76.596 %\n",
      "- Recall : 80.0 %\n",
      "- F1 : 0.78261\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 89.583 %\n",
      "- Precision : 85.194 %\n",
      "- Recall : 86.259 %\n",
      "- F1 : 0.85723\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,rumour,,,non-rumour,,,\n",
      "Twitter16-RNR_4LayerNet_L2Reg_BERT_Finetuned Validation, 89.583, 85.194, 86.259, 0.85723, 93.793, 92.517, 0.93151, 76.596, 80.0, 0.78261, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([81])\n",
      "81 vs 81\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 89.552 %\n",
      "- Recall : 98.361 %\n",
      "- F1 : 0.9375\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 92.857 %\n",
      "- Recall : 65.0 %\n",
      "- F1 : 0.76471\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 90.123 %\n",
      "- Precision : 91.205 %\n",
      "- Recall : 81.68 %\n",
      "- F1 : 0.8618\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,rumour,,,non-rumour,,,\n",
      "Twitter16-RNR_4LayerNet_L2Reg_BERT_Finetuned Test, 90.123, 91.205, 81.68, 0.8618, 89.552, 98.361, 0.9375, 92.857, 65.0, 0.76471, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_L2Reg_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=2, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc76bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
