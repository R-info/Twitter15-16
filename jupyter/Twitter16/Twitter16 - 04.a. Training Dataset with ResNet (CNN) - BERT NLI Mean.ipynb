{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "random.seed(33)\n",
    "\n",
    "unique_name = \"SBERT_NLI_Mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(818, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter16_SBERT_NLI_Mean_vectors.txt\", delimiter=\",\")\n",
    "first = vectors[0]\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>656955120626880512</td>\n",
       "      <td>correct predictions in back to the future ii U...</td>\n",
       "      <td>false</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>615689290706595840</td>\n",
       "      <td>.@whitehouse in rainbow colors for #scotusmarr...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>613404935003217920</td>\n",
       "      <td>cops bought the alleged church shooter burger ...</td>\n",
       "      <td>false</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  656955120626880512  correct predictions in back to the future ii U...   \n",
       "1  615689290706595840  .@whitehouse in rainbow colors for #scotusmarr...   \n",
       "2  613404935003217920  cops bought the alleged church shooter burger ...   \n",
       "3  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "4  714598641827246081  an open letter to trump voters from his top st...   \n",
       "\n",
       "        label       tvt  \n",
       "0       false  training  \n",
       "1        true  training  \n",
       "2       false  training  \n",
       "3  unverified  training  \n",
       "4  unverified  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter16_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4698ab17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['false', 'true', 'unverified', 'non-rumor']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = data['label'].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "maritime-bradley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 2, 2, 1, 2, 3, 3, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d['label'])\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt'] == 'test'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt'] == 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "quality-burst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(478, 768)\n",
      "(175, 768)\n",
      "(165, 768)\n",
      "(478,)\n",
      "(175,)\n",
      "(165,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e860c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.lin1 = nn.Linear(in_planes, planes)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.lin2 = nn.Linear(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Linear(in_planes, planes),\n",
    "                nn.BatchNorm1d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = self.bn2(self.lin2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.lin1 = nn.Linear(in_planes, planes)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.lin2 = nn.Linear(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "        self.lin3 = nn.Linear(planes, planes)\n",
    "        self.bn3 = nn.BatchNorm1d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Linear(in_planes, planes),\n",
    "                nn.BatchNorm1d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = F.leaky_relu(self.bn2(self.lin2(out)), 0.1)\n",
    "        out = self.bn3(self.lin3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, n_input=768, num_classes=1):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 512\n",
    "\n",
    "        self.lin1 = nn.Linear(n_input, self.in_planes)\n",
    "        self.bn1 = nn.BatchNorm1d(self.in_planes)\n",
    "        self.layer1 = self._make_layer(block, 512, num_blocks[0])\n",
    "        self.layer2 = self._make_layer(block, 256, num_blocks[1])\n",
    "        self.layer3 = self._make_layer(block, 128, num_blocks[2])\n",
    "        self.layer4 = self._make_layer(block, 64, num_blocks[3])\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks):\n",
    "        strides = [1] * num_blocks\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet10(n_input=768, n_output=1, block=BasicBlock):\n",
    "    return ResNet(block, [1, 1, 1, 1], n_input, n_output)\n",
    "\n",
    "    \n",
    "def ResNet18(n_input=768, n_output=1, block=BasicBlock):\n",
    "    return ResNet(block, [2, 2, 2, 2], n_input, n_output)\n",
    "\n",
    "\n",
    "def ResNet34(n_input=768, n_output=1, block=BasicBlock):\n",
    "    return ResNet(block, [3, 4, 6, 3], n_input, n_output)\n",
    "\n",
    "\n",
    "def ResNet50(n_input=768, n_output=1, block=Bottleneck):\n",
    "    return ResNet(block, [3, 4, 6, 3], n_input, n_output)\n",
    "\n",
    "\n",
    "def ResNet101(n_input=768, n_output=1, block=Bottleneck):\n",
    "    return ResNet(block, [3, 4, 23, 3], n_input, n_output)\n",
    "\n",
    "\n",
    "def ResNet152(n_input=768, n_output=1, block=Bottleneck):\n",
    "    return ResNet(block, [3, 8, 36, 3], n_input, n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e05091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CNNBasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(CNNBasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.conv1(x)), 0.1)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class CNNBottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes):\n",
    "        super(CNNBottleneck, self).__init__()\n",
    "        self.lin1 = nn.Linear(in_planes, planes)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.lin2 = nn.Linear(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.lin3 = nn.Linear(planes, planes)\n",
    "        self.bn3 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Linear(in_planes, planes),\n",
    "                nn.BatchNorm1d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = F.leaky_relu(self.bn2(self.lin2(out)), 0.1)\n",
    "        out = self.bn3(self.lin3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class CNNResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=1):\n",
    "        super(CNNResNet, self).__init__()\n",
    "        self.in_planes = 24\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 24, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(24)\n",
    "        self.layer1 = self._make_layer(block, 24, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 48, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 64, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(64 * 24 * 32, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.conv1(x)), 0.1)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def CNNResNet10(n_output: int):\n",
    "    return CNNResNet(CNNBasicBlock, [1, 1, 1, 1], n_output)\n",
    "\n",
    "    \n",
    "def CNNResNet18(n_output: int):\n",
    "    return CNNResNet(CNNBasicBlock, [2, 2, 2, 2], n_output)\n",
    "\n",
    "\n",
    "def CNNResNet34(n_output: int):\n",
    "    return CNNResNet(CNNBasicBlock, [3, 4, 6, 3], n_output)\n",
    "\n",
    "\n",
    "def CNNResNet50(n_output: int):\n",
    "    return CNNResNet(CNNBottleneck, [3, 4, 6, 3], n_output)\n",
    "\n",
    "\n",
    "def CNNResNet101(n_output: int):\n",
    "    return CNNResNet(CNNBottleneck, [3, 4, 23, 3], n_output)\n",
    "\n",
    "\n",
    "def CNNResNet152(n_output: int):\n",
    "    return CNNResNet(CNNBottleneck, [3, 8, 36, 3], n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class ResNetClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        model,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        n_features: int = 4,\n",
    "        lr: float = 0.0002,\n",
    "        beta1: float = 0.5,\n",
    "        device: str = None,\n",
    "        model_type: str = \"mlp\"\n",
    "    ):\n",
    "        super(ResNetClassifier, self).__init__()\n",
    "        self.model = model\n",
    "        self.model_type = model_type\n",
    "        self.criterion = criterion()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.model(input)\n",
    "        return x\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def save_model(self, saves: str):\n",
    "        print(f\"Saving model...\")\n",
    "        state = {\n",
    "            'net': self.model.state_dict()\n",
    "        }\n",
    "        if not os.path.isdir('models'):\n",
    "            os.mkdir('models')\n",
    "        torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        current_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "\n",
    "                if self.model_type == \"cnn\":\n",
    "                    outputs = self.model(inputs.unsqueeze(1))\n",
    "                elif self.model_type == \"mlp\":\n",
    "                    outputs = self.model(inputs)\n",
    "\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "#                 for i, output in enumerate(outputs.tolist()):\n",
    "#                     if targets[i,0].tolist() == round(output[0]):\n",
    "#                         correct += 1\n",
    "\n",
    "#             train_acc = round(100*correct/total, 4)\n",
    "#             train_accs.append(train_acc)\n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                \n",
    "                if self.model_type == 'mlp':\n",
    "                    outputs = self.model(inputs)\n",
    "                else:\n",
    "#                     outputs = self.model(inputs.reshape(inputs.shape[0], 1, 24, 32))\n",
    "                    outputs = self.model(inputs.unsqueeze(1))\n",
    "\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                if self.model_type == 'mlp':\n",
    "                    preds = self.predict(test_x)\n",
    "                else:\n",
    "                    preds = self.predict(test_x.reshape(test_x.shape[0], 1, 24, 32))\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1296e1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification Twitter16_ResNet10_MLP_SBERT_NLI_Mean\n",
      "\n",
      "---- Validation Set ----\n",
      "Predictions : torch.Size([175])\n",
      "175 vs 175\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 67.568 %\n",
      "- Recall : 71.429 %\n",
      "- F1 : 0.69444\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 84.783 %\n",
      "- Recall : 92.857 %\n",
      "- F1 : 0.88636\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 71.111 %\n",
      "- Recall : 84.211 %\n",
      "- F1 : 0.77108\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 76.596 %\n",
      "- Recall : 60.0 %\n",
      "- F1 : 0.6729\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 75.429 %\n",
      "- Precision : 75.014 %\n",
      "- Recall : 77.124 %\n",
      "- F1 : 0.76054\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,false,,,true,,,unverified,,,non-rumor,,,\n",
      "Twitter16_ResNet10_MLP_SBERT_NLI_Mean Validation, 75.429, 75.014, 77.124, 0.76054, 67.568, 71.429, 0.69444, 84.783, 92.857, 0.88636, 71.111, 84.211, 0.77108, 76.596, 60.0, 0.6729, \n",
      "\n",
      "---- Test Set ----\n",
      "Predictions : torch.Size([165])\n",
      "165 vs 165\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 79.07 %\n",
      "- Recall : 73.913 %\n",
      "- F1 : 0.76404\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 86.364 %\n",
      "- Recall : 88.372 %\n",
      "- F1 : 0.87356\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 65.217 %\n",
      "- Recall : 78.947 %\n",
      "- F1 : 0.71429\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 65.625 %\n",
      "- Recall : 55.263 %\n",
      "- F1 : 0.6\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 74.545 %\n",
      "- Precision : 74.069 %\n",
      "- Recall : 74.124 %\n",
      "- F1 : 0.74096\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,false,,,true,,,unverified,,,non-rumor,,,\n",
      "Twitter16_ResNet10_MLP_SBERT_NLI_Mean Test, 74.545, 74.069, 74.124, 0.74096, 79.07, 73.913, 0.76404, 86.364, 88.372, 0.87356, 65.217, 78.947, 0.71429, 65.625, 55.263, 0.6, \n"
     ]
    }
   ],
   "source": [
    "model_name = f\"Twitter16_ResNet10_MLP_{unique_name}\"\n",
    "print(f\"Multiclass Classification {model_name}\")\n",
    "model = ResNetClassifier(ResNet10(n_output=4), train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss, n_features=16) #, device=\"cpu\")\n",
    "# model.train_eval(torch.Tensor(train_vectors),\n",
    "#                 torch.Tensor(train_labels),\n",
    "#                 torch.Tensor(val_vectors),\n",
    "#                 torch.Tensor(val_labels),\n",
    "#                 saves=model_name,\n",
    "#                 n_iter=1000,\n",
    "#                 batch_size=1024)\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\n---- Validation Set ----\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\n---- Test Set ----\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "424621e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification Twitter16_ResNet18_MLP_SBERT_NLI_Mean\n",
      "\n",
      "---- Validation Set ----\n",
      "Predictions : torch.Size([175])\n",
      "175 vs 175\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 43.077 %\n",
      "- Recall : 80.0 %\n",
      "- F1 : 0.56\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 81.081 %\n",
      "- Recall : 71.429 %\n",
      "- F1 : 0.75949\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 63.889 %\n",
      "- Recall : 60.526 %\n",
      "- F1 : 0.62162\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 59.459 %\n",
      "- Recall : 36.667 %\n",
      "- F1 : 0.45361\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 58.857 %\n",
      "- Precision : 61.877 %\n",
      "- Recall : 62.155 %\n",
      "- F1 : 0.62016\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,false,,,true,,,unverified,,,non-rumor,,,\n",
      "Twitter16_ResNet18_MLP_SBERT_NLI_Mean Validation, 58.857, 61.877, 62.155, 0.62016, 43.077, 80.0, 0.56, 81.081, 71.429, 0.75949, 63.889, 60.526, 0.62162, 59.459, 36.667, 0.45361, \n",
      "\n",
      "---- Test Set ----\n",
      "Predictions : torch.Size([165])\n",
      "165 vs 165\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 47.945 %\n",
      "- Recall : 76.087 %\n",
      "- F1 : 0.58824\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 85.714 %\n",
      "- Recall : 69.767 %\n",
      "- F1 : 0.76923\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 58.065 %\n",
      "- Recall : 47.368 %\n",
      "- F1 : 0.52174\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 42.308 %\n",
      "- Recall : 28.947 %\n",
      "- F1 : 0.34375\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 56.97 %\n",
      "- Precision : 58.508 %\n",
      "- Recall : 55.543 %\n",
      "- F1 : 0.56987\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,false,,,true,,,unverified,,,non-rumor,,,\n",
      "Twitter16_ResNet18_MLP_SBERT_NLI_Mean Test, 56.97, 58.508, 55.543, 0.56987, 47.945, 76.087, 0.58824, 85.714, 69.767, 0.76923, 58.065, 47.368, 0.52174, 42.308, 28.947, 0.34375, \n"
     ]
    }
   ],
   "source": [
    "model_name = f\"Twitter16_ResNet18_MLP_{unique_name}\"\n",
    "print(f\"Multiclass Classification {model_name}\")\n",
    "model = ResNetClassifier(ResNet18(n_output=4), train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss, n_features=16) #, device=\"cpu\")\n",
    "# model.train_eval(torch.Tensor(train_vectors),\n",
    "#                 torch.Tensor(train_labels),\n",
    "#                 torch.Tensor(val_vectors),\n",
    "#                 torch.Tensor(val_labels),\n",
    "#                 saves=model_name,\n",
    "#                 n_iter=1000,\n",
    "#                 batch_size=1024)\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\n---- Validation Set ----\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\n---- Test Set ----\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61ccef0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification Twitter16_ResNet10_CNN_SBERT_NLI_Mean\n",
      "\n",
      "---- Validation Set ----\n",
      "Predictions : torch.Size([175])\n",
      "175 vs 175\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 79.412 %\n",
      "- Recall : 77.143 %\n",
      "- F1 : 0.78261\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 86.667 %\n",
      "- Recall : 92.857 %\n",
      "- F1 : 0.89655\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 63.83 %\n",
      "- Recall : 78.947 %\n",
      "- F1 : 0.70588\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 81.633 %\n",
      "- Recall : 66.667 %\n",
      "- F1 : 0.73394\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 77.714 %\n",
      "- Precision : 77.885 %\n",
      "- Recall : 78.904 %\n",
      "- F1 : 0.78391\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,false,,,true,,,unverified,,,non-rumor,,,\n",
      "Twitter16_ResNet10_CNN_SBERT_NLI_Mean Validation, 77.714, 77.885, 78.904, 0.78391, 79.412, 77.143, 0.78261, 86.667, 92.857, 0.89655, 63.83, 78.947, 0.70588, 81.633, 66.667, 0.73394, \n",
      "\n",
      "---- Test Set ----\n",
      "Predictions : torch.Size([165])\n",
      "165 vs 165\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 75.61 %\n",
      "- Recall : 67.391 %\n",
      "- F1 : 0.71264\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 90.244 %\n",
      "- Recall : 86.047 %\n",
      "- F1 : 0.88095\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 64.103 %\n",
      "- Recall : 65.789 %\n",
      "- F1 : 0.64935\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 52.273 %\n",
      "- Recall : 60.526 %\n",
      "- F1 : 0.56098\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 70.303 %\n",
      "- Precision : 70.557 %\n",
      "- Recall : 69.938 %\n",
      "- F1 : 0.70246\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,false,,,true,,,unverified,,,non-rumor,,,\n",
      "Twitter16_ResNet10_CNN_SBERT_NLI_Mean Test, 70.303, 70.557, 69.938, 0.70246, 75.61, 67.391, 0.71264, 90.244, 86.047, 0.88095, 64.103, 65.789, 0.64935, 52.273, 60.526, 0.56098, \n"
     ]
    }
   ],
   "source": [
    "model_name = f\"Twitter16_ResNet10_CNN_{unique_name}\"\n",
    "print(f\"Multiclass Classification {model_name}\")\n",
    "model = ResNetClassifier(CNNResNet10(n_output=4), train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss, n_features=16, model_type=\"cnn\") #, device=\"cpu\")\n",
    "# model.train_eval(torch.Tensor(train_vectors.reshape(train_vectors.shape[0], 24, 32)),\n",
    "#                 torch.Tensor(train_labels),\n",
    "#                 torch.Tensor(val_vectors.reshape(val_vectors.shape[0], 24, 32)),\n",
    "#                 torch.Tensor(val_labels),\n",
    "#                 saves=model_name,\n",
    "#                 n_iter=1000,\n",
    "#                 batch_size=1024)\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\n---- Validation Set ----\")\n",
    "preds = model.predict(val_vectors.reshape(val_vectors.shape[0], 1, 24, 32))\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\n---- Test Set ----\")\n",
    "preds = model.predict(test_vectors.reshape(test_vectors.shape[0], 1, 24, 32))\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c746093f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification Twitter16_ResNet18_CNN_SBERT_NLI_Mean\n",
      "\n",
      "---- Validation Set ----\n",
      "Predictions : torch.Size([175])\n",
      "175 vs 175\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 58.974 %\n",
      "- Recall : 65.714 %\n",
      "- F1 : 0.62162\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 81.25 %\n",
      "- Recall : 92.857 %\n",
      "- F1 : 0.86667\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 59.574 %\n",
      "- Recall : 73.684 %\n",
      "- F1 : 0.65882\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 80.488 %\n",
      "- Recall : 55.0 %\n",
      "- F1 : 0.65347\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 70.286 %\n",
      "- Precision : 70.072 %\n",
      "- Recall : 71.814 %\n",
      "- F1 : 0.70932\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,false,,,true,,,unverified,,,non-rumor,,,\n",
      "Twitter16_ResNet18_CNN_SBERT_NLI_Mean Validation, 70.286, 70.072, 71.814, 0.70932, 58.974, 65.714, 0.62162, 81.25, 92.857, 0.86667, 59.574, 73.684, 0.65882, 80.488, 55.0, 0.65347, \n",
      "\n",
      "---- Test Set ----\n",
      "Predictions : torch.Size([165])\n",
      "165 vs 165\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 69.565 %\n",
      "- Recall : 69.565 %\n",
      "- F1 : 0.69565\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 84.091 %\n",
      "- Recall : 86.047 %\n",
      "- F1 : 0.85057\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 62.222 %\n",
      "- Recall : 73.684 %\n",
      "- F1 : 0.6747\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 56.667 %\n",
      "- Recall : 44.737 %\n",
      "- F1 : 0.5\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 69.091 %\n",
      "- Precision : 68.136 %\n",
      "- Recall : 68.508 %\n",
      "- F1 : 0.68321\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,false,,,true,,,unverified,,,non-rumor,,,\n",
      "Twitter16_ResNet18_CNN_SBERT_NLI_Mean Test, 69.091, 68.136, 68.508, 0.68321, 69.565, 69.565, 0.69565, 84.091, 86.047, 0.85057, 62.222, 73.684, 0.6747, 56.667, 44.737, 0.5, \n"
     ]
    }
   ],
   "source": [
    "model_name = f\"Twitter16_ResNet18_CNN_{unique_name}\"\n",
    "print(f\"Multiclass Classification {model_name}\")\n",
    "model = ResNetClassifier(CNNResNet18(n_output=4), train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss, n_features=16, model_type=\"cnn\") #, device=\"cpu\")\n",
    "# model.train_eval(torch.Tensor(train_vectors.reshape(train_vectors.shape[0], 24, 32)),\n",
    "#                 torch.Tensor(train_labels),\n",
    "#                 torch.Tensor(val_vectors.reshape(val_vectors.shape[0], 24, 32)),\n",
    "#                 torch.Tensor(val_labels),\n",
    "#                 saves=model_name,\n",
    "#                 n_iter=1000,\n",
    "#                 batch_size=1024)\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\n---- Validation Set ----\")\n",
    "preds = model.predict(val_vectors.reshape(val_vectors.shape[0], 1, 24, 32))\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\n---- Test Set ----\")\n",
    "preds = model.predict(test_vectors.reshape(test_vectors.shape[0], 1, 24, 32))\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28d251e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
