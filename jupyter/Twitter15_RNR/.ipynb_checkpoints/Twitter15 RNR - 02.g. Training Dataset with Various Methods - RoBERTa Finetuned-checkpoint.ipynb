{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Twitter15-RNR\"\n",
    "unique_name = \"RoBERTa_Finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter15-RNR_RoBERTa_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>691809004356501505</td>\n",
       "      <td>america is a nation of second chances â€”@potus ...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693204708933160960</td>\n",
       "      <td>brandon marshall visits and offers advice, sup...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>551099691702956032</td>\n",
       "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "1  714598641827246081  an open letter to trump voters from his top st...   \n",
       "2  691809004356501505  america is a nation of second chances â€”@potus ...   \n",
       "3  693204708933160960  brandon marshall visits and offers advice, sup...   \n",
       "4  551099691702956032  rip elly may clampett: so sad to learn #beverl...   \n",
       "\n",
       "        label       tvt  cv_fold        tt      tvt2  \n",
       "0  unverified  training        1  training  training  \n",
       "1  unverified  training        1      test  training  \n",
       "2   non-rumor  training        2  training  training  \n",
       "3   non-rumor  training        1  training  training  \n",
       "4        true  training        3  training  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter15_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rumour', 'non-rumour']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = ['rumour', 'non-rumour']\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 0, 1, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "#     lab = labels_str.index(d['label'])\n",
    "    if d['label'] in ['true', 'false', 'unverified']:\n",
    "        lab = 0\n",
    "    else:\n",
    "        lab = 1\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1017, 768)\n",
      "(327, 768)\n",
      "(146, 768)\n",
      "(1017,)\n",
      "(327,)\n",
      "(146,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, n_output),\n",
    "#             nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 89.908\n",
      "Saving after new best accuracy : 90.52\n",
      "-- Epoch 50, Train Loss : 0.00019126474944641814, Test Loss : 0.7007138729095459\n",
      "-- Epoch 100, Train Loss : 4.332080061431043e-05, Test Loss : 0.8107349276542664\n",
      "-- Epoch 150, Train Loss : 1.8354342500970233e-05, Test Loss : 0.8748663663864136\n",
      "-- Epoch 200, Train Loss : 1.000568772724364e-05, Test Loss : 0.9203288555145264\n",
      "-- Epoch 250, Train Loss : 6.270683797993115e-06, Test Loss : 0.9555878639221191\n",
      "-- Epoch 300, Train Loss : 4.257537739249528e-06, Test Loss : 0.9844984412193298\n",
      "-- Epoch 350, Train Loss : 3.069878175665508e-06, Test Loss : 1.0091314315795898\n",
      "-- Epoch 400, Train Loss : 2.343636310797592e-06, Test Loss : 1.0305417776107788\n",
      "-- Epoch 450, Train Loss : 1.8358987290412188e-06, Test Loss : 1.0497897863388062\n",
      "-- Epoch 500, Train Loss : 1.3976109016766713e-06, Test Loss : 1.067091703414917\n",
      "-- Epoch 550, Train Loss : 1.1291902524135367e-06, Test Loss : 1.083032250404358\n",
      "-- Epoch 600, Train Loss : 9.050874894001026e-07, Test Loss : 1.0974931716918945\n",
      "-- Epoch 650, Train Loss : 8.220716836149222e-07, Test Loss : 1.110675573348999\n",
      "-- Epoch 700, Train Loss : 6.214326049303054e-07, Test Loss : 1.1233147382736206\n",
      "-- Epoch 750, Train Loss : 5.729010297272907e-07, Test Loss : 1.1347122192382812\n",
      "-- Epoch 800, Train Loss : 5.447645605727303e-07, Test Loss : 1.145969033241272\n",
      "-- Epoch 850, Train Loss : 4.854259572084629e-07, Test Loss : 1.1571310758590698\n",
      "-- Epoch 900, Train Loss : 3.2677978367701144e-07, Test Loss : 1.1665410995483398\n",
      "-- Epoch 950, Train Loss : 3.023911432364912e-07, Test Loss : 1.175520658493042\n",
      "-- Epoch 1000, Train Loss : 2.892622603667405e-07, Test Loss : 1.1844290494918823\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 36.25 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([327])\n",
      "327 vs 327\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 91.797 %\n",
      "- Recall : 95.918 %\n",
      "- F1 : 0.93812\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 85.915 %\n",
      "- Recall : 74.39 %\n",
      "- F1 : 0.79739\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 90.52 %\n",
      "- Precision : 88.856 %\n",
      "- Recall : 85.154 %\n",
      "- F1 : 0.86966\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,rumour,,,non-rumour,,,\n",
      "Twitter15-RNR_4LayerNet_RoBERTa_Finetuned Validation, 90.52, 88.856, 85.154, 0.86966, 91.797, 95.918, 0.93812, 85.915, 74.39, 0.79739, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([146])\n",
      "146 vs 146\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 94.69 %\n",
      "- Recall : 95.536 %\n",
      "- F1 : 0.95111\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 84.848 %\n",
      "- Recall : 82.353 %\n",
      "- F1 : 0.83582\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 92.466 %\n",
      "- Precision : 89.769 %\n",
      "- Recall : 88.944 %\n",
      "- F1 : 0.89355\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,rumour,,,non-rumour,,,\n",
      "Twitter15-RNR_4LayerNet_RoBERTa_Finetuned Test, 92.466, 89.769, 88.944, 0.89355, 94.69, 95.536, 0.95111, 84.848, 82.353, 0.83582, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=2, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55461251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
