{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "random.seed(33)\n",
    "\n",
    "dataset_name = \"Twitter16-TF\"\n",
    "unique_name = \"RoBERTa_Finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(412, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter16-TF_RoBERTa_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>656955120626880512</td>\n",
       "      <td>correct predictions in back to the future ii U...</td>\n",
       "      <td>False</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>615689290706595840</td>\n",
       "      <td>.@whitehouse in rainbow colors for #scotusmarr...</td>\n",
       "      <td>True</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>613404935003217920</td>\n",
       "      <td>cops bought the alleged church shooter burger ...</td>\n",
       "      <td>False</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>614467824313106432</td>\n",
       "      <td>god put a rainbow over the white house ðŸŒˆ URL\\r</td>\n",
       "      <td>True</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>622891631293935616</td>\n",
       "      <td>#wakeupamericaðŸ‡ºðŸ‡¸ who needs a #gun registry whe...</td>\n",
       "      <td>False</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  656955120626880512  correct predictions in back to the future ii U...   \n",
       "1  615689290706595840  .@whitehouse in rainbow colors for #scotusmarr...   \n",
       "2  613404935003217920  cops bought the alleged church shooter burger ...   \n",
       "3  614467824313106432     god put a rainbow over the white house ðŸŒˆ URL\\r   \n",
       "4  622891631293935616  #wakeupamericaðŸ‡ºðŸ‡¸ who needs a #gun registry whe...   \n",
       "\n",
       "   label        tvt2  \n",
       "0  False    training  \n",
       "1   True    testting  \n",
       "2  False  validation  \n",
       "3   True  validation  \n",
       "4  False    training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter16-tf_dataset.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = data['label'].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 1, 0, 1, 1, 0, 0, 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d['label'])\n",
    "#     labels.append([1 if j == lab else 0 for j in range(len(labels_str))])\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(275, 768)\n",
      "(98, 768)\n",
      "(39, 768)\n",
      "(275,)\n",
      "(98,)\n",
      "(39,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, n_output),\n",
    "#             nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ce67903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from library.classification import SKLearnClassification\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "logres_model = LogisticRegression(random_state=0, solver='liblinear', multi_class='ovr', max_iter=10000)\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "svm = LinearSVC()\n",
    "\n",
    "models = [\n",
    "    SKLearnClassification(logres_model, \"Logistic Regression\"),\n",
    "    SKLearnClassification(neigh, \"K-Nearest Neighbor\"),\n",
    "    SKLearnClassification(svm, \"Support Vector Machine\"),\n",
    "]\n",
    "# for model in models:\n",
    "#     print(f\"\\n--- {model.model_name.upper()} ---\")\n",
    "#     model.train(train_vectors, train_labels, dataset_name)\n",
    "    \n",
    "#     print(\"Validation Set\")\n",
    "#     preds = model.predict(val_vectors)\n",
    "\n",
    "#     conf_mat = ConfusionMatrix(\n",
    "#         labels=val_labels,\n",
    "#         predictions=preds,\n",
    "#         binary=True\n",
    "#     )\n",
    "#     conf_mat.evaluate()\n",
    "    \n",
    "#     print(\"Test Set\")\n",
    "#     preds = model.predict(test_vectors)\n",
    "\n",
    "#     conf_mat = ConfusionMatrix(\n",
    "#         labels=test_labels,\n",
    "#         predictions=preds,\n",
    "#         binary=False\n",
    "#     )\n",
    "#     conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "#     print(\"--- END ---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd07cc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 90.816\n",
      "-- Epoch 50, Train Loss : 0.0004364218330010772, Test Loss : 0.5724440813064575\n",
      "-- Epoch 100, Train Loss : 9.372776548843831e-05, Test Loss : 0.6828274130821228\n",
      "-- Epoch 150, Train Loss : 3.922468386008404e-05, Test Loss : 0.7460854053497314\n",
      "-- Epoch 200, Train Loss : 2.1331290554371662e-05, Test Loss : 0.7905267477035522\n",
      "-- Epoch 250, Train Loss : 1.334917851636419e-05, Test Loss : 0.8247781991958618\n",
      "-- Epoch 300, Train Loss : 9.122283699980471e-06, Test Loss : 0.8526731729507446\n",
      "-- Epoch 350, Train Loss : 6.618043244088767e-06, Test Loss : 0.8762081861495972\n",
      "-- Epoch 400, Train Loss : 5.01154408993898e-06, Test Loss : 0.896578311920166\n",
      "-- Epoch 450, Train Loss : 3.919159098586533e-06, Test Loss : 0.9145417213439941\n",
      "-- Epoch 500, Train Loss : 3.1401832529809326e-06, Test Loss : 0.9306766986846924\n",
      "-- Epoch 550, Train Loss : 2.5684153115435038e-06, Test Loss : 0.9453405141830444\n",
      "-- Epoch 600, Train Loss : 2.140996230082237e-06, Test Loss : 0.958715558052063\n",
      "-- Epoch 650, Train Loss : 1.8054773818221292e-06, Test Loss : 0.9710392355918884\n",
      "-- Epoch 700, Train Loss : 1.546685325592989e-06, Test Loss : 0.98248690366745\n",
      "-- Epoch 750, Train Loss : 1.3364438018470537e-06, Test Loss : 0.9931333065032959\n",
      "-- Epoch 800, Train Loss : 1.1665166539387428e-06, Test Loss : 1.0031380653381348\n",
      "-- Epoch 850, Train Loss : 1.0291008720741956e-06, Test Loss : 1.0125640630722046\n",
      "-- Epoch 900, Train Loss : 9.155271527561126e-07, Test Loss : 1.0215060710906982\n",
      "-- Epoch 950, Train Loss : 8.058546541178657e-07, Test Loss : 1.0300620794296265\n",
      "-- Epoch 1000, Train Loss : 7.178565510912449e-07, Test Loss : 1.0381957292556763\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 16.39 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([98])\n",
      "98 vs 98\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class False Evaluation\n",
      "- Precision : 92.0 %\n",
      "- Recall : 90.196 %\n",
      "- F1 : 0.91089\n",
      "\n",
      "Class True Evaluation\n",
      "- Precision : 89.583 %\n",
      "- Recall : 91.489 %\n",
      "- F1 : 0.90526\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 90.816 %\n",
      "- Precision : 90.792 %\n",
      "- Recall : 90.843 %\n",
      "- F1 : 0.90817\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,False,,,True,,,\n",
      "Twitter16-TF_4LayerNet_RoBERTa_Finetuned Validation, 90.816, 90.792, 90.843, 0.90817, 92.0, 90.196, 0.91089, 89.583, 91.489, 0.90526, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([39])\n",
      "39 vs 39\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class False Evaluation\n",
      "- Precision : 100.0 %\n",
      "- Recall : 95.0 %\n",
      "- F1 : 0.97436\n",
      "\n",
      "Class True Evaluation\n",
      "- Precision : 95.0 %\n",
      "- Recall : 100.0 %\n",
      "- F1 : 0.97436\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 97.436 %\n",
      "- Precision : 97.5 %\n",
      "- Recall : 97.5 %\n",
      "- F1 : 0.975\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,False,,,True,,,\n",
      "Twitter16-TF_4LayerNet_RoBERTa_Finetuned Test, 97.436, 97.5, 97.5, 0.975, 100.0, 95.0, 0.97436, 95.0, 100.0, 0.97436, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=2, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55461251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
