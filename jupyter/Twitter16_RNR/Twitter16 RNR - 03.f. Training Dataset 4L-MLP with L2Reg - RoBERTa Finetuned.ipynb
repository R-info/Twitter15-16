{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# random.seed(33)\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Twitter16-RNR\"\n",
    "unique_name = \"RoBERTa_Finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(818, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter16-RNR_RoBERTa_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>656955120626880512</td>\n",
       "      <td>correct predictions in back to the future ii U...</td>\n",
       "      <td>false</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>615689290706595840</td>\n",
       "      <td>.@whitehouse in rainbow colors for #scotusmarr...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>613404935003217920</td>\n",
       "      <td>cops bought the alleged church shooter burger ...</td>\n",
       "      <td>false</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  656955120626880512  correct predictions in back to the future ii U...   \n",
       "1  615689290706595840  .@whitehouse in rainbow colors for #scotusmarr...   \n",
       "2  613404935003217920  cops bought the alleged church shooter burger ...   \n",
       "3  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "4  714598641827246081  an open letter to trump voters from his top st...   \n",
       "\n",
       "        label       tvt  cv_fold        tt        tvt2  \n",
       "0       false  training        1  training  validation  \n",
       "1        true  training        3  training    training  \n",
       "2       false  training        2      test    training  \n",
       "3  unverified  training        3      test    training  \n",
       "4  unverified  training        1      test    training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter16_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5f76a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rumour', 'non-rumour']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = ['rumour', 'non-rumour']\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "maritime-bradley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 1, 1, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "#     lab = labels_str.index(d['label'])\n",
    "    if d['label'] in ['true', 'false', 'unverified']:\n",
    "        lab = 0\n",
    "    else:\n",
    "        lab = 1\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(545, 768)\n",
      "(192, 768)\n",
      "(81, 768)\n",
      "(545,)\n",
      "(192,)\n",
      "(81,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1\n",
    "    ):\n",
    "        super(NNModel, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(128, n_output)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "    \n",
    "\n",
    "class NNClassifier:\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = NNModel(n_input, n_output)\n",
    "\n",
    "        self.criterion = criterion()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)\n",
    "\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        print(f\"loading model from {filepath}...\")\n",
    "#         print(checkpoint[key])\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def save_model(self, saves: str):\n",
    "        print(f\"Saving model...\")\n",
    "        state = {\n",
    "            'net': self.model.state_dict()\n",
    "        }\n",
    "        if not os.path.isdir('models'):\n",
    "            os.mkdir('models')\n",
    "        torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        current_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "#                 for i, output in enumerate(outputs.tolist()):\n",
    "#                     if targets[i,0].tolist() == round(output[0]):\n",
    "#                         correct += 1\n",
    "\n",
    "#             train_acc = round(100*correct/total, 4)\n",
    "#             train_accs.append(train_acc)\n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d69d25f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 88.542\n",
      "-- Epoch 50, Train Loss : 0.0029135651857359335, Test Loss : 1.0941728353500366\n",
      "-- Epoch 100, Train Loss : 0.0007570155758003239, Test Loss : 1.353669285774231\n",
      "-- Epoch 150, Train Loss : 0.00039449446921935305, Test Loss : 1.5466498136520386\n",
      "-- Epoch 200, Train Loss : 0.00012195404997328296, Test Loss : 1.7031750679016113\n",
      "-- Epoch 250, Train Loss : 2.0100675101275556e-05, Test Loss : 1.8089189529418945\n",
      "-- Epoch 300, Train Loss : 0.00010365541538703837, Test Loss : 1.8799480199813843\n",
      "-- Epoch 350, Train Loss : 2.4944584765762556e-05, Test Loss : 1.942499041557312\n",
      "-- Epoch 400, Train Loss : 1.1275474662397755e-05, Test Loss : 1.982446551322937\n",
      "-- Epoch 450, Train Loss : 2.366609271575726e-05, Test Loss : 2.0140984058380127\n",
      "-- Epoch 500, Train Loss : 6.049685111975123e-06, Test Loss : 2.0528178215026855\n",
      "-- Epoch 550, Train Loss : 1.7179676433443092e-05, Test Loss : 2.076524496078491\n",
      "-- Epoch 600, Train Loss : 3.487046774353075e-05, Test Loss : 2.099740743637085\n",
      "-- Epoch 650, Train Loss : 3.3040509777038096e-06, Test Loss : 2.1225948333740234\n",
      "-- Epoch 700, Train Loss : 3.89900021957601e-06, Test Loss : 2.111856698989868\n",
      "-- Epoch 750, Train Loss : 1.10559381027997e-05, Test Loss : 2.124598741531372\n",
      "-- Epoch 800, Train Loss : 1.0697086963773472e-05, Test Loss : 2.1387739181518555\n",
      "-- Epoch 850, Train Loss : 2.157771859856439e-06, Test Loss : 2.1418426036834717\n",
      "-- Epoch 900, Train Loss : 1.0400793371445616e-05, Test Loss : 2.142155408859253\n",
      "-- Epoch 950, Train Loss : 2.0186847621062043e-05, Test Loss : 2.1508913040161133\n",
      "-- Epoch 1000, Train Loss : 4.8788818389766675e-06, Test Loss : 2.1507112979888916\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 19.75 seconds\n",
      "loading model from ../../data/models/Twitter16-RNR_4LayerNet_L2Reg_RoBERTa_Finetuned.pth...\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([192])\n",
      "192 vs 192\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 90.323 %\n",
      "- Recall : 95.238 %\n",
      "- F1 : 0.92715\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 81.081 %\n",
      "- Recall : 66.667 %\n",
      "- F1 : 0.73171\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 88.542 %\n",
      "- Precision : 85.702 %\n",
      "- Recall : 80.952 %\n",
      "- F1 : 0.83259\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,rumour,,,non-rumour,,,\n",
      "Twitter16-RNR_4LayerNet_L2Reg_RoBERTa_Finetuned Validation, 88.542, 85.702, 80.952, 0.83259, 90.323, 95.238, 0.92715, 81.081, 66.667, 0.73171, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([81])\n",
      "81 vs 81\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 90.909 %\n",
      "- Recall : 98.361 %\n",
      "- F1 : 0.94488\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 93.333 %\n",
      "- Recall : 70.0 %\n",
      "- F1 : 0.8\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 91.358 %\n",
      "- Precision : 92.121 %\n",
      "- Recall : 84.18 %\n",
      "- F1 : 0.87972\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,rumour,,,non-rumour,,,\n",
      "Twitter16-RNR_4LayerNet_L2Reg_RoBERTa_Finetuned Test, 91.358, 92.121, 84.18, 0.87972, 90.909, 98.361, 0.94488, 93.333, 70.0, 0.8, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_L2Reg_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=2, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc76bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
