{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Twitter16-TF\"\n",
    "unique_name = \"RoBERTa_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "terms_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(412, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter16-TF_RoBERTa_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>656955120626880512</td>\n",
       "      <td>correct predictions in back to the future ii U...</td>\n",
       "      <td>False</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>615689290706595840</td>\n",
       "      <td>.@whitehouse in rainbow colors for #scotusmarr...</td>\n",
       "      <td>True</td>\n",
       "      <td>testting</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>613404935003217920</td>\n",
       "      <td>cops bought the alleged church shooter burger ...</td>\n",
       "      <td>False</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>614467824313106432</td>\n",
       "      <td>god put a rainbow over the white house ðŸŒˆ URL\\r</td>\n",
       "      <td>True</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>622891631293935616</td>\n",
       "      <td>#wakeupamericaðŸ‡ºðŸ‡¸ who needs a #gun registry whe...</td>\n",
       "      <td>False</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  656955120626880512  correct predictions in back to the future ii U...   \n",
       "1  615689290706595840  .@whitehouse in rainbow colors for #scotusmarr...   \n",
       "2  613404935003217920  cops bought the alleged church shooter burger ...   \n",
       "3  614467824313106432     god put a rainbow over the white house ðŸŒˆ URL\\r   \n",
       "4  622891631293935616  #wakeupamericaðŸ‡ºðŸ‡¸ who needs a #gun registry whe...   \n",
       "\n",
       "   label        tvt2    tvt2_1    tvt2_2    tvt2_3  \n",
       "0  False    training  training  training  training  \n",
       "1   True    testting  testting  training  testting  \n",
       "2  False  validation  training  training  training  \n",
       "3   True  validation  training  training  training  \n",
       "4  False    training  testting  training  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter16-tf_dataset.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_type = \"label\"\n",
    "labels_str = data[label_type].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [1], [0], [1], [0], [1], [1], [0], [0], [1]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d[label_type])\n",
    "    labels.append([lab])\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mass shootings', 'charlie hebdo', 'lindt cafe', 'he was', '#charliehebdo attackers', 'will be', 'a rainbow', 'parliament hill', 'is not', 'red cross']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "474"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_terms = []\n",
    "with open(\"../../data/processed/twitter16-tf_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        vector_terms.append(t.strip())\n",
    "\n",
    "print(vector_terms[:10])\n",
    "len(vector_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2unigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(text)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def text2trigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    trigrams = nltk.trigrams(text)\n",
    "    trigrams = map(' '.join, trigrams)\n",
    "    trigrams = [bgr for bgr in trigrams]\n",
    "    \n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def bigrams_vectors_generation(texts):\n",
    "    bigram_vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(bigram_vector_base) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in bigram_vector_base:\n",
    "                idx = bigram_vector_base.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        bigram_vectors.append(init_vec)\n",
    "    \n",
    "    return bigram_vectors\n",
    "\n",
    "\n",
    "def custom_vectors_generation(texts, vector_terms):\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "        trigrams = text2trigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(vector_terms) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in vector_terms:\n",
    "                idx = vector_terms.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        for tgr in trigrams:\n",
    "            if tgr in vector_terms:\n",
    "                idx = vector_terms.index(tgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        vectors.append(init_vec)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(412, 1243)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "terms_vectors = custom_vectors_generation(texts, vector_terms)\n",
    "\n",
    "vectors = np.concatenate([vectors, terms_vectors], axis=1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(278, 1243)\n",
      "(95, 1243)\n",
      "(39, 1243)\n",
      "(278, 1)\n",
      "(95, 1)\n",
      "(39, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, n_output),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        binary: bool = False,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x, binary=binary)\n",
    "                if binary:\n",
    "                    preds = np.array([p[0] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([v[0] for v in test_y])\n",
    "                else:\n",
    "                    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y])\n",
    "                \n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=label_target,\n",
    "                    predictions=preds,\n",
    "                    binary=binary\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x, binary=False):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            \n",
    "            if binary:\n",
    "                return preds\n",
    "            else:\n",
    "                _, preds = torch.max(preds, dim = 1)\n",
    "                return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 91.579\n",
      "-- Epoch 50, Train Loss : 0.002922401763498783, Test Loss : 0.4105841815471649\n",
      "-- Epoch 100, Train Loss : 0.0005569298518821597, Test Loss : 0.5208710432052612\n",
      "-- Epoch 150, Train Loss : 0.00016593003238085657, Test Loss : 0.6037995219230652\n",
      "-- Epoch 200, Train Loss : 5.391679587773979e-05, Test Loss : 0.6824379563331604\n",
      "-- Epoch 250, Train Loss : 2.7394127755542286e-05, Test Loss : 0.7302061915397644\n",
      "-- Epoch 300, Train Loss : 1.6827330910018645e-05, Test Loss : 0.7641178369522095\n",
      "-- Epoch 350, Train Loss : 1.142766086559277e-05, Test Loss : 0.7908878326416016\n",
      "-- Epoch 400, Train Loss : 8.280585461761802e-06, Test Loss : 0.8129546046257019\n",
      "-- Epoch 450, Train Loss : 5.702771431970177e-06, Test Loss : 0.845751166343689\n",
      "-- Epoch 500, Train Loss : 4.300552973290905e-06, Test Loss : 0.8681485056877136\n",
      "-- Epoch 550, Train Loss : 3.413124886719743e-06, Test Loss : 0.886210560798645\n",
      "-- Epoch 600, Train Loss : 2.7889886951015797e-06, Test Loss : 0.9009978175163269\n",
      "-- Epoch 650, Train Loss : 2.3254428924701642e-06, Test Loss : 0.913210928440094\n",
      "-- Epoch 700, Train Loss : 1.9680283003253862e-06, Test Loss : 0.9246776700019836\n",
      "-- Epoch 750, Train Loss : 1.6882286217878573e-06, Test Loss : 0.9350318908691406\n",
      "-- Epoch 800, Train Loss : 1.4723220829182537e-06, Test Loss : 0.9438759088516235\n",
      "-- Epoch 850, Train Loss : 1.287504460378841e-06, Test Loss : 0.9550204873085022\n",
      "-- Epoch 900, Train Loss : 1.140851054515224e-06, Test Loss : 0.9620389342308044\n",
      "-- Epoch 950, Train Loss : 1.0100636700371979e-06, Test Loss : 0.9718125462532043\n",
      "-- Epoch 1000, Train Loss : 9.086498948818189e-07, Test Loss : 0.975983202457428\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 10.81 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([95, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 44\n",
      "False Positive : 4\n",
      "False Negative : 4\n",
      "True Negative : 43\n",
      "\n",
      "Class True Evaluation\n",
      "- Precision : 91.667 %\n",
      "- Recall : 91.667 %\n",
      "- F1 : 0.91667\n",
      "\n",
      "Class False Evaluation\n",
      "- Precision : 91.489 %\n",
      "- Recall : 91.489 %\n",
      "- F1 : 0.91489\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 91.579 %\n",
      "- Precision : 91.578 %\n",
      "- Recall : 91.578 %\n",
      "- F1 : 0.91578\n",
      "- Average Confidence : 9.82 %\n",
      "Model, Combined,,,,True,,,False,,,\n",
      "Twitter16-TF_2LMLP_RoBERTa_Finetuned_with_TopTermsVectors Validation, 91.579, 91.578, 91.578, 0.91578, 91.667, 91.667, 0.91667, 91.489, 91.489, 0.91489, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([39, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 18\n",
      "False Positive : 0\n",
      "False Negative : 1\n",
      "True Negative : 20\n",
      "\n",
      "Class True Evaluation\n",
      "- Precision : 100.0 %\n",
      "- Recall : 94.737 %\n",
      "- F1 : 0.97297\n",
      "\n",
      "Class False Evaluation\n",
      "- Precision : 95.238 %\n",
      "- Recall : 100.0 %\n",
      "- F1 : 0.97561\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 97.436 %\n",
      "- Precision : 97.619 %\n",
      "- Recall : 97.368 %\n",
      "- F1 : 0.97493\n",
      "- Average Confidence : 9.83 %\n",
      "Model, Combined,,,,True,,,False,,,\n",
      "Twitter16-TF_2LMLP_RoBERTa_Finetuned_with_TopTermsVectors Test, 97.436, 97.619, 97.368, 0.97493, 100.0, 94.737, 0.97297, 95.238, 100.0, 0.97561, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "binary = True\n",
    "\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_2LMLP_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=1, criterion=nn.BCELoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                binary=binary,\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in val_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in test_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55461251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
