{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Twitter16-TF\"\n",
    "unique_name = \"BERT_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "terms_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(412, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter16-TF_BERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>656955120626880512</td>\n",
       "      <td>correct predictions in back to the future ii U...</td>\n",
       "      <td>False</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>615689290706595840</td>\n",
       "      <td>.@whitehouse in rainbow colors for #scotusmarr...</td>\n",
       "      <td>True</td>\n",
       "      <td>testting</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>613404935003217920</td>\n",
       "      <td>cops bought the alleged church shooter burger ...</td>\n",
       "      <td>False</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>614467824313106432</td>\n",
       "      <td>god put a rainbow over the white house ðŸŒˆ URL\\r</td>\n",
       "      <td>True</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>622891631293935616</td>\n",
       "      <td>#wakeupamericaðŸ‡ºðŸ‡¸ who needs a #gun registry whe...</td>\n",
       "      <td>False</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  656955120626880512  correct predictions in back to the future ii U...   \n",
       "1  615689290706595840  .@whitehouse in rainbow colors for #scotusmarr...   \n",
       "2  613404935003217920  cops bought the alleged church shooter burger ...   \n",
       "3  614467824313106432     god put a rainbow over the white house ðŸŒˆ URL\\r   \n",
       "4  622891631293935616  #wakeupamericaðŸ‡ºðŸ‡¸ who needs a #gun registry whe...   \n",
       "\n",
       "   label        tvt2    tvt2_1    tvt2_2    tvt2_3  \n",
       "0  False    training  training  training  training  \n",
       "1   True    testting  testting  training  testting  \n",
       "2  False  validation  training  training  training  \n",
       "3   True  validation  training  training  training  \n",
       "4  False    training  testting  training  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter16-tf_dataset.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_type = \"label\"\n",
    "labels_str = data[label_type].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [1], [0], [1], [0], [1], [1], [0], [0], [1]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d[label_type])\n",
    "    labels.append([lab])\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mass shootings', 'charlie hebdo', 'lindt cafe', 'he was', '#charliehebdo attackers', 'will be', 'a rainbow', 'parliament hill', 'is not', 'red cross']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "474"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_terms = []\n",
    "with open(\"../../data/processed/twitter16-tf_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        vector_terms.append(t.strip())\n",
    "\n",
    "print(vector_terms[:10])\n",
    "len(vector_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2unigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(text)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def text2trigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    trigrams = nltk.trigrams(text)\n",
    "    trigrams = map(' '.join, trigrams)\n",
    "    trigrams = [bgr for bgr in trigrams]\n",
    "    \n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def bigrams_vectors_generation(texts):\n",
    "    bigram_vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(bigram_vector_base) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in bigram_vector_base:\n",
    "                idx = bigram_vector_base.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        bigram_vectors.append(init_vec)\n",
    "    \n",
    "    return bigram_vectors\n",
    "\n",
    "\n",
    "def custom_vectors_generation(texts, vector_terms):\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "        trigrams = text2trigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(vector_terms) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in vector_terms:\n",
    "                idx = vector_terms.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        for tgr in trigrams:\n",
    "            if tgr in vector_terms:\n",
    "                idx = vector_terms.index(tgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        vectors.append(init_vec)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(412, 1243, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "terms_vectors = custom_vectors_generation(texts, vector_terms)\n",
    "\n",
    "vectors = np.concatenate([vectors, terms_vectors], axis=1)\n",
    "vectors = vectors.reshape(vectors.shape[0], vectors.shape[1], 1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(278, 1243, 1)\n",
      "(95, 1243, 1)\n",
      "(39, 1243, 1)\n",
      "(278, 1)\n",
      "(95, 1)\n",
      "(39, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv1d(n_input, 512, 1, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 128, 1, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=1, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, n_output),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        binary: bool = False,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                \n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x, binary=binary)\n",
    "                if binary:\n",
    "                    preds = np.array([p[0] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([v[0] for v in test_y])\n",
    "                else:\n",
    "                    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y])\n",
    "                \n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=label_target,\n",
    "                    predictions=preds,\n",
    "                    binary=binary\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x, binary=False):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            \n",
    "            if binary:\n",
    "                return preds\n",
    "            else:\n",
    "                _, preds = torch.max(preds, dim = 1)\n",
    "                return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 91.579\n",
      "-- Epoch 50, Train Loss : 0.003529331646859646, Test Loss : 0.3957882821559906\n",
      "-- Epoch 100, Train Loss : 0.0006263480172492564, Test Loss : 0.5053937435150146\n",
      "-- Epoch 150, Train Loss : 0.00023602088913321495, Test Loss : 0.5692625641822815\n",
      "-- Epoch 200, Train Loss : 0.00011978305701632053, Test Loss : 0.6142417192459106\n",
      "-- Epoch 250, Train Loss : 7.195595389930531e-05, Test Loss : 0.6484466791152954\n",
      "-- Epoch 300, Train Loss : 4.247933975420892e-05, Test Loss : 0.6874337196350098\n",
      "-- Epoch 350, Train Loss : 2.3016391423880123e-05, Test Loss : 0.7447599768638611\n",
      "-- Epoch 400, Train Loss : 1.623146454221569e-05, Test Loss : 0.7783521413803101\n",
      "-- Epoch 450, Train Loss : 1.2277909263502806e-05, Test Loss : 0.8038617968559265\n",
      "-- Epoch 500, Train Loss : 9.666807272878941e-06, Test Loss : 0.8247265219688416\n",
      "-- Epoch 550, Train Loss : 7.825666216376703e-06, Test Loss : 0.8429661989212036\n",
      "-- Epoch 600, Train Loss : 6.4701694100222085e-06, Test Loss : 0.8575716018676758\n",
      "-- Epoch 650, Train Loss : 5.440792392619187e-06, Test Loss : 0.8728620409965515\n",
      "-- Epoch 700, Train Loss : 4.6397626647376455e-06, Test Loss : 0.8867048025131226\n",
      "-- Epoch 750, Train Loss : 3.9999695218284614e-06, Test Loss : 0.8940345048904419\n",
      "-- Epoch 800, Train Loss : 3.495253622531891e-06, Test Loss : 0.9092775583267212\n",
      "-- Epoch 850, Train Loss : 3.06000674754614e-06, Test Loss : 0.9156777262687683\n",
      "-- Epoch 900, Train Loss : 2.706449322431581e-06, Test Loss : 0.9214420318603516\n",
      "-- Epoch 950, Train Loss : 2.4178575586120132e-06, Test Loss : 0.9343323707580566\n",
      "-- Epoch 1000, Train Loss : 2.1721471057389863e-06, Test Loss : 0.9468680024147034\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 12.39 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([95, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 45\n",
      "False Positive : 5\n",
      "False Negative : 3\n",
      "True Negative : 42\n",
      "\n",
      "Class True Evaluation\n",
      "- Precision : 90.0 %\n",
      "- Recall : 93.75 %\n",
      "- F1 : 0.91837\n",
      "\n",
      "Class False Evaluation\n",
      "- Precision : 93.333 %\n",
      "- Recall : 89.362 %\n",
      "- F1 : 0.91304\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 91.579 %\n",
      "- Precision : 91.667 %\n",
      "- Recall : 91.556 %\n",
      "- F1 : 0.91611\n",
      "- Average Confidence : 10.92 %\n",
      "Model, Combined,,,,True,,,False,,,\n",
      "Twitter16-TF_1DCNN_BERT_Finetuned_with_TopTermsVectors Validation, 91.579, 91.667, 91.556, 0.91611, 90.0, 93.75, 0.91837, 93.333, 89.362, 0.91304, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([39, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 18\n",
      "False Positive : 0\n",
      "False Negative : 1\n",
      "True Negative : 20\n",
      "\n",
      "Class True Evaluation\n",
      "- Precision : 100.0 %\n",
      "- Recall : 94.737 %\n",
      "- F1 : 0.97297\n",
      "\n",
      "Class False Evaluation\n",
      "- Precision : 95.238 %\n",
      "- Recall : 100.0 %\n",
      "- F1 : 0.97561\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 97.436 %\n",
      "- Precision : 97.619 %\n",
      "- Recall : 97.368 %\n",
      "- F1 : 0.97493\n",
      "- Average Confidence : 10.53 %\n",
      "Model, Combined,,,,True,,,False,,,\n",
      "Twitter16-TF_1DCNN_BERT_Finetuned_with_TopTermsVectors Test, 97.436, 97.619, 97.368, 0.97493, 100.0, 94.737, 0.97297, 95.238, 100.0, 0.97561, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "binary = True\n",
    "\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_1DCNN_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=1, criterion=nn.BCELoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                binary=binary,\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in val_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in test_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b4d368",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
