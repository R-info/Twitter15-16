{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "random.seed(33)\n",
    "\n",
    "unique_name = \"BERT_with_BigramVector\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>691809004356501505</td>\n",
       "      <td>america is a nation of second chances â€”@potus ...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693204708933160960</td>\n",
       "      <td>brandon marshall visits and offers advice, sup...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>551099691702956032</td>\n",
       "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "1  714598641827246081  an open letter to trump voters from his top st...   \n",
       "2  691809004356501505  america is a nation of second chances â€”@potus ...   \n",
       "3  693204708933160960  brandon marshall visits and offers advice, sup...   \n",
       "4  551099691702956032  rip elly may clampett: so sad to learn #beverl...   \n",
       "\n",
       "        label       tvt  cv_fold        tt      tvt2  \n",
       "0  unverified  training        1  training  training  \n",
       "1  unverified  training        1      test  training  \n",
       "2   non-rumor  training        2  training  training  \n",
       "3   non-rumor  training        1  training  training  \n",
       "4        true  training        3  training  training  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter15_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ab5cc80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinton #neverhillary #trump2016 URL\\r',\n",
       " 'an open letter to trump voters from his top strategist-turned-defector URL via @xojanedotcom\\r',\n",
       " 'america is a nation of second chances â€”@potus on new reforms to solitary confinement: URL URL\\r',\n",
       " 'brandon marshall visits and offers advice, support to brother of fallen hero zaevion dobson: URL URL\\r',\n",
       " 'rip elly may clampett: so sad to learn #beverlyhillbillies star donna douglas has passed away. URL\\r',\n",
       " 'former 3 doors down guitarist matt roberts has died at age 38, according to his father. URL URL\\r',\n",
       " 'craigslist ad: â€˜get paid $15 an hour to protest at the trump rallyâ€™ - URL URL\\r',\n",
       " 'just in: missing afghan soldiers found trying to enter canada near niagara falls URL URL\\r',\n",
       " 'the day #ferguson cops told a dirty, bloody lie (via @thedailybeast): URL URL\\r',\n",
       " \"#riphulkhogan my heart is ripping like your shirt. wwe'll miss you.\\r\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unverified', 'non-rumor', 'true', 'false']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = data['label'].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 2, 1, 0, 2, 0, 3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d['label'])\n",
    "#     labels.append([1 if j == lab else 0 for j in range(len(labels_str))])\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5516af8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>unverified</th>\n",
       "      <th>non-rumor</th>\n",
       "      <th>true</th>\n",
       "      <th>false</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca kkk</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kkk grand</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grand wizard</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wizard endorses</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>endorses @hillaryclinton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      token  unverified  non-rumor  true  false\n",
       "0                    ca kkk           1          0     0      0\n",
       "1                 kkk grand           1          0     0      0\n",
       "2              grand wizard           1          0     0      0\n",
       "3           wizard endorses           1          0     0      0\n",
       "4  endorses @hillaryclinton           1          0     0      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_data = pd.read_excel('../../data/processed/twitter15_ngram_distribution.xlsx', sheet_name='bigram')\n",
    "bigram_data.columns = [\"token\", \"unverified\", \"non-rumor\", \"true\", \"false\"]\n",
    "bigram_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "603a6862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13842"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vector_base = bigram_data['token'].tolist()\n",
    "len(bigram_vector_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc184086",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-04 12:24:34.316355: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-04 12:24:34.316379: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "WARNING:root:No sentence-transformers model found with name /home/romy/.cache/torch/sentence_transformers/bert-base-uncased. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at /home/romy/.cache/torch/sentence_transformers/bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.models import Pooling\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "model = SentenceTransformer('bert-base-uncased')\n",
    "pooling_layer = Pooling(768)\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    bigrams = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    bigrams = [t for t in bigrams if t not in string.punctuation]\n",
    "    bigrams = [t for t in bigrams if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(bigrams)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def bigrams_vectors_generation(texts):\n",
    "    bigram_vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(bigram_vector_base) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in bigram_vector_base:\n",
    "                idx = bigram_vector_base.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        bigram_vectors.append(init_vec)\n",
    "    \n",
    "    return bigram_vectors\n",
    "\n",
    "\n",
    "def vectors_generation(texts):\n",
    "    return model.encode(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdea8e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 14611)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vectors = bigrams_vectors_generation(texts)\n",
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter15_BERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "\n",
    "vectors = np.concatenate([vectors, bigram_vectors], axis=1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1017, 14611)\n",
      "(327, 14611)\n",
      "(146, 14611)\n",
      "(1017,)\n",
      "(327,)\n",
      "(146,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, n_output),\n",
    "#             nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ce67903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from library.classification import SKLearnClassification\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Twitter15\"\n",
    "\n",
    "logres_model = LogisticRegression(random_state=0, solver='liblinear', multi_class='ovr', max_iter=10000)\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "svm = LinearSVC()\n",
    "\n",
    "models = [\n",
    "    SKLearnClassification(logres_model, \"Logistic Regression\"),\n",
    "    SKLearnClassification(neigh, \"K-Nearest Neighbor\"),\n",
    "    SKLearnClassification(svm, \"Support Vector Machine\"),\n",
    "]\n",
    "# for model in models:\n",
    "#     print(f\"\\n--- {model.model_name.upper()} ---\")\n",
    "#     model.train(train_vectors, train_labels, dataset_name)\n",
    "    \n",
    "#     print(\"Validation Set\")\n",
    "#     preds = model.predict(val_vectors)\n",
    "\n",
    "#     conf_mat = ConfusionMatrix(\n",
    "#         labels=val_labels,\n",
    "#         predictions=preds,\n",
    "#         binary=True\n",
    "#     )\n",
    "#     conf_mat.evaluate()\n",
    "    \n",
    "#     print(\"Test Set\")\n",
    "#     preds = model.predict(test_vectors)\n",
    "\n",
    "#     conf_mat = ConfusionMatrix(\n",
    "#         labels=test_labels,\n",
    "#         predictions=preds,\n",
    "#         binary=False\n",
    "#     )\n",
    "#     conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "#     print(\"--- END ---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 25.382\n",
      "Saving after new best accuracy : 33.945\n",
      "Saving after new best accuracy : 47.706\n",
      "Saving after new best accuracy : 56.575\n",
      "Saving after new best accuracy : 64.22\n",
      "Saving after new best accuracy : 66.361\n",
      "Saving after new best accuracy : 68.502\n",
      "Saving after new best accuracy : 70.948\n",
      "Saving after new best accuracy : 72.783\n",
      "Saving after new best accuracy : 73.7\n",
      "Saving after new best accuracy : 74.312\n",
      "Saving after new best accuracy : 74.618\n",
      "Saving after new best accuracy : 74.924\n",
      "Saving after new best accuracy : 75.535\n",
      "Saving after new best accuracy : 75.841\n",
      "-- Epoch 50, Train Loss : 0.005424300907179713, Test Loss : 0.6741644144058228\n",
      "-- Epoch 100, Train Loss : 0.0011019745143130422, Test Loss : 0.7077829241752625\n",
      "-- Epoch 150, Train Loss : 0.00046429657959379256, Test Loss : 0.7311723232269287\n",
      "-- Epoch 200, Train Loss : 0.0002586345362942666, Test Loss : 0.7494237422943115\n",
      "-- Epoch 250, Train Loss : 0.0001650830963626504, Test Loss : 0.7645213007926941\n",
      "-- Epoch 300, Train Loss : 0.00011428304424043745, Test Loss : 0.7773768901824951\n",
      "-- Epoch 350, Train Loss : 8.360619540326297e-05, Test Loss : 0.7883318662643433\n",
      "-- Epoch 400, Train Loss : 6.367101559590083e-05, Test Loss : 0.7984744310379028\n",
      "-- Epoch 450, Train Loss : 4.9955602662521414e-05, Test Loss : 0.8082196116447449\n",
      "-- Epoch 500, Train Loss : 4.011232158518396e-05, Test Loss : 0.8171156048774719\n",
      "-- Epoch 550, Train Loss : 3.2792947422422e-05, Test Loss : 0.8252365589141846\n",
      "-- Epoch 600, Train Loss : 2.7204394427826628e-05, Test Loss : 0.8326399326324463\n",
      "-- Epoch 650, Train Loss : 2.2911398446012754e-05, Test Loss : 0.8390899300575256\n",
      "-- Epoch 700, Train Loss : 1.949625766428653e-05, Test Loss : 0.8451765775680542\n",
      "-- Epoch 750, Train Loss : 1.6744892946007894e-05, Test Loss : 0.8511050939559937\n",
      "-- Epoch 800, Train Loss : 1.4508003459923202e-05, Test Loss : 0.8572247624397278\n",
      "-- Epoch 850, Train Loss : 1.2649675682041561e-05, Test Loss : 0.8634330630302429\n",
      "-- Epoch 900, Train Loss : 1.1084262496297015e-05, Test Loss : 0.8692418932914734\n",
      "-- Epoch 950, Train Loss : 9.781174412637483e-06, Test Loss : 0.8746121525764465\n",
      "-- Epoch 1000, Train Loss : 8.68170627654763e-06, Test Loss : 0.8799063563346863\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 71.87 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([327])\n",
      "327 vs 327\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 75.342 %\n",
      "- Recall : 66.265 %\n",
      "- F1 : 0.70513\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 77.143 %\n",
      "- Recall : 65.854 %\n",
      "- F1 : 0.71053\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 77.083 %\n",
      "- Recall : 93.671 %\n",
      "- F1 : 0.84571\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 73.864 %\n",
      "- Recall : 78.313 %\n",
      "- F1 : 0.76023\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 75.841 %\n",
      "- Precision : 75.858 %\n",
      "- Recall : 76.026 %\n",
      "- F1 : 0.75942\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Twitter15_4LayerNet_BERT_with_BigramVector Validation, 75.841, 75.858, 76.026, 0.75942, 75.342, 66.265, 0.70513, 77.143, 65.854, 0.71053, 77.083, 93.671, 0.84571, 73.864, 78.313, 0.76023, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([146])\n",
      "146 vs 146\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 76.744 %\n",
      "- Recall : 86.842 %\n",
      "- F1 : 0.81481\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 84.375 %\n",
      "- Recall : 79.412 %\n",
      "- F1 : 0.81818\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 86.486 %\n",
      "- Recall : 91.429 %\n",
      "- F1 : 0.88889\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 85.294 %\n",
      "- Recall : 74.359 %\n",
      "- F1 : 0.79452\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 82.877 %\n",
      "- Precision : 83.225 %\n",
      "- Recall : 83.01 %\n",
      "- F1 : 0.83117\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Twitter15_4LayerNet_BERT_with_BigramVector Test, 82.877, 83.225, 83.01, 0.83117, 76.744, 86.842, 0.81481, 84.375, 79.412, 0.81818, 86.486, 91.429, 0.88889, 85.294, 74.359, 0.79452, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "start = time.time()\n",
    "model_name = f\"Twitter15_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55461251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
