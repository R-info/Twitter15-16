{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "random.seed(33)\n",
    "\n",
    "unique_name = \"DistilBERT_Finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter15_DistilBERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "first = vectors[0]\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>691809004356501505</td>\n",
       "      <td>america is a nation of second chances â€”@potus ...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693204708933160960</td>\n",
       "      <td>brandon marshall visits and offers advice, sup...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>551099691702956032</td>\n",
       "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "1  714598641827246081  an open letter to trump voters from his top st...   \n",
       "2  691809004356501505  america is a nation of second chances â€”@potus ...   \n",
       "3  693204708933160960  brandon marshall visits and offers advice, sup...   \n",
       "4  551099691702956032  rip elly may clampett: so sad to learn #beverl...   \n",
       "\n",
       "        label       tvt  cv_fold        tt      tvt2  \n",
       "0  unverified  training        1  training  training  \n",
       "1  unverified  training        1      test  training  \n",
       "2   non-rumor  training        2  training  training  \n",
       "3   non-rumor  training        1  training  testting  \n",
       "4        true  training        3  training  testting  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter15_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4698ab17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unverified', 'non-rumor', 'true', 'false']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = data['label'].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "maritime-bradley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 2, 1, 0, 2, 0, 3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d['label'])\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "quality-burst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1017, 768)\n",
      "(328, 768)\n",
      "(145, 768)\n",
      "(1017,)\n",
      "(328,)\n",
      "(145,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e860c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.lin1 = nn.Linear(in_planes, planes)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.lin2 = nn.Linear(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Linear(in_planes, planes),\n",
    "                nn.BatchNorm1d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = self.bn2(self.lin2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.lin1 = nn.Linear(in_planes, planes)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.lin2 = nn.Linear(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "        self.lin3 = nn.Linear(planes, planes)\n",
    "        self.bn3 = nn.BatchNorm1d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Linear(in_planes, planes),\n",
    "                nn.BatchNorm1d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = F.leaky_relu(self.bn2(self.lin2(out)), 0.1)\n",
    "        out = self.bn3(self.lin3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, n_input=768, num_classes=1):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 512\n",
    "\n",
    "        self.lin1 = nn.Linear(n_input, self.in_planes)\n",
    "        self.bn1 = nn.BatchNorm1d(self.in_planes)\n",
    "        self.layer1 = self._make_layer(block, 512, num_blocks[0])\n",
    "        self.layer2 = self._make_layer(block, 256, num_blocks[1])\n",
    "        self.layer3 = self._make_layer(block, 128, num_blocks[2])\n",
    "        self.layer4 = self._make_layer(block, 64, num_blocks[3])\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks):\n",
    "        strides = [1] * num_blocks\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet10(n_input=768, n_output=1, block=BasicBlock):\n",
    "    return ResNet(block, [1, 1, 1, 1], n_input, n_output)\n",
    "\n",
    "    \n",
    "def ResNet18(n_input=768, n_output=1, block=BasicBlock):\n",
    "    return ResNet(block, [2, 2, 2, 2], n_input, n_output)\n",
    "\n",
    "\n",
    "def ResNet34(n_input=768, n_output=1, block=BasicBlock):\n",
    "    return ResNet(block, [3, 4, 6, 3], n_input, n_output)\n",
    "\n",
    "\n",
    "def ResNet50(n_input=768, n_output=1, block=Bottleneck):\n",
    "    return ResNet(block, [3, 4, 6, 3], n_input, n_output)\n",
    "\n",
    "\n",
    "def ResNet101(n_input=768, n_output=1, block=Bottleneck):\n",
    "    return ResNet(block, [3, 4, 23, 3], n_input, n_output)\n",
    "\n",
    "\n",
    "def ResNet152(n_input=768, n_output=1, block=Bottleneck):\n",
    "    return ResNet(block, [3, 8, 36, 3], n_input, n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e05091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CNNBasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(CNNBasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.conv1(x)), 0.1)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class CNNBottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes):\n",
    "        super(CNNBottleneck, self).__init__()\n",
    "        self.lin1 = nn.Linear(in_planes, planes)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.lin2 = nn.Linear(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.lin3 = nn.Linear(planes, planes)\n",
    "        self.bn3 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Linear(in_planes, planes),\n",
    "                nn.BatchNorm1d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = F.leaky_relu(self.bn2(self.lin2(out)), 0.1)\n",
    "        out = self.bn3(self.lin3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class CNNResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=1):\n",
    "        super(CNNResNet, self).__init__()\n",
    "        self.in_planes = 24\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 24, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(24)\n",
    "        self.layer1 = self._make_layer(block, 24, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 48, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 64, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(64 * 24 * 32, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.conv1(x)), 0.1)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def CNNResNet10(n_output: int):\n",
    "    return CNNResNet(CNNBasicBlock, [1, 1, 1, 1], n_output)\n",
    "\n",
    "    \n",
    "def CNNResNet18(n_output: int):\n",
    "    return CNNResNet(CNNBasicBlock, [2, 2, 2, 2], n_output)\n",
    "\n",
    "\n",
    "def CNNResNet34(n_output: int):\n",
    "    return CNNResNet(CNNBasicBlock, [3, 4, 6, 3], n_output)\n",
    "\n",
    "\n",
    "def CNNResNet50(n_output: int):\n",
    "    return CNNResNet(CNNBottleneck, [3, 4, 6, 3], n_output)\n",
    "\n",
    "\n",
    "def CNNResNet101(n_output: int):\n",
    "    return CNNResNet(CNNBottleneck, [3, 4, 23, 3], n_output)\n",
    "\n",
    "\n",
    "def CNNResNet152(n_output: int):\n",
    "    return CNNResNet(CNNBottleneck, [3, 8, 36, 3], n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class ResNetClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        model,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        n_features: int = 4,\n",
    "        lr: float = 0.0002,\n",
    "        beta1: float = 0.5,\n",
    "        device: str = None,\n",
    "        model_type: str = \"mlp\"\n",
    "    ):\n",
    "        super(ResNetClassifier, self).__init__()\n",
    "        self.model = model\n",
    "        self.model_type = model_type\n",
    "        self.criterion = criterion()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "        \n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.model(input)\n",
    "        return x\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def save_model(self, saves: str):\n",
    "        print(f\"Saving model...\")\n",
    "        state = {\n",
    "            'net': self.model.state_dict()\n",
    "        }\n",
    "        if not os.path.isdir('models'):\n",
    "            os.mkdir('models')\n",
    "        torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        current_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "\n",
    "                if self.model_type == \"cnn\":\n",
    "                    outputs = self.model(inputs.unsqueeze(1))\n",
    "                elif self.model_type == \"mlp\":\n",
    "                    outputs = self.model(inputs)\n",
    "\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "#                 for i, output in enumerate(outputs.tolist()):\n",
    "#                     if targets[i,0].tolist() == round(output[0]):\n",
    "#                         correct += 1\n",
    "\n",
    "#             train_acc = round(100*correct/total, 4)\n",
    "#             train_accs.append(train_acc)\n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                \n",
    "                if self.model_type == 'mlp':\n",
    "                    outputs = self.model(inputs)\n",
    "                else:\n",
    "#                     outputs = self.model(inputs.reshape(inputs.shape[0], 1, 24, 32))\n",
    "                    outputs = self.model(inputs.unsqueeze(1))\n",
    "\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                if self.model_type == 'mlp':\n",
    "                    preds = self.predict(test_x)\n",
    "                else:\n",
    "                    preds = self.predict(test_x.reshape(test_x.shape[0], 1, 24, 32))\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61ccef0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification Twitter15_ResNet10_CNN_DistilBERT_Finetuned\n",
      "Using cuda\n",
      "Saving after new best accuracy : 67.683\n",
      "Saving after new best accuracy : 70.122\n",
      "Saving after new best accuracy : 73.171\n",
      "Saving after new best accuracy : 73.78\n",
      "Saving after new best accuracy : 74.695\n",
      "Saving after new best accuracy : 75.61\n",
      "Saving after new best accuracy : 77.439\n",
      "Saving after new best accuracy : 77.744\n",
      "Saving after new best accuracy : 78.659\n",
      "Saving after new best accuracy : 78.963\n",
      "Saving after new best accuracy : 79.573\n",
      "-- Epoch 50, Train Loss : 5.037109076511115e-05, Test Loss : 1.1082041263580322\n",
      "-- Epoch 100, Train Loss : 2.983459307870362e-05, Test Loss : 1.2308217287063599\n",
      "-- Epoch 150, Train Loss : 2.0516872609732673e-05, Test Loss : 1.251961350440979\n",
      "-- Epoch 200, Train Loss : 1.52984430314973e-05, Test Loss : 1.2701914310455322\n",
      "-- Epoch 250, Train Loss : 1.2006541510345414e-05, Test Loss : 1.2864665985107422\n",
      "-- Epoch 300, Train Loss : 9.765277354745194e-06, Test Loss : 1.3011903762817383\n",
      "-- Epoch 350, Train Loss : 8.152847840392496e-06, Test Loss : 1.3146593570709229\n",
      "-- Epoch 400, Train Loss : 6.94000254952698e-06, Test Loss : 1.3271100521087646\n",
      "-- Epoch 450, Train Loss : 6.004946044413373e-06, Test Loss : 1.3387037515640259\n",
      "-- Epoch 500, Train Loss : 5.259003501123516e-06, Test Loss : 1.349554419517517\n",
      "-- Epoch 550, Train Loss : 4.657309546018951e-06, Test Loss : 1.3597832918167114\n",
      "-- Epoch 600, Train Loss : 4.159206582698971e-06, Test Loss : 1.3694796562194824\n",
      "-- Epoch 650, Train Loss : 3.737861561603495e-06, Test Loss : 1.3787187337875366\n",
      "-- Epoch 700, Train Loss : 3.384372348591569e-06, Test Loss : 1.3875384330749512\n",
      "-- Epoch 750, Train Loss : 3.082566536249942e-06, Test Loss : 1.3959838151931763\n",
      "-- Epoch 800, Train Loss : 2.8196704988658894e-06, Test Loss : 1.4041093587875366\n",
      "-- Epoch 850, Train Loss : 2.590879830677295e-06, Test Loss : 1.4119441509246826\n",
      "-- Epoch 900, Train Loss : 2.388108214290696e-06, Test Loss : 1.4194990396499634\n",
      "-- Epoch 950, Train Loss : 2.2100659862189787e-06, Test Loss : 1.4267971515655518\n",
      "-- Epoch 1000, Train Loss : 2.049252998403972e-06, Test Loss : 1.433859944343567\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAFXCAYAAAC1NambAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAqyUlEQVR4nO3de3xdVZ338c+36SW0VC4tXmigAS08YilFIxUchnIbsSqMjBcwSFG0DzhSUAcE64Vh7AzqDMhFgerDRYwgoiBKHRQEQbmZIiCISIVCw72BlkIpvf2eP/ZOe5KcJOc0Z2dnJ9/363VeOfty9l7n9DTfrLX2WlsRgZmZWaVG5F0AMzMrFgeHmZlVxcFhZmZVcXCYmVlVHBxmZlYVB4eZmVXFwWHWT5L2lfTwAJ7vvySdNFDnK3P+0yX9sJftd0t620CWyQaWg8P6RdISSQflXY6BJCkkvaVjOSJui4hdB+jc2wFHAxcNxPk2038DZ+RdCMuOg8OsB5JG5l2GMo4BFkbEq3kXpBfXAftLemPeBbFsODgsE5LGSPq2pKfSx7cljUm3TZT0S0nLJb0g6TZJI9JtX5T0pKSVkh6WdGAPx99K0g8kPS/pcUlfljQiPe9ySVNL9t1O0quSXp8uv1/Svel+t0uaVrLvkrQM9wOvdA0PSbemT++T9LKkj0qaKamtyzFOlnS/pFck/T9Jb5D0q/R93Shpm5L935WWY7mk+yTN7OWjfS/wuy5l6uv9nCbpL5JelHSJpPqS7Z+WtDj9d7hO0vYl294m6TfptmclfanktKPTz3+lpAclNXVsiIjVwCLgPb28DyuyiPDDj81+AEuAg8qsPwO4E3g9sB1wO/Af6bb/Ai4ERqWPfQEBuwJLge3T/RqBN/dw3h8APwfGp/v9DTg23XYxML9k338F/jd9vifwHDADqANmp+9hTMn7uRfYAdiih3MH8JaS5ZlAW5fP5E7gDcCk9Hz3pOeuB34LfC3ddxLQDswi+UPu4HR5ux7O/TzwzpLlSt7PA+n72Rb4A/D1dNsBwDLg7cAY4Dzg1nTbeOBp4AtpmccDM9JtpwOr0zLXpf+ed3Yp57nAWXl/P/3I5uEah2WlGTgjIp6LiOeBfwc+nm5bC7wJmBwRayPpIwhgPckvsN0kjYqIJRHx964HllQHHAGcFhErI2IJ8D8lx/9Rur3Dx9J1AHOAiyLirohYHxGXAa8B7yrZ/9yIWBr9aw46LyKejYgngduAuyLiT5H8NX4NyS98gKNImp4WRsSGiPgN0EryS7mcrYGVJcuVvJ/z0/fzAjAfODJd3wxcHBH3RMRrwGnA3pIagfcDz0TE/0TE6vRzvqvkmL9Py7weuBzYo0s5V6ZltSHIwWFZ2R54vGT58XQdwLeAxcCvJT0q6VSAiFgMnETyF+1zkq4sbTopMZGkptL1+JPS5zcDYyXNSH8JTif5ZQ0wGfhC2qyzXNJykr/GS8+ztNo3W8azJc9fLbO8ZUl5PtylPP9AEqzlvEjy13+Hat9P6b9Dp3+jiHiZpLYzKT1Gt9Au8UzJ81VAfZdmvfHA8l5ebwXm4LCsPEXyS63Djuk60r9evxAROwOHAp/v6MuIiB9FxD+krw3gG2WOvYyk1tL1+E+mx1gPXEXyl/WRwC8jouOv9KUkzVhblzzGRsQVJccayCmjlwKXdynPuIg4s4f97wd26fL6vt7PDiXPN/470OXfSNI4YALJ57gU2Lkf7+utwH39eL0NYg4Oq4VRkupLHiOBK4Avpx3TE4GvAj+EjZ25b5EkYAVJE9UGSbtKOiDtRF9N8pf5hq4nKwmG+ZLGS5oMfL7j+KkfAR8laY75Ucn67wHHpbURSRon6X2SSv+K78uz9O+XaqkfAh+Q9B5JdennN1NSQw/7LwT2K1mu5P38q6QGSdsC84Afp+uvAD4haXr6mf8nSZPaEuCXwJsknZRecDBe0oxK3lDa+f4O4DcVfgZWMA4Oq4WFJL/kOx6nA18naau/H/gzSefw19P9pwA3Ai8DdwDfjYibSfo3ziSpUTxD0rF+Wg/nPAF4BXgU+D1JOFzcsTFtj3+FpDnmVyXrW4FPA+eTNPssJrnEtRqnA5elTUMfqfK1nUTEUuAw4EskHd9LgZPp+f/mD4BZkrZIX1/J+/kR8GuSz+rvpP8OEXEj8BXgpyQd4W8m7RtKa2gHAx8g+bd4BNi/wrf1AeCWiHiqzz2tkJT0SZpZUUj6T+C5iPh2BfsuAT6VhsSAkHQXyRVuDwzUOW1gDcYBTmbWi4j4Ut975SciKmrSsuJyU5WZmVXFTVVmZlYV1zjMzKwqDg4zM6tK4TrHJ06cGI2NjXkXw8yGm7/9DVau7Hu/QWoJsCxCtThW4YKjsbGR1tbWvIthZkPBQQfBTTflXYoB0dT3LhVzU5WZDS2f+QxIlT2GSWjUWmbBIeliSc9J6nUQkKR3Slon6UNZlcXMCq6lBcaMqSwMLrgg79IOeVnWOC4FDulth3R67G+QTIdgZsNNpYFw1FGwZk3epR2cDjwQIvp8LEpurlUTmQVHRNwKvNDHbieQzJPzXFblMLMcOBA2X4VBsPFx44DNJrNRbn0ckiYBHwT6rFdKmiOpVVLr888/n33hzKxnBx3kQKjW8ccP6iCoVp5XVX0b+GJEbEhm1+5ZRCwAFgA0NTV5qLtZFobRFUb9duCBhfgFn5U8g6MJuDINjYkkU0Wvi4hrcyyT2dDT0gKf/KRrAH0Z5mFQjdyCIyJ26ngu6VKSu7Rdm1d5zArJodC7+nr4/vehuTnvkgwpWV6OewXJTXp2ldQm6VhJx0k6rl8HXrQIGhuT/zBmQ11f/QnDtS+h0j6DV191aGSgcLPjNknRCjB2LCxY4C+FFddnPuMxB10dfzx897t5l2JIkrQoImoygLy4wQEwYQIsW5Znccx65s7mTRwIuatlcBR7ypH2djdZWX76akYaDqFR6ZgDh8aQUuzgAJg3L+8S2FDV15xHQzkYKg0EX4U0LBU/OB5/PO8SWFH1Nbp5qPY/VNKx7ECwXhRuWvVu6uryLoENZsOtn8F9CTYAih8c69fnXQLL03Aax+ABajZIFL+pqo/pSmwI6K1JaaiMY6ivhx/+0M1HVgjFD44IX1k1VPR0ldJQCIe+Ops9UM0KpPjBAb6yqkh6u1KpyH0RfQWDaws2hBS/jwN8ZdVgNNQ6pT3nkdlGQyM4fGVVfoZSQPiKJLOKDI3g8JVV2RsKAeGrksxqYmj0cUyYkHcJho6eOqiLEhq9DW5zaJjVxNAIDqteT5e4FiEgegsHNzWZZW5oNFW1t+ddgsGtiM1MblYyG7SGRo1D8liODuWamgZraPQ26M2hYTZoDY3giBh+YzlaWmDLLYsREj2NcfCgN7NCGhpNVQBPPJF3CbJTlPmY3LxkNiwULzhGjy7/C3THHQe+LFkZ7H0SDgizYa14TVVbbVV+/axZA1uOWik3BcdgCY2empgcGmbDWvFqHCtWlF+/cOHAlmNzDdbahEdNm1mFihccPbXzD8Y+jsHYN+FmJjPrp+IFx2Du4xhsQeGQMLMMFK+PY9IkGDWq87pRo2D+/IEvS9fR13neN6LcaGqHhplloHA1jscegzWI0aUrB/IugIOhj8L9EWaWI0VE3mWoyjSNifsp81f95MmwZEntT5h385Obm8ysBiQtioimWhyrcE1Vo8uFBtS+c7zjMtmBbH4qNwWHQ8PMBpnCNVWtYTSUC49adY5/5jNwwQW1OVZfXJswswIqXHA8ySRe4VnGsWrTSqk2AwAnTYKnnur/cXrivgkzGwIK11T1AttyCbPp1DMTAZdd1r8ZcrfZpvah0fVKJ4eGmQ0BmQWHpIslPSfpgR62N0u6X9KfJd0uaY9Kj/3PdQvpdh3VqlWbP0PuNtvA8uWb99pSDgozGwayrHFcChzSy/bHgP0iYnfgP4AFlRx0xAho2NBDR/jmdJBPmrT5odF1LicHhZkNA5kFR0TcCrzQy/bbI+LFdPFOoKHig/fUEV5tB/lBB1XfPFVaq3DHtpkNQ4Olj+NY4FcV7z1/PmyxRed1Y8dWN3q8paXygXwjR266TNa1CjMb5nIPDkn7kwTHF3vZZ46kVkmtEZHcNe6oozbtUFcHs2dXdze5446rpHBJYKxd6zvVmZmlcg0OSdOA7wOHRUR7T/tFxIKIaEpGPab3Fy+9gmr9+uquqmppgZdf7n2frbeGDRscGGZmXWQ65YikRuCXETG1zLYdgd8CR0fE7ZUec8SIptiw4zJ4/PHuGyuddmTiRGjvMaeSmsaGDZUWycxs0KvllCOZDQCUdAUwE5goqQ34GjAKICIuBL4KTAC+q2SSwnUVv6merp6q9Kqq3kID4PLLKzuOmdkwVLhJDvtd42hp6dw/0tW4cX03Y5mZFcywnuQQSK6eGju287pKr6o68cTet1900eaXy8xsGChmcDQ3w4IFyU2UIKlpLFhQWUd2b81U48a5M9zMrA+Fm+Rwo+ZmuOIKePppWLSostf0ddWVaxtmZn0qZo0DkhC4+Wa45x5obKzsUty+5rJybcPMrE/FDI6WFpgzJ5nYEJKO8jlz+g6Pch3qHSZMqF35zMyGsGIGx7x5m0KjQyWz447o5e2ec07/y2VmNgwU83Jc7knmjeqqr4F76jYZ+yYF+xzMzKrhy3E3Z3bc/tzkyczMNipmcGzOOI7emrHcv2FmVrHCBUcEm8ZxbLttsrKhoe9xHL11jLt/w8ysYoXr45CaIqI1WfjBD5Lp1Bcvhje/ufcXjhyZzKLb/YCe0NDMhjz3cXToGPg3ZUrfYznKhQa4U9zMrErFDY6Wlk0jvSP6HsvR06W4dXXZlM/MbIgqbnDMmwevvdZ5XU9jOVpaem6O6qkmYmZmZRU3OKq5J0dvV1RNnlyb8piZDRPFDY5qxnL0dkVVJVOxm5nZRsUNjvnzYYstOq/raSxHT/0Ykic2NDOrUnGDo7kZvvnNTcu93ZPDV1SZmdVMcYMD4GMfS36ec05yy9ieag89jQz3iHEzs6oVOzjq65Ofq1f3vl9f283MrGJDPzhaWuCVV8pve+GF2pfJzGyIK3ZwXHFF8vNrX+t55Hhvl+L2NpuumZmVVdzg6LgLYIeeRo73NN4DfCmumdlmKO4kh42N5cdnTJ6cdJR3mDgR2tu77zduHLz8clbFNDMbVDzJIVQ3crycjv4RMzOrSnGDo9KR4z11gLtj3MxssxQyOCKo/C6AHTd76qqn9WZm1qtCBgew6S6Ao0cny72NHDczs5opZOf4hg2tSOmKmTOTn7fcUv4FI0aUn1rEd/4zs2Fk2HeOd8qBLbbofQBgT01SHsNhZrZZChkcndTX9xwcLS3w0kvd148e7TEcZmabKbPgkHSxpOckPdDDdkk6V9JiSfdLevtmnai+Hl59tfy2efNg7dru68ePd1+ImdlmyrLGcSlwSC/b3wtMSR9zgAsqPfDGpqqWFvjFL+Bvfys/5UhPYzp8Ka6Z2WbLLDgi4lagt9/QhwE/iMSdwNaS3lTxCTqmHOmYwLDclCO+FNfMrOby7OOYBCwtWW5L13UjaY6kVkmtG1fOmwerVnXecdWq3ic1NDOzfitE53hELIiIpo5LySKobMoRjxo3M6u5PIPjSWCHkuWGdF1lKplypNJpSczMrGJ5Bsd1wNHp1VXvAlZExNOVvLDiKUdmzSp/gJ7Wm5lZn0ZmdWBJVwAzgYmS2oCvAaMAIuJCYCEwC1gMrAI+UdUJOi6nPeEEePFFaGiAM8/sfJntwoXlX9vTejMz61MhpxxZs6aVUaPSFd/7XnI11ZNPwvbbd97Z042YmQGecqRzFnTcV6PcIEBPN2JmVnOFDI5OOoKj67Qjnm7EzCwTQzc4PN2ImVkmChkcnZqqbr89+fnOd3aedsTTjZiZZSKzq6oGREsLnH128jxi07QjkPRjPP5499e4f8PMrF8KWePYaN48eO21zus6ph2ZP3/T3QE7uH/DzKzfChkcG5uq+pp2pOuluAW79NjMbDAq5DiOV19tTfrEGxvLN0dNnpz87GnbkiUZltDMbPAZ9uM4Npo/P7l1bKmOaUcqmQTRzMyqVsjg2FhJam7e1DkOSW1iwYJkvSc4NDPLRCGDo5Ojjkp+futbSRNUxxgNT3BoZpaJ4gfHmDHJz65TjniCQzOzTBQyODr1548cmTy6jhx3H4eZWSYKGRzd1Nd3Dw73cZiZZaKQwdGpxtHSkgz6O+uszlOOlOvL6HqjJzMzq1rxpxyZM2fTvTU6phz5wx/gsss67yvB7Nme4NDMrJ8KOQDw5ZdbGTeOngcA1tXB+vXd13vwn5kNU8N+AGCfU46UC43e9jczs4oVMjg26qmju66uuv3NzKxixQ6O+fOTDu9SY8cm/RyeGdfMLBOFDI5OU44sWLDpLoAdU468+92eGdfMLCOF7Bx/6aVWxo8vWXnYYbB0KdxzT7Lc26y57hw3s2Fo2HeOd9N1AKBHjZuZZaaQwdGtktQ1ODxq3MwsM4UMjm7q6ztPcujbxpqZZab4wdHSAldcAc8803nKEXeOm5llopCd48uXt7LVVmyacmTVqk07jB2b3BWwvb37i905bmbDVC07x4s9V9W8eZ1DA5Llrus6uHPczKzfCtlU1eeUIz1x57iZWb8VMjg26ikIxo3rvs5TqpuZ1USmwSHpEEkPS1os6dQy23eUdLOkP0m6X1J1NwQvN+XIqFGwdm3XE3lKdTOzGsksOCTVAd8B3gvsBhwpabcuu30ZuCoi9gSOAL5bybG7TTkyYUKyPGkSvO51sGZN9xf4XuNmZjWRZY1jL2BxRDwaEWuAK4HDuuwTwOvS51sBT1V9luZmOP/85PmNN8ILL5Tfzx3jZmY1kWVwTAKWliy3petKnQ4cJakNWAicUO5AkuZIapXUWvZMHZMcrl7tUeNmZhnLu3P8SODSiGgAZgGXS+pWpohYEBFNHdcgdxt6ssUWyc/Vqz1q3MwsY1kGx5PADiXLDem6UscCVwFExB1APTCx6jOV1jiSg3XeXrBBjmZmg1mWwfFHYIqknSSNJun8vq7LPk8ABwJIeitJcDxf9ZluuSX5ecABydVTXa+qWrs2GSxoZmb9lllwRMQ64LPADcBDJFdPPSjpDEmHprt9Afi0pPuAK4BjooI5UDrt0dICZ565aYPvN25mlqlCzlW1bFnrxitwe7xpU1eep8rMhjHfyKlUJTUJjxo3M6uZQgZHp0pSX5fZ1tV51LiZWQ1VFBySxnVcJitpF0mHShqVbdEqNH/+pstxy1m/Hi67bNN9OszMrF8qrXHcCtRLmgT8Gvg4cGlWhapKczNccMGm5bq67vusWuWrqszMaqTS4FBErAIOB74bER8G3pZdsXrXrT//6KOTiQy/8hXYsKH8i3xVlZlZTVQcHJL2BpqB69N1Zf60z4mUDAL0lCNmZpmr9A6AJwGnAdekYzF2Bm7OrFR96FbjaGmB116Db33L9+IwM8tYRcEREb8DfgeQdpIvi4i5WRasYh33He9oonrllc7bfS8OM7OaqvSqqh9Jep2kccADwF8knZxt0SpU7r7jpXwvDjOzmqq0j2O3iHgJ+GfgV8BOJFdW5aJTU1Ulnd7uGDczq5lKg2NUOm7jn4HrImItyU2Y8ldJp7c7xs3MaqbS4LgIWAKMA26VNBl4KatCVaXcfce7mlXdrczNzKxnmz3JoaSR6Qy4A0pqiqefbuWNbyxZ2dFB3lNfhyc4NLNhbsAnOZS0laSzOm7fKul/SGofg4fU8zb3cZiZ1UylTVUXAyuBj6SPl4BLsipUVTpqG10vwy3lPg4zs5qpdADgmyPiX0qW/13SvRmUpyKdWtf6uhzX9xs3M6upSmscr0r6h44FSe8GXs2mSFXqqxmqYDeqMjMb7CoNjuOA70haImkJcD7wfzMrVTX6aoby/cbNzGqqouCIiPsiYg9gGjAtIvYEDsi0ZL2Wp2Shkstx3TluZlYzVd0BMCJeSkeQA3w+g/JUr7k5mYuqN+4cNzOrmf7cOraX61+z1a3bore5qCR3jpuZ1VB/gmPw9Dr31hQV4ZlxzcxqqNfLcSWtpHxACOjlRt8DbMcd4fHHy2+bMGFgy2JmNsT1WuOIiPER8boyj/ERUekYkJrr1lTluajMzAZMf5qqBo+rrup5W3v7wJXDzGwYGBrB0Vs41A2eW6ObmQ0FhQyOqgaDr1+fWTnMzIajQgZHN711gE+ePHDlMDMbBoZGcJxzTvkmKU9waGZWc4UMjm5NVc3NcNllnWseEybAxRd7DIeZWY1lGhySDpH0sKTFkk7tYZ+PSPqLpAcl/WizT9bcDMuWJakSkTx3aJiZ1VxmYzEk1QHfAQ4G2oA/SrouIv5Sss8U4DTg3RHxoqTXZ1UeMzOrjSxrHHsBiyPi0YhYA1wJHNZln08D34mIFwEi4rlKDuxbbJiZ5SfL4JgELC1ZbkvXldoF2EXSHyTdKemQDMtjZmY1kNu0ISXnnwLMBBqAWyXtHhHLS3eSNAeYkyy9Y0ALaGZmnWVZ43gS2KFkuSFdV6oNuC4i1kbEY8DfSIKkk4hYEBFNEdGULGdUYjMz61OWwfFHYIqknSSNBo4Aruuyz7UktQ0kTSRpuno0wzKZmVk/ZRYcEbEO+CxwA/AQcFVEPCjpDEmHprvdALRL+gtwM3ByRPQ5K6FrHGZm+VEU7Lew1BSPPtrKTjvlXRIzs+KQtKijub+/Cjly3MzM8lPI4ChYJcnMbEgpZHCYmVl+HBxmZlaVQgaHm6rMzPJTyOAwM7P8ODjMzKwqhQwON1WZmeWnkMFhZmb5cXCYmVlVChkcbqoyM8tPIYPDzMzyU8jgcI3DzCw/hQwOMzPLj4PDzMyqUsjgcFOVmVl+ChkcZmaWHweHmZlVpZDB4aYqM7P8FDI4zMwsPw4OMzOrSiGDw01VZmb5KWRwmJlZfhwcZmZWlUIGh5uqzMzyU8jgMDOz/Dg4zMysKoUMDjdVmZnlp5DBYWZm+SlkcLjGYWaWn0IGh5mZ5SfT4JB0iKSHJS2WdGov+/2LpJDUlGV5zMys/zILDkl1wHeA9wK7AUdK2q3MfuOBE4G7Kj22m6rMzPKTZY1jL2BxRDwaEWuAK4HDyuz3H8A3gNUZlsXMzGoky+CYBCwtWW5L120k6e3ADhFxfW8HkjRHUquk1toX08zMqpFb57ikEcBZwBf62jciFkREU0Q0JctZl87MzHqSZXA8CexQstyQruswHpgK3CJpCfAu4Dp3kJuZDW5ZBscfgSmSdpI0GjgCuK5jY0SsiIiJEdEYEY3AncChEeHmKDOzQSyz4IiIdcBngRuAh4CrIuJBSWdIOrR/x65FCc3MbHOMzPLgEbEQWNhl3Vd72HdmlmUxM7Pa8MhxMzOrSiGDw01VZmb5KWRwmJlZfgoZHK5xmJnlp5DBYWZm+XFwmJlZVQoZHG6qMjPLTyGDw8zM8uPgMDOzqhQyONxUZWaWn0IGh5mZ5cfBYWZmVSlkcLipyswsP4UMDjMzy4+Dw8zMqlLI4HBTlZlZfgoZHGZmlh8Hh5mZVaWQweGmKjOz/BQyOMzMLD+FDA7XOMzM8lPI4DAzs/w4OMzMrCqFDA43VZmZ5aeQwWFmZvlxcJiZWVUKGRxuqjIzy08hg8PMzPLj4DAzs6oUMjjcVGVmlp9Mg0PSIZIelrRY0qlltn9e0l8k3S/pJkmTsyyPmZn1X2bBIakO+A7wXmA34EhJu3XZ7U9AU0RMA64GvplVeczMrDayrHHsBSyOiEcjYg1wJXBY6Q4RcXNErEoX7wQaKjmwm6rMzPKTZXBMApaWLLel63pyLPCrchskzZHUKqm1huUzM7PNMDLvAgBIOgpoAvYrtz0iFgALkn2bwjUOM7P8ZBkcTwI7lCw3pOs6kXQQMA/YLyJey7A8ZjYIrV27lra2NlavXp13UYaE+vp6GhoaGDVqVGbnyDI4/ghMkbQTSWAcAXysdAdJewIXAYdExHMZlsXMBqm2tjbGjx9PY2MjkvIuTqFFBO3t7bS1tbHTTjtldp7M+jgiYh3wWeAG4CHgqoh4UNIZkg5Nd/sWsCXwE0n3SrqusmNnUmQzy8Hq1auZMGGCQ6MGJDFhwoTMa2+Z9nFExEJgYZd1Xy15flCW5zezYnBo1M5AfJaFHDluZlYr7e3tTJ8+nenTp/PGN76RSZMmbVxes2ZNr69tbW1l7ty5VZ2vsbGRZcuW9afIuRsUV1VVy01VZsNXSwvMmwdPPAE77gjz50Nz8+Yfb8KECdx7770AnH766Wy55Zb827/928bt69atY+TI8r8qm5qaaGpq2vyTF5RrHGZWGC0tMGcOPP548gfk448nyy0ttT3PMcccw3HHHceMGTM45ZRTuPvuu9l7773Zc8892WeffXj44YcBuOWWW3j/+98PJKHzyU9+kpkzZ7Lzzjtz7rnnVny+JUuWcMABBzBt2jQOPPBAnnjiCQB+8pOfMHXqVPbYYw/+8R//EYAHH3yQvfbai+nTpzNt2jQeeeSR2r75ChSyxmFmQ9NJJ0H6x39Zd94Jr3W5aH/VKjj2WPje98q/Zvp0+Pa3qy9LW1sbt99+O3V1dbz00kvcdtttjBw5khtvvJEvfelL/PSnP+32mr/+9a/cfPPNrFy5kl133ZXjjz++ostiTzjhBGbPns3s2bO5+OKLmTt3Ltdeey1nnHEGN9xwA5MmTWL58uUAXHjhhZx44ok0NzezZs0a1q9fX/2b66dCBoebqsyGp66h0df6/vjwhz9MXV0dACtWrGD27Nk88sgjSGLt2rVlX/O+972PMWPGMGbMGF7/+tfz7LPP0tDQ90xKd9xxBz/72c8A+PjHP84pp5wCwLvf/W6OOeYYPvKRj3D44YcDsPfeezN//nza2to4/PDDmTJlSi3eblUKGRxmNjT1VTNobEyap7qaPBluuaW2ZRk3btzG51/5ylfYf//9ueaaa1iyZAkzZ84s+5oxY8ZsfF5XV8e6dev6VYYLL7yQu+66i+uvv553vOMdLFq0iI997GPMmDGD66+/nlmzZnHRRRdxwAEH9Os81XIfh5kVxvz5MHZs53Vjxybrs7RixQomTUqm2rv00ktrfvx99tmHK6+8EoCWlhb23XdfAP7+978zY8YMzjjjDLbbbjuWLl3Ko48+ys4778zcuXM57LDDuP/++2tenr4UMjjcVGU2PDU3w4IFSQ1DSn4uWNC/q6oqccopp3Daaaex55579rsWATBt2jQaGhpoaGjg85//POeddx6XXHIJ06ZN4/LLL+ecc84B4OSTT2b33Xdn6tSp7LPPPuyxxx5cddVVTJ06lenTp/PAAw9w9NFH97s81VLRZgyUmuLmm1vpoaZoZgXz0EMP8da3vjXvYgwp5T5TSYsioibXDheyxmFmZvkpZHAUrJJkZjakFDI4zMwsP4UMDtc4zMzyU8jgMDOz/Dg4zMysKoUcOe6mKjOrlfb2dg488EAAnnnmGerq6thuu+0AuPvuuxk9enSvr7/lllsYPXo0++yzT7dtl156Ka2trZx//vm1L3iOXOMws2JpaUnmHhkxIvnZz6lxO6ZVv/feeznuuOP43Oc+t3G5r9CAJDhuv/32fpWhaBwcZlYcAzSv+qJFi9hvv/14xzvewXve8x6efvppAM4991x22203pk2bxhFHHMGSJUu48MILOfvss5k+fTq33XZbRcc/66yzmDp1KlOnTuXb6QRdr7zyCu973/vYY489mDp1Kj/+8Y8BOPXUUzees/Q+IXlyU5WZDR6DYF71iOCEE07g5z//Odtttx0//vGPmTdvHhdffDFnnnkmjz32GGPGjGH58uVsvfXWHHfccd1u/tSbRYsWcckll3DXXXcREcyYMYP99tuPRx99lO23357rr78eSObHam9v55prruGvf/0rkjZOrZ431zjMrDgGYF711157jQceeICDDz6Y6dOn8/Wvf522tjYgmWOqubmZH/7whz3eFbAvv//97/ngBz/IuHHj2HLLLTn88MO57bbb2H333fnNb37DF7/4RW677Ta22morttpqK+rr6zn22GP52c9+xtiuMzzmpJA1DjMbogbBvOoRwdve9jbuuOOObtuuv/56br31Vn7xi18wf/58/vznP9fknAC77LIL99xzDwsXLuTLX/4yBx54IF/96le5++67uemmm7j66qs5//zz+e1vf1uzc26uQtY43FRlNkwNwLzqY8aM4fnnn98YHGvXruXBBx9kw4YNLF26lP33359vfOMbrFixgpdffpnx48ezcuXKio+/7777cu2117Jq1SpeeeUVrrnmGvbdd1+eeuopxo4dy1FHHcXJJ5/MPffcw8svv8yKFSuYNWsWZ599Nvfdd1/N3md/uMZhZsXRMX/6vHnwxBOw445JaNRwXvURI0Zw9dVXM3fuXFasWMG6des46aST2GWXXTjqqKNYsWIFEcHcuXPZeuut+cAHPsCHPvQhfv7zn3PeeedtvJdGh0svvZRrr7124/Kdd97JMcccw1577QXApz71Kfbcc09uuOEGTj75ZEaMGMGoUaO44IILWLlyJYcddhirV68mIjjrrLNq9j77o5DTqv/6160cfHDeJTGzWvC06rXnadXLKFjWmZkNKYUMDjMzy08hg8M1DjOz/BQyOMxsaClaX+tgNhCfpYPDzHJVX19Pe3u7w6MGIoL29nbq6+szPU8hL8f198ts6GhoaKCtrY3nn38+76IMCfX19TQ0NGR6jkJejiu1ZnH5tpnZkFXLy3ELGRzQmncxzMwKpomIVtXiSO7jMDOzqjg4zMysKgVsqpoY0Jh3MczMCmYJEctq0lRVwKuq2hdFLKtJB0/RSWqtVWdX0fmz2MSfxSb+LDaRVLPOYTdVmZlZVRwcZmZWlSIGx4K8CzCI+LPYxJ/FJv4sNvFnsUnNPovCdY6bmVm+iljjMDOzHBUqOCQdIulhSYslnZp3ebIkaQdJN0v6i6QHJZ2Yrt9W0m8kPZL+3CZdL0nnpp/N/ZLenu87qD1JdZL+JOmX6fJOku5K3/OPJY1O149Jlxen2xtzLXiNSdpa0tWS/irpIUl7D9fvhaTPpf8/HpB0haT64fS9kHSxpOckPVCyrurvgqTZ6f6PSJrd13kLExyS6oDvAO8FdgOOlLRbvqXK1DrgCxGxG/Au4F/T93sqcFNETAFuSpch+VympI85wAUDX+TMnQg8VLL8DeDsiHgL8CJwbLr+WODFdP3Z6X5DyTnA/0bE/wH2IPlMht33QtIkYC7QFBFTgTrgCIbX9+JS4JAu66r6LkjaFvgaMAPYC/haR9j0KCIK8QD2Bm4oWT4NOC3vcg3g+/85cDDwMPCmdN2bgIfT5xcBR5bsv3G/ofAAGtL/BAcAvwQELANGdv1+ADcAe6fPR6b7Ke/3UKPPYSvgsa7vZzh+L4BJwFJg2/Tf+ZfAe4bb94JkRPQDm/tdAI4ELipZ32m/co/C1DjY9CXp0JauG/LSKvWewF3AGyLi6XTTM8Ab0udD/fP5NnAKsCFdngAsj4h16XLp+934WaTbV6T7DwU7Ac8Dl6TNdt+XNI5h+L2IiCeB/waeAJ4m+XdexPD8XpSq9rtQ9XekSMExLEnaEvgpcFJEvFS6LZI/D4b8ZXGS3g88FxGL8i7LIDASeDtwQUTsCbzCpqYIYFh9L7YBDiMJ0+2BcXRvthnWsvouFCk4ngR2KFluSNcNWZJGkYRGS0T8LF39rKQ3pdvfBDyXrh/Kn8+7gUMlLQGuJGmuOgfYWlLHtDml73fjZ5Fu3wpoH8gCZ6gNaIuIu9Llq0mCZDh+Lw4CHouI5yNiLfAzku/KcPxelKr2u1D1d6RIwfFHYEp6xcRokk6w63IuU2YkCfh/wEMRcVbJpuuAjqseZpP0fXSsPzq9cuJdwIqS6mqhRcRpEdEQEY0k/+6/jYhm4GbgQ+luXT+Ljs/oQ+n+Q+Iv8Ih4Blgqadd01YHAXxiG3wuSJqp3SRqb/n/p+CyG3feii2q/CzcA/yRpm7QW90/pup7l3bFTZSfQLOBvwN+BeXmXJ+P3+g8kVcz7gXvTxyySNtmbgEeAG4Ft0/1FctXZ34E/k1xpkvv7yOBzmQn8Mn2+M3A3sBj4CTAmXV+fLi9Ot++cd7lr/BlMJ7mb2f3AtcA2w/V7Afw78FfgAeByYMxw+l4AV5D076wlqY0euznfBeCT6eeyGPhEX+f1yHEzM6tKkZqqzMxsEHBwmJlZVRwcZmZWFQeHmZlVxcFhZmZVcXCYdSFpvaR7Sx41m4lZUmPpTKZmRTSy713Mhp1XI2J63oUwG6xc4zCrkKQlkr4p6c+S7pb0lnR9o6Tfpvc4uEnSjun6N0i6RtJ96WOf9FB1kr6X3kfi15K2yO1NmW0GB4dZd1t0aar6aMm2FRGxO3A+yYy9AOcBl0XENKAFODddfy7wu4jYg2Q+qQfT9VOA70TE24DlwL9k+m7Maswjx826kPRyRGxZZv0S4ICIeDSdgPKZiJggaRnJ/Q/WpuufjoiJkp4HGiLitZJjNAK/ieQmO0j6IjAqIr4+AG/NrCZc4zCrTvTwvBqvlTxfj/sarWAcHGbV+WjJzzvS57eTzNoL0Azclj6/CTgeNt4vfauBKqRZlvyXjll3W0i6t2T5fyOi45LcbSTdT1JrODJddwLJHflOJrk73yfS9ScCCyQdS1KzOJ5kJlOzQnMfh1mF0j6OpohYlndZzPLkpiozM6uKaxxmZlYV1zjMzKwqDg4zM6uKg8PMzKri4DAzs6o4OMzMrCoODjMzq8r/B4Orco2UZ0t4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 151.63 seconds\n",
      "\n",
      "---- Validation Set ----\n",
      "Predictions : torch.Size([328])\n",
      "328 vs 328\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 85.915 %\n",
      "- Recall : 72.619 %\n",
      "- F1 : 0.7871\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 67.89 %\n",
      "- Recall : 86.047 %\n",
      "- F1 : 0.75897\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 86.842 %\n",
      "- Recall : 83.544 %\n",
      "- F1 : 0.85161\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 83.333 %\n",
      "- Recall : 75.949 %\n",
      "- F1 : 0.7947\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 79.573 %\n",
      "- Precision : 80.995 %\n",
      "- Recall : 79.54 %\n",
      "- F1 : 0.80261\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Twitter15_ResNet10_CNN_DistilBERT_Finetuned Validation, 79.573, 80.995, 79.54, 0.80261, 85.915, 72.619, 0.7871, 67.89, 86.047, 0.75897, 86.842, 83.544, 0.85161, 83.333, 75.949, 0.7947, \n",
      "\n",
      "---- Test Set ----\n",
      "Predictions : torch.Size([145])\n",
      "145 vs 145\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 74.194 %\n",
      "- Recall : 65.714 %\n",
      "- F1 : 0.69697\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 58.824 %\n",
      "- Recall : 78.947 %\n",
      "- F1 : 0.67416\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 82.353 %\n",
      "- Recall : 77.778 %\n",
      "- F1 : 0.8\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 75.862 %\n",
      "- Recall : 61.111 %\n",
      "- F1 : 0.67692\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 71.034 %\n",
      "- Precision : 72.808 %\n",
      "- Recall : 70.888 %\n",
      "- F1 : 0.71835\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Twitter15_ResNet10_CNN_DistilBERT_Finetuned Validation, 71.034, 72.808, 70.888, 0.71835, 74.194, 65.714, 0.69697, 58.824, 78.947, 0.67416, 82.353, 77.778, 0.8, 75.862, 61.111, 0.67692, \n"
     ]
    }
   ],
   "source": [
    "model_name = f\"Twitter15_ResNet10_CNN_{unique_name}\"\n",
    "start = time.time()\n",
    "print(f\"Multiclass Classification {model_name}\")\n",
    "model = ResNetClassifier(CNNResNet10(n_output=4), train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss, n_features=16, model_type=\"cnn\") #, device=\"cpu\")\n",
    "model.train_eval(torch.Tensor(train_vectors.reshape(train_vectors.shape[0], 24, 32)),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors.reshape(val_vectors.shape[0], 24, 32)),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=1024)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\n---- Validation Set ----\")\n",
    "preds = model.predict(val_vectors.reshape(val_vectors.shape[0], 1, 24, 32))\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\n---- Test Set ----\")\n",
    "preds = model.predict(test_vectors.reshape(test_vectors.shape[0], 1, 24, 32))\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c746093f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification Twitter15_ResNet18_CNN_DistilBERT_Finetuned\n",
      "Using cuda\n",
      "Saving after new best accuracy : 25.61\n",
      "Saving after new best accuracy : 26.22\n",
      "Saving after new best accuracy : 26.829\n",
      "Saving after new best accuracy : 39.939\n",
      "Saving after new best accuracy : 50.305\n",
      "Saving after new best accuracy : 54.268\n",
      "Saving after new best accuracy : 56.098\n",
      "Saving after new best accuracy : 58.232\n",
      "Saving after new best accuracy : 63.11\n",
      "Saving after new best accuracy : 67.988\n",
      "Saving after new best accuracy : 71.037\n",
      "Saving after new best accuracy : 72.256\n",
      "Saving after new best accuracy : 73.476\n",
      "Saving after new best accuracy : 74.085\n",
      "Saving after new best accuracy : 74.695\n",
      "Saving after new best accuracy : 75.305\n",
      "Saving after new best accuracy : 75.61\n",
      "Saving after new best accuracy : 76.22\n",
      "Saving after new best accuracy : 76.524\n",
      "Saving after new best accuracy : 77.744\n",
      "Saving after new best accuracy : 78.049\n",
      "-- Epoch 50, Train Loss : 8.727570821065456e-05, Test Loss : 1.2951250076293945\n",
      "Saving after new best accuracy : 78.354\n",
      "Saving after new best accuracy : 78.659\n",
      "-- Epoch 100, Train Loss : 3.95951938116923e-05, Test Loss : 1.3744431734085083\n",
      "Saving after new best accuracy : 78.963\n",
      "Saving after new best accuracy : 79.268\n",
      "-- Epoch 150, Train Loss : 2.5793417080421932e-05, Test Loss : 1.3577806949615479\n",
      "-- Epoch 200, Train Loss : 1.9233424609410577e-05, Test Loss : 1.3496636152267456\n",
      "Saving after new best accuracy : 79.573\n",
      "-- Epoch 250, Train Loss : 1.5305555280065164e-05, Test Loss : 1.346022129058838\n",
      "Saving after new best accuracy : 79.878\n",
      "-- Epoch 300, Train Loss : 1.2648609299503732e-05, Test Loss : 1.344780683517456\n",
      "-- Epoch 350, Train Loss : 1.0713301890064031e-05, Test Loss : 1.3449386358261108\n",
      "-- Epoch 400, Train Loss : 9.235337529389653e-06, Test Loss : 1.3459599018096924\n",
      "-- Epoch 450, Train Loss : 8.069891009654384e-06, Test Loss : 1.3475227355957031\n",
      "-- Epoch 500, Train Loss : 7.1317199399345554e-06, Test Loss : 1.3494449853897095\n",
      "-- Epoch 550, Train Loss : 6.356048743327847e-06, Test Loss : 1.3516007661819458\n",
      "-- Epoch 600, Train Loss : 5.709732704417547e-06, Test Loss : 1.3539258241653442\n",
      "-- Epoch 650, Train Loss : 5.162545676284935e-06, Test Loss : 1.3563482761383057\n",
      "-- Epoch 700, Train Loss : 4.69539372716099e-06, Test Loss : 1.3588322401046753\n",
      "-- Epoch 750, Train Loss : 4.290348897484364e-06, Test Loss : 1.361365556716919\n",
      "-- Epoch 800, Train Loss : 3.938274858228397e-06, Test Loss : 1.3639174699783325\n",
      "-- Epoch 850, Train Loss : 3.630966830314719e-06, Test Loss : 1.3664767742156982\n",
      "-- Epoch 900, Train Loss : 3.357176183271804e-06, Test Loss : 1.3690285682678223\n",
      "-- Epoch 950, Train Loss : 3.1164354368229397e-06, Test Loss : 1.3715846538543701\n",
      "-- Epoch 1000, Train Loss : 2.899367927966523e-06, Test Loss : 1.3741416931152344\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 273.54 seconds\n",
      "\n",
      "---- Validation Set ----\n",
      "Predictions : torch.Size([328])\n",
      "328 vs 328\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 89.552 %\n",
      "- Recall : 71.429 %\n",
      "- F1 : 0.7947\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 68.868 %\n",
      "- Recall : 84.884 %\n",
      "- F1 : 0.76042\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 89.189 %\n",
      "- Recall : 83.544 %\n",
      "- F1 : 0.86275\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 77.778 %\n",
      "- Recall : 79.747 %\n",
      "- F1 : 0.7875\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 79.878 %\n",
      "- Precision : 81.347 %\n",
      "- Recall : 79.901 %\n",
      "- F1 : 0.80618\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Twitter15_ResNet18_CNN_DistilBERT_Finetuned Validation, 79.878, 81.347, 79.901, 0.80618, 89.552, 71.429, 0.7947, 68.868, 84.884, 0.76042, 89.189, 83.544, 0.86275, 77.778, 79.747, 0.7875, \n",
      "\n",
      "---- Test Set ----\n",
      "Predictions : torch.Size([145])\n",
      "145 vs 145\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 75.862 %\n",
      "- Recall : 62.857 %\n",
      "- F1 : 0.6875\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 56.863 %\n",
      "- Recall : 76.316 %\n",
      "- F1 : 0.65169\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 81.818 %\n",
      "- Recall : 75.0 %\n",
      "- F1 : 0.78261\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 71.875 %\n",
      "- Recall : 63.889 %\n",
      "- F1 : 0.67647\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 69.655 %\n",
      "- Precision : 71.604 %\n",
      "- Recall : 69.515 %\n",
      "- F1 : 0.70544\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Twitter15_ResNet18_CNN_DistilBERT_Finetuned Validation, 69.655, 71.604, 69.515, 0.70544, 75.862, 62.857, 0.6875, 56.863, 76.316, 0.65169, 81.818, 75.0, 0.78261, 71.875, 63.889, 0.67647, \n"
     ]
    }
   ],
   "source": [
    "model_name = f\"Twitter15_ResNet18_CNN_{unique_name}\"\n",
    "start = time.time()\n",
    "print(f\"Multiclass Classification {model_name}\")\n",
    "model = ResNetClassifier(CNNResNet18(n_output=4), train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss, n_features=16, model_type=\"cnn\") #, device=\"cpu\")\n",
    "model.train_eval(torch.Tensor(train_vectors.reshape(train_vectors.shape[0], 24, 32)),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors.reshape(val_vectors.shape[0], 24, 32)),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=1024)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\n---- Validation Set ----\")\n",
    "preds = model.predict(val_vectors.reshape(val_vectors.shape[0], 1, 24, 32))\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\n---- Test Set ----\")\n",
    "preds = model.predict(test_vectors.reshape(test_vectors.shape[0], 1, 24, 32))\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28d251e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
