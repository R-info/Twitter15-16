{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Twitter15-Multi\"\n",
    "unique_name = \"RoBERTa_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "bigram_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter15_RoBERTa_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>691809004356501505</td>\n",
       "      <td>america is a nation of second chances â€”@potus ...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693204708933160960</td>\n",
       "      <td>brandon marshall visits and offers advice, sup...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>551099691702956032</td>\n",
       "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "1  714598641827246081  an open letter to trump voters from his top st...   \n",
       "2  691809004356501505  america is a nation of second chances â€”@potus ...   \n",
       "3  693204708933160960  brandon marshall visits and offers advice, sup...   \n",
       "4  551099691702956032  rip elly may clampett: so sad to learn #beverl...   \n",
       "\n",
       "        label       tvt  cv_fold        tt        tvt2      tvt2_1  \\\n",
       "0  unverified  training        1  training    training  validation   \n",
       "1  unverified  training        1      test    training    testting   \n",
       "2   non-rumor  training        2  training  validation  validation   \n",
       "3   non-rumor  training        1  training    testting    testting   \n",
       "4        true  training        3  training  validation    training   \n",
       "\n",
       "       tvt2_2    tvt2_3  \n",
       "0    training  training  \n",
       "1    training  training  \n",
       "2  validation  testting  \n",
       "3    training  training  \n",
       "4  validation  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter15_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unverified', 'non-rumor', 'true', 'false']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = data['label'].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 2, 1, 0, 2, 0, 3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d['label'])\n",
    "    labs = [1 if idx == lab else 0 for idx in range(len(labels_str))]\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#ferguson pd', 'bathroom policy', 'institutional racism', 'want to', 'bag charge', 'ios 8', 'can be', 'clinton campaign', 'new transgender', 'protest at']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_terms = []\n",
    "with open(\"../../data/processed/twitter15-multi_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        vector_terms.append(t.strip())\n",
    "\n",
    "print(vector_terms[:10])\n",
    "len(vector_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2unigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(text)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def text2trigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    trigrams = nltk.trigrams(text)\n",
    "    trigrams = map(' '.join, trigrams)\n",
    "    trigrams = [bgr for bgr in trigrams]\n",
    "    \n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def custom_vectors_generation(texts, vector_terms):\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "        trigrams = text2trigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(vector_terms) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in vector_terms:\n",
    "                idx = vector_terms.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        for tgr in trigrams:\n",
    "            if tgr in vector_terms:\n",
    "                idx = vector_terms.index(tgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        vectors.append(init_vec)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 1519, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "terms_vectors = custom_vectors_generation(texts, vector_terms)\n",
    "\n",
    "vectors = np.concatenate([vectors, terms_vectors], axis=1)\n",
    "vectors = vectors.reshape(vectors.shape[0], vectors.shape[1], 1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1004, 1519, 1)\n",
      "(355, 1519, 1)\n",
      "(131, 1519, 1)\n",
      "(1004,)\n",
      "(355,)\n",
      "(131,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv1d(n_input, 512, 1, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 128, 1, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=1, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, n_output)\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 80.845\n",
      "Saving after new best accuracy : 83.099\n",
      "-- Epoch 50, Train Loss : 0.004198941169306636, Test Loss : 0.9572575688362122\n",
      "-- Epoch 100, Train Loss : 0.0010238933027721941, Test Loss : 1.1235121488571167\n",
      "-- Epoch 150, Train Loss : 0.0004476801404962316, Test Loss : 1.2219526767730713\n",
      "-- Epoch 200, Train Loss : 0.0002167119091609493, Test Loss : 1.3079310655593872\n",
      "-- Epoch 250, Train Loss : 0.00013156578643247485, Test Loss : 1.375985026359558\n",
      "-- Epoch 300, Train Loss : 8.943272041506134e-05, Test Loss : 1.4263545274734497\n",
      "Saving after new best accuracy : 83.38\n",
      "-- Epoch 350, Train Loss : 6.48326204100158e-05, Test Loss : 1.4674698114395142\n",
      "-- Epoch 400, Train Loss : 4.910281677439343e-05, Test Loss : 1.5026181936264038\n",
      "-- Epoch 450, Train Loss : 3.840861245407723e-05, Test Loss : 1.5334601402282715\n",
      "-- Epoch 500, Train Loss : 3.078881036344683e-05, Test Loss : 1.5610588788986206\n",
      "-- Epoch 550, Train Loss : 2.5033671590790618e-05, Test Loss : 1.5862232446670532\n",
      "-- Epoch 600, Train Loss : 2.0449288967938628e-05, Test Loss : 1.6099052429199219\n",
      "-- Epoch 650, Train Loss : 1.705417798802955e-05, Test Loss : 1.6316088438034058\n",
      "-- Epoch 700, Train Loss : 1.4357647160068154e-05, Test Loss : 1.6523574590682983\n",
      "-- Epoch 750, Train Loss : 1.224374591402011e-05, Test Loss : 1.6720010042190552\n",
      "-- Epoch 800, Train Loss : 1.0542556083237287e-05, Test Loss : 1.6903231143951416\n",
      "-- Epoch 850, Train Loss : 9.162989499600371e-06, Test Loss : 1.707438349723816\n",
      "-- Epoch 900, Train Loss : 8.021484063647222e-06, Test Loss : 1.7236164808273315\n",
      "-- Epoch 950, Train Loss : 7.071284471749095e-06, Test Loss : 1.738959550857544\n",
      "-- Epoch 1000, Train Loss : 6.272669907048112e-06, Test Loss : 1.7536548376083374\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAFXCAYAAAC1NambAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAoo0lEQVR4nO3de5wU1Z338c+PYZwBJKJAjM7IjG7UJ4JcIo94iSuKbhLUmLgm0YBCouEFJqK5aEQSY3xk12Q3XtAokgTxMlET4y1K1niNuCpmYBHBy4pmkEHjBQVBRLn8nj+qBtthZrprprtrTvf3/Xr1i65LV52qaeY755yqU+buiIiI5KpH2gUQEZGwKDhERCQRBYeIiCSi4BARkUQUHCIikoiCQ0REElFwiHSRmR1mZi8UcX//bmZnF2t/bez/QjO7qYPlT5nZ4GKWSYpLwSFdYmZNZnZU2uUoJjNzM/t0y7S7z3f3fYu074HAqcC1xdhfJ/0ncFHahZDCUXCItMPMeqZdhjZMBOa5+/tpF6QDdwNHmNmn0i6IFIaCQwrCzKrM7HIzezV+XW5mVfGyAWZ2j5mtMbO3zWy+mfWIl/3IzFaZ2Toze8HMxrSz/Z3M7AYze9PMVpjZj82sR7zfNWY2JGPdgWb2vpl9Mp4+1swWx+s9bmZDM9ZtisuwBHivdXiY2aPx26fNbL2Zfd3MRptZc6ttnGNmS8zsPTP7rZntamZ/jo/rATPbOWP9g+JyrDGzp81sdAen9ovAX1uVKdvxTDOzZ83sHTO7zsyqM5Z/28yWxz+Hu81s94xlg83s/njZ62Z2fsZud4jP/zozW2ZmI1sWuPtGYCHw+Q6OQ0Lm7nrp1ekX0AQc1cb8i4AngU8CA4HHgf8XL/t3YBZQGb8OAwzYF1gJ7B6vVw/8Uzv7vQG4C+gbr/e/wGnxsjnAjIx1vwP8V/x+BPAGMAqoACbEx1CVcTyLgT2AXu3s24FPZ0yPBppbnZMngV2Bmnh/i+J9VwMPAT+N160BVgNjif6QOzqeHtjOvt8E/m/GdC7HszQ+nl2A/wYujpcdCbwFfBaoAq4EHo2X9QVeA34Ql7kvMCpediGwMS5zRfzzfLJVOWcCl6b9/dSrMC/VOKRQxgEXufsb7v4m8DPglHjZJmA3oM7dN3nUR+DAFqJfYPuZWaW7N7n7S603bGYVwEnANHdf5+5NwC8ztv+7eHmLb8TzACYB17r7Anff4u7XAx8AB2WsP9PdV3rXmoOudPfX3X0VMB9Y4O7/49Ff43cQ/cIHGE/U9DTP3be6+/1AI9Ev5bb0A9ZlTOdyPFfFx/M2MAM4OZ4/Dpjj7ovc/QNgGnCwmdUDxwL/cPdfuvvG+DwvyNjmY3GZtwA3AsNalXNdXFYpQQoOKZTdgRUZ0yvieQD/ASwH/mJmL5vZeQDuvhw4m+gv2jfM7JbMppMMA4hqKq23XxO/fxjobWaj4l+Cw4l+WQPUAT+Im3XWmNkaor/GM/ezMunBtuH1jPfvtzG9Y0Z5vtqqPJ8jCta2vEP013+LpMeT+XP42M/I3dcT1XZq4m1sF9oZ/pHxfgNQ3apZry+wpoPPS8AUHFIorxL9UmsxKJ5H/NfrD9x9L+BLwPdb+jLc/Xfu/rn4sw78vI1tv0VUa2m9/VXxNrYAvyf6y/pk4B53b/krfSVRM1a/jFdvd785Y1vFHDJ6JXBjq/L0cfdL2ll/CbBPq89nO549Mt5v+znQ6mdkZn2A/kTncSWwVxeO6zPA0134vHRjCg7Jh0ozq8549QRuBn4cd0wPAC4AboJtnbmfNjMD1hI1UW01s33N7Mi4E30j0V/mW1vvLCMYZphZXzOrA77fsv3Y74CvEzXH/C5j/q+ByXFtxMysj5kdY2aZf8Vn8zpd+6Wa6SbgODP7vJlVxOdvtJnVtrP+PODwjOlcjuc7ZlZrZrsA04Fb4/k3A980s+HxOf83oia1JuAeYDczOzu+4KCvmY3K5YDizvcDgPtzPAcSGAWH5MM8ol/yLa8LgYuJ2uqXAM8QdQ5fHK+/N/AAsB54Arja3R8m6t+4hKhG8Q+ijvVp7ezzTOA94GXgMaJwmNOyMG6Pf4+oOebPGfMbgW8DVxE1+ywnusQ1iQuB6+Omoa8l/OzHuPtK4HjgfKKO75XAObT/f/MGYKyZ9Yo/n8vx/A74C9G5eon45+DuDwA/Af5I1BH+T8R9Q3EN7WjgOKKfxYvAETke1nHAI+7+atY1JUgW9UmKSCjM7N+AN9z98hzWbQJOj0OiKMxsAdEVbkuLtU8pru54g5OIdMDdz8++VnrcPacmLQmXmqpERCQRNVWJiEgiqnGIiEgiCg4REUkkuM5xswEeDU0UOeCA9MoiIhKKhQsXvuXuA/OxreCCIwqNRgDq6qCxMdXCiIgEwcxWZF8rN8E2VfXuDTNmpF0KEZHyE2Rw1NXB7NkwblzaJRERKT8BNlVBU1PaJRARKV9B1jhERCQ9Cg4REUkkyODQze4iIukJMji2bveEBhERKZaCBYeZ7WFmD5vZs2a2zMzOamOd0Wa21swWx68Lctm2gkNEJD2FvKpqM/ADd18UP41soZnd7+7Ptlpvvrsfm2TDaqoSEUlPwWoc7v6auy+K368DngNq8rFt1ThERNJTlD4OM6sHRgAL2lh8sJk9bWZ/NrPB7Xx+kpk1mlkjKDhERNJU8OAwsx2Jnml8tru/22rxIqDO3YcBVwJ3trUNd5/t7iPdfSQoOERE0lTQ4DCzSqLQaHD321svd/d33X19/H4eUGlmA7JtV8EhIpKeQl5VZcBvgefc/dJ21vlUvB5mdmBcntXZtq3OcRGR9BTyqqpDgVOAZ8xscTzvfGAQgLvPAk4EppjZZuB94CTP4Vm2qnGIiKSnYMHh7o8BlmWdq4Crkm5bwSEikh7dOS4iIokoOEREJJEgg0Od4yIi6QkyOFTjEBFJj4JDREQSUXCIiEgiCg4REUkkyOBQ57iISHqCDA7VOERE0qPgEBGRRBQcIiKSiIJDREQSCTI41DkuIpKeIINDNQ4RkfQoOEREJBEFh4iIJKLgEBGRRIIMDnWOi4ikJ8jgUI1DRCQ9Cg4REUlEwSEiIokEGRzq4xARSU+QwaEah4hIehQcIiKSiIJDREQSUXCIiEgiQQaHOsdFRNITZHCoxiEikh4Fh4iIJKLgEBGRRBQcIiKSSJDBcdxxUF8PDQ1pl0REpPwEGRzusGIFTJqk8BARKbYgg6PFhg0wfXrapRARKS9BBwfAK6+kXQIRkfISfHAMGpR2CUREykvQwdG7N8yYkXYpRETKS5DBYQZ1dTB7Nowbl3ZpRETKS8+0C9AZDQ1w8slpl0JEpDwFWePQDYAiIulRcIiISCJBBoeGVRcRSU+QwaEah4hIehQcIiKSiIJDREQSKVhwmNkeZvawmT1rZsvM7Kw21jEzm2lmy81siZl9NpdtKzhERNJTyPs4NgM/cPdFZtYXWGhm97v7sxnrfBHYO36NAq6J/+2QOsdFRNJTsBqHu7/m7ovi9+uA54CaVqsdD9zgkSeBfma2W7Ztq8YhIpKeovRxmFk9MAJY0GpRDbAyY7qZ7cMFM5tkZo1m1ggKDhGRNBU8OMxsR+CPwNnu/m5ntuHus919pLuPBAWHiEiaChocZlZJFBoN7n57G6usAvbImK6N53VIwSEikp5CXlVlwG+B59z90nZWuxs4Nb666iBgrbu/lm3b6hwXEUlPIa+qOhQ4BXjGzBbH884HBgG4+yxgHjAWWA5sAL6Zy4ZV4xARSU/BgsPdHwMsyzoOfCfpthUcIiLp0Z3jIiKSSJDBoT4OEZH0BBkcqnGIiKRHwSEiIokoOEREJBEFh4iIJBJkcKhzXEQkPUEGh2ocIiLpUXCIiEgiCg4REUkkuOAwU3CIiKQpuOAAdY6LiKQpuOBQjUNEJF3BBQcoOERE0qTgEBGRRIILDjVViYikK7jgAHWOi4ikKcjgUI1DRCRHDQ1QX88BcEC+NlnIZ44XhJqqRKTsNTTAt74FH36Yyu6DCw5QcIhIiTrjDLjmmrRLkVVwTVWbN8O110J9fRS6IiLd3hlnRM0l2V4BhAYEWuMAWLECJk2K3o8bl25ZRKRMHXUUPPhg2qUouuBqHJk2bIDp09MuhYiUnIYGqKrKXkMow9CAgGscLV55Je0SiEhQUu5YLgXBB8egQWmXQES6DYVCUQTdVNW7N8yYkXYpRKRosnUyjx9fnqExZUp0Z3QHr4WwMF+7C7bGUVcXhYY6xkVKSJl2Nrepuhp+85tu+UsuuOCoqoIvfxluuSXtkohIYgqGbh0IuQouOHTnuEg3FsgNbAUxZgw88EDapSiK4IIDFBwiqSrHWsOUKXD11WmXotsILjjMYMuWtEshUsLKLRgUCokFeVWVahwiXZDt5rZSCo0crjZSaCQXZI1DwSGSRTncz1ACncyhCi44QMEhsk0pNyuVUWdzaIJsqlIfh5SVjm56Czk0xozpuAlJodFtBVfjUFOVlKxSqz2oKalkBRccoOCQgJVa34Oak8pScMGhGocEoVQCQsEgbVAfh0hXtHdpa0iD7XV0yapCQ9qgGodIrkLug9BNbpJHwQUHKDikwEIdb0nNSlIkwQWHahySV6HVInSlknQDwQUHqI9DOiG0WoRqD9KNBdk5rhqHdKitG+a6a2i01zGt0JBuLLgah5qq5GNCuexVndNSQgpW4zCzOWb2hpktbWf5aDNba2aL49cFuW5bwVHGjjqqe1/22l4NQqEhJaSQNY65wFXADR2sM9/dj02yUdU4ykh3rk2oD0LKWMFqHO7+KPB2IbatzvES1bpvojvUJqqr4aab1AchkiHtPo6Dzexp4FXgh+6+rK2VzGwSMAmgd+8hqnGUiu52KaxqESI5SfOqqkVAnbsPA64E7mxvRXef7e4j3X1kVVWVgiNUrfsn0goN1SJEuiS14HD3d919ffx+HlBpZgOyfU59HAFp3fSURlC0FRLvv68b6ES6ILXgMLNPmZnF7w+My7I6l8+qj6Obaj3gXxr3TrS+qkkhIZJ3BevjMLObgdHAADNrBn4KVAK4+yzgRGCKmW0G3gdOcnfPvl3VOLqVNPsp1CchkoqCBYe7n5xl+VVEl+smpuBIUZqXyOomOpFuIe2rqhJTjSMFaYzzpMH8RLqt4IID1MdRFMVuglKzk0gwggsO1TgKqJhhoaAQCZZGxy13mZfMFjI0Wl8Wq9AQCVZwNQ5QcHRZsTq41ZktUpKCCw4z9XF0WqGbotT8JFIWcmqqMrM+ZtYjfr+PmX3JzCoLW7T2qcaRQKGbojJvuFNoiJSFXPs4HgWqzawG+AtwCtGw6UX31luwbh3U10ctLtKOlnGh8n0Zbeu+CjVFiZSdXJuqzN03mNlpwNXu/gszW1zAcrWrpbaxYgVMmhS916X+GQrRHKUmKBHJkGuNw8zsYGAccG88r6IwRcrdhg0wfXrapegGMseIyldojBmjJigRaVOuNY6zgWnAHe6+zMz2Ah4uWKkSeOWVtEuQssGD4dln87Mt3a0tIjnIKTjc/a/AXwHiTvK33H1qIQuWq0GD0i5BCvI9BIgumxWRBHK9qup3ZvYJM+sDLAWeNbNzClu07Hr3hhkz0i5FEbVcIZWP0MhsilJoiEgCufZx7Ofu7wJfBv4M7El0ZVXRVcQ9K4MGwezZZdKqkq/AyLwiSv0WItJJufZxVMb3bXwZuMrdN5lZ1mdnFMKuu8Krr8JLL0HP4G5fTChfTVK6KkpE8ijXGse1QBPQB3jUzOqAdwtVqFyU9E2ADQ3Qo0fXQ6OlOUqhISJ5lGvn+ExgZsasFWZ2RGGK1LHoYbMlHBz5uEpKnd0iUkC5do7vZGaXmllj/PolUe0jNSUXHA0NUSp2JTRahv9QaIhIAeXaSzCH6Gqqr8XTpwDXAScUolAdaalxlNRAh12pZfTsCXPnlslVAiLSHeQaHP/k7v+aMf2ztIYcaVESNY6uDA+iwBCRlOTaOf6+mX2uZcLMDgXeL0yROlYSfRwtl9d2JjR69owuqd20SaEhIqnItcYxGbjBzHaKp98BJhSmSLkJMji6cnltRQVcf73CQkRSl+tVVU8Dw8zsE/H0u2Z2NrCkgGXrUFDB0dAAp5wSdVx3hq6SEpFuJNEtdPHd4y2+D1ye19LkILjO8a50fO++O6xald/yiIh0Ua59HG2xvJWiE7p9jaPlQUqdDY0pUxQaItItdWXQjlSGHOn2neMNDTB+fOc/r+FBRKSb6zA4zGwdbQeEAb0KUqIsBqxYyCPUU337DJjazTqKu9Istd9+sGxZfssjIlIAHTZVuXtfd/9EG6++7p7aEIP1rGCX8yZ1n4eOt1xe25nQaLm8VqEhIoEw7+yVPikZaeaNLRN1ddDUlGJpgJqaaLjepHR5rYgUkZktdPeR+dhWVzrH05fmc2NbxpbqTGhMmQKbNys0RCRIYT/RIq3nxnZ2qBB1fItICQg2OLZW96ZHGs+N7UzTlO7HEJESEmRT1QoGserCIj83trNNU7ofQ0RKTJA1jiEs5b+/2Jc9irXDzjRN6fJaESlRQdY4KtlUvBsABw9OFhpmurxWREpakDWOHfiwOGNVJe3PUF+GiJQB1Tjas/POyUJjzBiFhoiUhSCDYwc+LGxw7LwzrFmT27otTVO6zFZEykSQTVUFrXEkCQ01TYlIGVKNI1OS0FDTlIiUqSCDo5JN+e8cTxIaU6aoaUpEylaQTVV5r3HkGhpmcOONGmNKRMpakDWO/+ZQRn29Pj/DqtfU5BYa/fpFT49SaIhImQsyOHrg9HpjBRtOmcRjZ3QhPAYPzu2S23794J13Or8fEZESUrDgMLM5ZvaGmS1tZ7mZ2UwzW25mS8zss0n30ds3MGjW9M5VPI46KrcHLyk0REQ+ppA1jrnAFzpY/kVg7/g1CbimMzup9VeYPj3hhxoachtGRKEhIrKdggWHuz8KvN3BKscDN3jkSaCfme2WdD+vMCj585wmTsy+jkJDRKRNafZx1AArM6ab43k5e4/enM+MZM9zGjw4evpeR8wUGiIi7Qiic9zMJplZo5k1AjjQRB3fZjZ39R5Hzs9zyrVf48YbO19YEZESl2ZwrIKPPVKjNp63HXef7e4jWx60PonZ7GVNPF43jtm5Ps8p136NKVN0ya2ISAfSDI67gVPjq6sOAta6+2u5fLCSTTQ0QFNTgt/xp5+efZ0xY+Dqq3PcoIhIeSrYneNmdjMwGhhgZs3AT4FKAHefBcwDxgLLgQ3AN3Pd9g58mLWb4mMaGmDjxo7XqajQMCIiIjkoWHC4+8lZljvwnc5sO/FYVblcRXX99Z0piohI2Qmic7y1RE8APOqo7FdRqV9DRCRnQQZHzjWOXDrE1a8hIpJIkMGRcx/H5MnZ11G/hohIIuEFR48eudU4Ghpg/fqO15kyJW/FEhEpFxb1UYdjpJn/DVi3cx2fuHJG+30Tfft2HBwVFdn7PkRESoSZLWy5F66rwqtxAAZ84p0VMGlS28/kyKW2oauoREQ6JcgaR2PmjLq66E7ATNlqG336ZA8WEZESUvY1jo9pPTRuLrWNa68tXHlEREpc6dU4BgyA1avb34BqGyJShlTjaNG7N9sNjdtRaIBqGyIiXRRecJjhwDufqGO7oXGzPUO2Tx/dIS4i0kXhBUefPjxmh/GLM5q2D4Gzzur4s6ptiIh0WXjB0aMHvdjY9i0Y2fo2VNsQEemyIIOj2jZuf+d4tmYq1TZERPIivOAwo4oPtg+ObM1Uqm2IiORFeMHRowfVbTVVddRM1b9/QYskIlJOwguOd96hdusrXHRD/UfNU9maqa64ouDFEhEpFwV7AmDBbN2KAf3Xx2NVgZqpRESKKLwaR6YNG2D6dDVTiYgUUdjBAfiKFR2voGYqEZG8Cj44tmY7BDVTiYjkVdDB8R696cHW9ldQM5WISN4FFxybqQBgJbV8m9kdr6xmKhGRvAsuOJrZA4DDmJ99ZTVTiYjkXXDBgRkA1WzkCs7C2ltPzVQiIgURXHD0HxgVuZqNDKCDy3DVTCUiUhDBBUdfi57e9z98tv3aBqiZSkSkQIILDt54A4DocU4iIlJs4QVHLs9IV/+GiEjBhBccuVD/hohIwZRmcKh/Q0SkYMILDuuwSzz7chER6ZLwgmPAgI6X59IHIiIinRZecHQ0hDpAXV1xyiEiUqbCC46tHQxqCDBjRnHKISJSpsILjmzUMS4iUlClFRwVFWmXQESk5JVWcGzZknYJRERKXmkFhzrGRUQKrrSCQx3jIiIFV1rBoY5xEZGCCy84+vZte1zcKVOKXRIRkbIUXHC8PWAfZldMYTMVOLC1R0UUGldfnXbRRETKQnDBsWIFTN5yNZVspgdO3+rNNByq0BARKZbggqP1jeMbNsD06emURUSkHBU0OMzsC2b2gpktN7Pz2lg+0czeNLPF8ev0zuznlVe6XlYREclNz0Jt2MwqgF8BRwPNwN/M7G53f7bVqre6+3e7sq9Bg7ryaRERSaKQNY4DgeXu/rK7fwjcAhzf1Y32aFXi3r11+4aISDEVMjhqgJUZ083xvNb+1cyWmNltZrZHto3W1UG/ftH7PfaA2bN1+4aISDGl3Tn+J6De3YcC9wPXt7WSmU0ys0Yza9yy5U1+9rNo/uLFCg0RkWIrZHCsAjJrELXxvG3cfbW7fxBP/gY4oK0Nuftsdx/p7iMHDhzIDjtE8z/8MO9lFhGRLAoZHH8D9jazPc1sB+Ak4O7MFcxst4zJLwHP5bJhBYeISHoKdlWVu282s+8C9wEVwBx3X2ZmFwGN7n43MNXMvgRsBt4GJuaybQWHiEh6ChYcAO4+D5jXat4FGe+nAdOSbrclOD74oOP1REQk/9LuHO8U1ThERNKj4BARkUSCDI6qquhfBYeISPEFGRyqcYiIpCfI4Hjooejfo4+G+npoaEi1OCIiZSW44Hj7bbjkkui9e/R8jkmTFB4iIsUSXHCsWgUbN358np7JISJSPMEFR3v9Gnomh4hIcQQXHC0d463pmRwiIsURXHDU1ECvXh+fp2dyiIgUT3DBscsucNllH03X1emZHCIixVTQsaoK5RvfgMmT4T/+A374w7RLIyJdsWnTJpqbm9nY+qoX6ZTq6mpqa2uprKws2D6CDA7dAChSOpqbm+nbty/19fWYWdrFCZq7s3r1apqbm9lzzz0Ltp/gmqpAwSFSSjZu3Ej//v0VGnlgZvTv37/gtbcgg8MMKisVHCKlQqGRP8U4l0EGB0S1DgWHiHTV6tWrGT58OMOHD+dTn/oUNTU126Y/zPJLprGxkalTpybaX319PW+99VZXipy6IIOjoQHefx9++UuNVSVSbhoaov/3PXrk5/9///79Wbx4MYsXL2by5Ml873vf2za9ww47sHnz5nY/O3LkSGbOnNm1AgQouOB4++1obKqtW6NpjVUlUj4aGqL/7ytWFHasuokTJzJ58mRGjRrFueeey1NPPcXBBx/MiBEjOOSQQ3jhhRcAeOSRRzj22GMBuPDCC/nWt77F6NGj2WuvvRIFSlNTE0ceeSRDhw5lzJgxvBIPhfGHP/yBIUOGMGzYMP75n/8ZgGXLlnHggQcyfPhwhg4dyosvvpjfg89BcFdVrVq1fRNVy1hVupdDJGxnnw2LF7e//Mknt39k9IYNcNpp8Otft/2Z4cPh8suTl6W5uZnHH3+ciooK3n33XebPn0/Pnj154IEHOP/88/njH/+43Weef/55Hn74YdatW8e+++7LlClTcros9swzz2TChAlMmDCBOXPmMHXqVO68804uuugi7rvvPmpqalizZg0As2bN4qyzzmLcuHF8+OGHbNmyJfnBdVFwwaGxqkTKV+vQyDa/K7761a9SUVEBwNq1a5kwYQIvvvgiZsamTZva/MwxxxxDVVUVVVVVfPKTn+T111+ntrY2676eeOIJbr/9dgBOOeUUzj33XAAOPfRQJk6cyNe+9jVOOOEEAA4++GBmzJhBc3MzJ5xwAnvvvXc+DjeR4IKjvU5xjVUlEr5sNYP6+qh5qrW6OnjkkfyWpU+fPtve/+QnP+GII47gjjvuoKmpidGjR7f5maqWx5MCFRUVHfaP5GLWrFksWLCAe++9lwMOOICFCxfyjW98g1GjRnHvvfcyduxYrr32Wo488sgu7Sep4Po4amqisakyaawqkfIwY0Y6///Xrl1LTU0NAHPnzs379g855BBuueUWABoaGjjssMMAeOmllxg1ahQXXXQRAwcOZOXKlbz88svstddeTJ06leOPP54lS5bkvTzZBBccu+wSjU3VMtChxqoSKR/jxkX/3+vqovu5ivX//9xzz2XatGmMGDGiy7UIgKFDh1JbW0ttbS3f//73ufLKK7nuuusYOnQoN954I1dccQUA55xzDvvvvz9DhgzhkEMOYdiwYfz+979nyJAhDB8+nKVLl3Lqqad2uTxJmbsXfaddMXLkSG9sbGT8eHjiCXjppbRLJCJd8dxzz/GZz3wm7WKUlLbOqZktdPeR+dh+cDUOiC69u+suePll3cchIlJswXWOt9zHsWFDNN1yHTeouUpEpBiCq3GsWvVRaLTQM8dFRIonuODQfRwiIukKLjj0zHERkXQFFxxt3cdhBmPHplMeEZFyE1xw7LILTJjw8XnucP31urpKRJLryrDqEA10+Pjjj7e5bO7cuXz3u9/Nd5FTF1xwAMybt/08dZCLlIk8j6uebVj1bDoKjlIVZHC01xGuDnKRElekcdUXLlzI4YcfzgEHHMDnP/95XnvtNQBmzpzJfvvtx9ChQznppJNoampi1qxZXHbZZQwfPpz58+fntP1LL72UIUOGMGTIEC6PB+h67733OOaYYxg2bBhDhgzh1ltvBeC8887bts8f/vCHeT3OzgruPg6IOsLbGuhMHeQigesG46q7O2eeeSZ33XUXAwcO5NZbb2X69OnMmTOHSy65hL///e9UVVWxZs0a+vXrx+TJk9lxxx1z/qW+cOFCrrvuOhYsWIC7M2rUKA4//HBefvlldt99d+69914gGh9r9erV3HHHHTz//POY2bah1dMWZI2jvY5wdZCLlLgijKv+wQcfsHTpUo4++miGDx/OxRdfTHNzMxCNMTVu3Dhuuukmevbs3N/djz32GF/5ylfo06cPO+64IyeccALz589n//335/777+dHP/oR8+fPZ6eddmKnnXaiurqa0047jdtvv53era8MSkmQNY62+jg6mi8igegG46q7O4MHD+aJJ57Ybtm9997Lo48+yp/+9CdmzJjBM888k5d9Auyzzz4sWrSIefPm8eMf/5gxY8ZwwQUX8NRTT/Hggw9y2223cdVVV/HQQw/lbZ+dFWSNo63vTUfzRaREFGFc9aqqKt58881twbFp0yaWLVvG1q1bWblyJUcccQQ///nPWbt2LevXr6dv376sW7cu5+0fdthh3HnnnWzYsIH33nuPO+64g8MOO4xXX32V3r17M378eM455xwWLVrE+vXrWbt2LWPHjuWyyy7j6aefzttxdkWQNY6KCmjraYlmxS+LiBRRy4B006dHV8MMGhSFRh4HquvRowe33XYbU6dOZe3atWzevJmzzz6bffbZh/Hjx7N27VrcnalTp9KvXz+OO+44TjzxRO666y6uvPLKbc/SaDF37lzuvPPObdNPPvkkEydO5MADDwTg9NNPZ8SIEdx3332cc8459OjRg8rKSq655hrWrVvH8ccfz8aNG3F3Lr300rwdZ1cEOaz6woWN7S6/6SYNdigSEg2rnn8aVr0NdXXtL9O9HCIihRVkcHTUnKl+DhGRwgoyONQUJSKSniCDI5ujjkq7BCKSRGh9rd1ZMc5lSQbHgw/CGWekXQoRyUV1dTWrV69WeOSBu7N69Wqqq6sLup8gr6pqbGxkwABYvTr7+lOmwNVXF75cItI5mzZtorm5mY0bN6ZdlJJQXV1NbW0tlZWVH5ufz6uqgg2OhgYYPz5/21XAiEgpU3A0Rvdx9OoF+iNFRCQXI3FvzMtt0kH3cfzmN2mXQESk/AQdHOPGwZgxaZdCRKS8BNdUZWbrgBc+PnfwflDdK5UCiYgEoQn3t/LSVBXiIIcv5KuDJ3Rm1qhzEdG5+IjOxUd0Lj5iZu0P8pdQ0E1VIiJSfAoOERFJJMTgmJ12AboRnYuP6Fx8ROfiIzoXH8nbuQiuc1xERNIVYo1DRERSFFRwmNkXzOwFM1tuZuelXZ5CMrM9zOxhM3vWzJaZ2Vnx/F3M7H4zezH+d+d4vpnZzPjcLDGzz6Z7BPlnZhVm9j9mdk88vaeZLYiP+VYz2yGeXxVPL4+X16da8Dwzs35mdpuZPW9mz5nZweX6vTCz78X/P5aa2c1mVl1O3wszm2Nmb5jZ0ox5ib8LZjYhXv9FM5uQbb/BBIeZVQC/Ar4I7AecbGb7pVuqgtoM/MDd9wMOAr4TH+95wIPuvjfwYDwN0XnZO35NAq4pfpEL7izguYzpnwOXufungXeA0+L5pwHvxPMvi9crJVcA/+Xu/wcYRnROyu57YWY1wFRgpLsPASqAkyiv78Vc4Aut5iX6LpjZLsBPgVHAgcBPW8KmXe4exAs4GLgvY3oaMC3tchXx+O8Cjia6+XG3eN5uRPe1AFwLnJyx/rb1SuEF1Mb/CY4E7gEMeAvo2fr7AdwHHBy/7xmvZ2kfQ57Ow07A31sfTzl+L4AaYCWwS/xzvgf4fLl9L4B6YGlnvwvAycC1GfM/tl5br2BqHHz0JWnRHM8reXGVegSwANjV3V+LF/0D2DV+X+rn53LgXGBrPN0fWOPum+PpzOPddi7i5Wvj9UvBnsCbwHVxs91vzKwPZfi9cPdVwH8CrwCvEf2cF1Ke34tMSb8Lib8jIQVHWTKzHYE/Ame7+7uZyzz686DkL4szs2OBN9x9Ydpl6QZ6Ap8FrnH3EcB7fNQUAZTV92Jn4HiiMN0d6MP2zTZlrVDfhZCCYxWwR8Z0bTyvZJlZJVFoNLj77fHs181st3j5bsAb8fxSPj+HAl8ysybgFqLmqiuAfmbWMmxO5vFuOxfx8p2AHB77FYRmoNndF8TTtxEFSTl+L44C/u7ub7r7JuB2ou9KOX4vMiX9LiT+joQUHH8D9o6vmNiBqBPs7pTLVDBmZsBvgefc/dKMRXcDLVc9TCDq+2iZf2p85cRBwNqM6mrQ3H2au9e6ez3Rz/0hdx8HPAycGK/W+ly0nKMT4/VL4i9wd/8HsNLM9o1njQGepQy/F0RNVAeZWe/4/0vLuSi770UrSb8L9wH/YmY7x7W4f4nntS/tjp2EnUBjgf8FXgKmp12eAh/r54iqmEuAxfFrLFGb7IPAi8ADwC7x+kZ01dlLwDNEV5qkfhwFOC+jgXvi93sBTwHLgT8AVfH86nh6ebx8r7TLnedzMBxojL8bdwI7l+v3AvgZ8DywFLgRqCqn7wVwM1H/ziai2uhpnfkuAN+Kz8ty4JvZ9qs7x0VEJJGQmqpERKQbUHCIiEgiCg4REUlEwSEiIokoOEREJBEFh0grZrbFzBZnvPI2ErOZ1WeOZCoSop7ZVxEpO++7+/C0CyHSXanGIZIjM2sys1+Y2TNm9pSZfTqeX29mD8XPOHjQzAbF83c1szvM7On4dUi8qQoz+3X8HIm/mFmv1A5KpBMUHCLb69WqqerrGcvWuvv+wFVEI/YCXAlc7+5DgQZgZjx/JvBXdx9GNJ7Usnj+3sCv3H0wsAb414IejUie6c5xkVbMbL2779jG/CbgSHd/OR6A8h/u3t/M3iJ6/sGmeP5r7j7AzN4Eat39g4xt1AP3e/SQHczsR0Clu19chEMTyQvVOESS8XbeJ/FBxvstqK9RAqPgEEnm6xn/PhG/f5xo1F6AccD8+P2DwBTY9rz0nYpVSJFC0l86ItvrZWaLM6b/y91bLsnd2cyWENUaTo7nnUn0RL5ziJ7O9814/lnAbDM7jahmMYVoJFORoKmPQyRHcR/HSHd/K+2yiKRJTVUiIpKIahwiIpKIahwiIpKIgkNERBJRcIiISCIKDhERSUTBISIiiSg4REQkkf8PdBKAPwFt1LYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 42.1 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([355])\n",
      "355 vs 355\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 79.167 %\n",
      "- Recall : 73.077 %\n",
      "- F1 : 0.76\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 73.737 %\n",
      "- Recall : 83.908 %\n",
      "- F1 : 0.78495\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 91.489 %\n",
      "- Recall : 92.473 %\n",
      "- F1 : 0.91979\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 88.889 %\n",
      "- Recall : 82.474 %\n",
      "- F1 : 0.85561\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 83.38 %\n",
      "- Precision : 83.321 %\n",
      "- Recall : 82.983 %\n",
      "- F1 : 0.83152\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Twitter15-Multi_4LayerNet_RoBERTa_Finetuned_with_TopTermsVectors Validation, 83.38, 83.321, 82.983, 0.83152, 79.167, 73.077, 0.76, 73.737, 83.908, 0.78495, 91.489, 92.473, 0.91979, 88.889, 82.474, 0.85561, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([131])\n",
      "131 vs 131\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 77.5 %\n",
      "- Recall : 86.111 %\n",
      "- F1 : 0.81579\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 89.655 %\n",
      "- Recall : 83.871 %\n",
      "- F1 : 0.86667\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 87.879 %\n",
      "- Recall : 85.294 %\n",
      "- F1 : 0.86567\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 86.207 %\n",
      "- Recall : 83.333 %\n",
      "- F1 : 0.84746\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 84.733 %\n",
      "- Precision : 85.31 %\n",
      "- Recall : 84.652 %\n",
      "- F1 : 0.8498\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Twitter15-Multi_4LayerNet_RoBERTa_Finetuned_with_TopTermsVectors Test, 84.733, 85.31, 84.652, 0.8498, 77.5, 86.111, 0.81579, 89.655, 83.871, 0.86667, 87.879, 85.294, 0.86567, 86.207, 83.333, 0.84746, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b4d368",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
