{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "random.seed(33)\n",
    "\n",
    "unique_name = \"DistilBERT_Finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(818, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter16_DistilBERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>656955120626880512</td>\n",
       "      <td>correct predictions in back to the future ii U...</td>\n",
       "      <td>false</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>615689290706595840</td>\n",
       "      <td>.@whitehouse in rainbow colors for #scotusmarr...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>613404935003217920</td>\n",
       "      <td>cops bought the alleged church shooter burger ...</td>\n",
       "      <td>false</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  656955120626880512  correct predictions in back to the future ii U...   \n",
       "1  615689290706595840  .@whitehouse in rainbow colors for #scotusmarr...   \n",
       "2  613404935003217920  cops bought the alleged church shooter burger ...   \n",
       "3  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "4  714598641827246081  an open letter to trump voters from his top st...   \n",
       "\n",
       "        label       tvt  cv_fold        tt        tvt2  \n",
       "0       false  training        1  training  validation  \n",
       "1        true  training        3  training    training  \n",
       "2       false  training        2      test    training  \n",
       "3  unverified  training        3      test    training  \n",
       "4  unverified  training        1      test    training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter16_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['false', 'true', 'unverified', 'non-rumor']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = data['label'].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 2, 2, 1, 2, 3, 3, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d['label'])\n",
    "#     labels.append([1 if j == lab else 0 for j in range(len(labels_str))])\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(531, 768)\n",
      "(185, 768)\n",
      "(102, 768)\n",
      "(531,)\n",
      "(185,)\n",
      "(102,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, n_output),\n",
    "#             nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ce67903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from library.classification import SKLearnClassification\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Twitter16\"\n",
    "\n",
    "logres_model = LogisticRegression(random_state=0, solver='liblinear', multi_class='ovr', max_iter=10000)\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "svm = LinearSVC()\n",
    "\n",
    "models = [\n",
    "    SKLearnClassification(logres_model, \"Logistic Regression\"),\n",
    "    SKLearnClassification(neigh, \"K-Nearest Neighbor\"),\n",
    "    SKLearnClassification(svm, \"Support Vector Machine\"),\n",
    "]\n",
    "# for model in models:\n",
    "#     print(f\"\\n--- {model.model_name.upper()} ---\")\n",
    "#     model.train(train_vectors, train_labels, dataset_name)\n",
    "    \n",
    "#     print(\"Validation Set\")\n",
    "#     preds = model.predict(val_vectors)\n",
    "\n",
    "#     conf_mat = ConfusionMatrix(\n",
    "#         labels=val_labels,\n",
    "#         predictions=preds,\n",
    "#         binary=True\n",
    "#     )\n",
    "#     conf_mat.evaluate()\n",
    "    \n",
    "#     print(\"Test Set\")\n",
    "#     preds = model.predict(test_vectors)\n",
    "\n",
    "#     conf_mat = ConfusionMatrix(\n",
    "#         labels=test_labels,\n",
    "#         predictions=preds,\n",
    "#         binary=False\n",
    "#     )\n",
    "#     conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "#     print(\"--- END ---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd07cc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 56.216\n",
      "Saving after new best accuracy : 76.757\n",
      "Saving after new best accuracy : 78.919\n",
      "Saving after new best accuracy : 79.459\n",
      "Saving after new best accuracy : 80.0\n",
      "-- Epoch 50, Train Loss : 0.0009022081503644586, Test Loss : 1.0214052200317383\n",
      "-- Epoch 100, Train Loss : 0.0002144013560609892, Test Loss : 1.177476167678833\n",
      "-- Epoch 150, Train Loss : 9.470317672821693e-05, Test Loss : 1.268017292022705\n",
      "-- Epoch 200, Train Loss : 5.328875340637751e-05, Test Loss : 1.3324511051177979\n",
      "-- Epoch 250, Train Loss : 3.406717769394163e-05, Test Loss : 1.3824588060379028\n",
      "-- Epoch 300, Train Loss : 2.3632662305317353e-05, Test Loss : 1.423534631729126\n",
      "-- Epoch 350, Train Loss : 1.732579085000907e-05, Test Loss : 1.4584376811981201\n",
      "-- Epoch 400, Train Loss : 1.3255048997962149e-05, Test Loss : 1.488782286643982\n",
      "-- Epoch 450, Train Loss : 1.0408933121652808e-05, Test Loss : 1.515809416770935\n",
      "-- Epoch 500, Train Loss : 8.390176844841335e-06, Test Loss : 1.540246605873108\n",
      "-- Epoch 550, Train Loss : 6.899128038639901e-06, Test Loss : 1.5626516342163086\n",
      "-- Epoch 600, Train Loss : 5.752460992880515e-06, Test Loss : 1.5834228992462158\n",
      "-- Epoch 650, Train Loss : 4.8626463922119e-06, Test Loss : 1.6027673482894897\n",
      "-- Epoch 700, Train Loss : 4.1445720171395806e-06, Test Loss : 1.6208914518356323\n",
      "-- Epoch 750, Train Loss : 3.5865706422555377e-06, Test Loss : 1.6379691362380981\n",
      "-- Epoch 800, Train Loss : 3.112116587544733e-06, Test Loss : 1.6540776491165161\n",
      "-- Epoch 850, Train Loss : 2.733513611019589e-06, Test Loss : 1.669446349143982\n",
      "-- Epoch 900, Train Loss : 2.4051890363807615e-06, Test Loss : 1.6840343475341797\n",
      "-- Epoch 950, Train Loss : 2.1152806652935396e-06, Test Loss : 1.697960376739502\n",
      "-- Epoch 1000, Train Loss : 1.8797801999426156e-06, Test Loss : 1.7113995552062988\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 31.34 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([185])\n",
      "185 vs 185\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 81.818 %\n",
      "- Recall : 70.588 %\n",
      "- F1 : 0.75789\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 97.059 %\n",
      "- Recall : 94.286 %\n",
      "- F1 : 0.95652\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 74.074 %\n",
      "- Recall : 81.633 %\n",
      "- F1 : 0.7767\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 73.585 %\n",
      "- Recall : 78.0 %\n",
      "- F1 : 0.75728\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 80.0 %\n",
      "- Precision : 81.634 %\n",
      "- Recall : 81.127 %\n",
      "- F1 : 0.8138\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,false,,,true,,,unverified,,,non-rumor,,,\n",
      "Twitter16_4LayerNet_DistilBERT_Finetuned Validation, 80.0, 81.634, 81.127, 0.8138, 81.818, 70.588, 0.75789, 97.059, 94.286, 0.95652, 74.074, 81.633, 0.7767, 73.585, 78.0, 0.75728, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([102])\n",
      "102 vs 102\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 75.0 %\n",
      "- Recall : 77.778 %\n",
      "- F1 : 0.76364\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 88.0 %\n",
      "- Recall : 84.615 %\n",
      "- F1 : 0.86275\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 87.5 %\n",
      "- Recall : 84.0 %\n",
      "- F1 : 0.85714\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 76.0 %\n",
      "- Recall : 79.167 %\n",
      "- F1 : 0.77551\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 81.373 %\n",
      "- Precision : 81.625 %\n",
      "- Recall : 81.39 %\n",
      "- F1 : 0.81507\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,false,,,true,,,unverified,,,non-rumor,,,\n",
      "Twitter16_4LayerNet_DistilBERT_Finetuned Test, 81.373, 81.625, 81.39, 0.81507, 75.0, 77.778, 0.76364, 88.0, 84.615, 0.86275, 87.5, 84.0, 0.85714, 76.0, 79.167, 0.77551, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "start = time.time()\n",
    "model_name = f\"Twitter16_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55461251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
