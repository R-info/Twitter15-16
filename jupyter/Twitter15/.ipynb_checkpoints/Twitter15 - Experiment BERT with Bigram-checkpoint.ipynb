{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "random.seed(33)\n",
    "\n",
    "unique_name = \"BERT_with_Bigram\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>691809004356501505</td>\n",
       "      <td>america is a nation of second chances â€”@potus ...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693204708933160960</td>\n",
       "      <td>brandon marshall visits and offers advice, sup...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>551099691702956032</td>\n",
       "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "1  714598641827246081  an open letter to trump voters from his top st...   \n",
       "2  691809004356501505  america is a nation of second chances â€”@potus ...   \n",
       "3  693204708933160960  brandon marshall visits and offers advice, sup...   \n",
       "4  551099691702956032  rip elly may clampett: so sad to learn #beverl...   \n",
       "\n",
       "        label       tvt  cv_fold        tt      tvt2  \n",
       "0  unverified  training        1  training  training  \n",
       "1  unverified  training        1      test  training  \n",
       "2   non-rumor  training        2  training  training  \n",
       "3   non-rumor  training        1  training  training  \n",
       "4        true  training        3  training  training  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter15_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ab5cc80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinton #neverhillary #trump2016 URL\\r',\n",
       " 'an open letter to trump voters from his top strategist-turned-defector URL via @xojanedotcom\\r',\n",
       " 'america is a nation of second chances â€”@potus on new reforms to solitary confinement: URL URL\\r',\n",
       " 'brandon marshall visits and offers advice, support to brother of fallen hero zaevion dobson: URL URL\\r',\n",
       " 'rip elly may clampett: so sad to learn #beverlyhillbillies star donna douglas has passed away. URL\\r',\n",
       " 'former 3 doors down guitarist matt roberts has died at age 38, according to his father. URL URL\\r',\n",
       " 'craigslist ad: â€˜get paid $15 an hour to protest at the trump rallyâ€™ - URL URL\\r',\n",
       " 'just in: missing afghan soldiers found trying to enter canada near niagara falls URL URL\\r',\n",
       " 'the day #ferguson cops told a dirty, bloody lie (via @thedailybeast): URL URL\\r',\n",
       " \"#riphulkhogan my heart is ripping like your shirt. wwe'll miss you.\\r\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unverified', 'non-rumor', 'true', 'false']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = data['label'].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 2, 1, 0, 2, 0, 3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d['label'])\n",
    "#     labels.append([1 if j == lab else 0 for j in range(len(labels_str))])\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5516af8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>unverified</th>\n",
       "      <th>non-rumor</th>\n",
       "      <th>true</th>\n",
       "      <th>false</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca kkk</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kkk grand</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grand wizard</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wizard endorses</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>endorses @hillaryclinton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Unnamed: 0  unverified  non-rumor  true  false\n",
       "0                    ca kkk           1          0     0      0\n",
       "1                 kkk grand           1          0     0      0\n",
       "2              grand wizard           1          0     0      0\n",
       "3           wizard endorses           1          0     0      0\n",
       "4  endorses @hillaryclinton           1          0     0      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_data = pd.read_excel('../../data/processed/twitter15_ngram_distribution.xlsx', sheet_name='bigram')\n",
    "bigram_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78d5c2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_probability = {}\n",
    "for i, d in bigram_data.iterrows():\n",
    "    bigram_probability[d[0]] = []\n",
    "    sum_of = 0\n",
    "    for l in labels_str:\n",
    "        bigram_probability[d[0]].append(d[l])\n",
    "        sum_of += d[l]\n",
    "    \n",
    "    for i, bp in enumerate(bigram_probability[d[0]]):\n",
    "        bigram_probability[d[0]][i] = bp/sum_of\n",
    "\n",
    "bigram_probability['wizard endorses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc184086",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-04 11:02:30.324612: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-04 11:02:30.324639: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "WARNING:root:No sentence-transformers model found with name /home/romy/.cache/torch/sentence_transformers/bert-base-uncased. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at /home/romy/.cache/torch/sentence_transformers/bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.models import Pooling\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "model = SentenceTransformer('bert-base-uncased')\n",
    "pooling_layer = Pooling(768)\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    bigrams = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    bigrams = [t for t in bigrams if t not in string.punctuation]\n",
    "    bigrams = [t for t in bigrams if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(bigrams)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def bigrams2vectors(bigrams):\n",
    "    vectors = model.encode(bigrams)\n",
    "    return vectors\n",
    "\n",
    "\n",
    "def vectors_with_bigrams(text):\n",
    "    bigrams = text2bigrams(texts[9])\n",
    "    base_vecs = bigrams2vectors(bigrams)\n",
    "    embeddings = base_vecs\n",
    "#     embeddings = []\n",
    "    \n",
    "#     for i, vec in enumerate(base_vecs):\n",
    "#         embeddings.append(vec * max(bigram_probability[bigrams[i]]))\n",
    "    \n",
    "    embeddings = torch.unsqueeze(torch.Tensor(embeddings), 0)\n",
    "    \n",
    "    inputs = {\n",
    "        'attention_mask': torch.ones(1, len(bigrams)),\n",
    "        'token_embeddings': embeddings\n",
    "    }\n",
    "    result = pooling_layer.forward(inputs)\n",
    "    result = torch.squeeze(result['sentence_embedding'], 0).cpu().detach().numpy()\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def vectors_generation(texts):\n",
    "    return model.encode(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdea8e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 768)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = []\n",
    "for text in texts:\n",
    "    vectors.append(vectors_with_bigrams(text))\n",
    "vectors = np.array(vectors)\n",
    "\n",
    "# vectors = vectors_generation(texts)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1017, 768)\n",
      "(327, 768)\n",
      "(146, 768)\n",
      "(1017,)\n",
      "(327,)\n",
      "(146,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, n_output),\n",
    "#             nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ce67903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from library.classification import SKLearnClassification\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Twitter15\"\n",
    "\n",
    "logres_model = LogisticRegression(random_state=0, solver='liblinear', multi_class='ovr', max_iter=10000)\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "svm = LinearSVC()\n",
    "\n",
    "models = [\n",
    "    SKLearnClassification(logres_model, \"Logistic Regression\"),\n",
    "    SKLearnClassification(neigh, \"K-Nearest Neighbor\"),\n",
    "    SKLearnClassification(svm, \"Support Vector Machine\"),\n",
    "]\n",
    "# for model in models:\n",
    "#     print(f\"\\n--- {model.model_name.upper()} ---\")\n",
    "#     model.train(train_vectors, train_labels, dataset_name)\n",
    "    \n",
    "#     print(\"Validation Set\")\n",
    "#     preds = model.predict(val_vectors)\n",
    "\n",
    "#     conf_mat = ConfusionMatrix(\n",
    "#         labels=val_labels,\n",
    "#         predictions=preds,\n",
    "#         binary=True\n",
    "#     )\n",
    "#     conf_mat.evaluate()\n",
    "    \n",
    "#     print(\"Test Set\")\n",
    "#     preds = model.predict(test_vectors)\n",
    "\n",
    "#     conf_mat = ConfusionMatrix(\n",
    "#         labels=test_labels,\n",
    "#         predictions=preds,\n",
    "#         binary=False\n",
    "#     )\n",
    "#     conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "#     print(\"--- END ---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 25.076\n",
      "-- Epoch 50, Train Loss : 2.7724803686141968, Test Loss : 1.3866060972213745\n",
      "-- Epoch 100, Train Loss : 2.7724525928497314, Test Loss : 1.3866099119186401\n",
      "-- Epoch 150, Train Loss : 2.7724355459213257, Test Loss : 1.386613130569458\n",
      "-- Epoch 200, Train Loss : 2.7724231481552124, Test Loss : 1.3866174221038818\n",
      "-- Epoch 250, Train Loss : 2.7724119424819946, Test Loss : 1.3866180181503296\n",
      "-- Epoch 300, Train Loss : 2.772403597831726, Test Loss : 1.3866198062896729\n",
      "-- Epoch 350, Train Loss : 2.7723971605300903, Test Loss : 1.386621356010437\n",
      "-- Epoch 400, Train Loss : 2.7723958492279053, Test Loss : 1.3866215944290161\n",
      "-- Epoch 450, Train Loss : 2.7723861932754517, Test Loss : 1.3866244554519653\n",
      "-- Epoch 500, Train Loss : 2.77238130569458, Test Loss : 1.3866262435913086\n",
      "-- Epoch 550, Train Loss : 2.772376537322998, Test Loss : 1.3866277933120728\n",
      "-- Epoch 600, Train Loss : 2.7723724842071533, Test Loss : 1.386629343032837\n",
      "-- Epoch 650, Train Loss : 2.772369623184204, Test Loss : 1.3866307735443115\n",
      "-- Epoch 700, Train Loss : 2.772366762161255, Test Loss : 1.3866312503814697\n",
      "-- Epoch 750, Train Loss : 2.7723639011383057, Test Loss : 1.3866331577301025\n",
      "-- Epoch 800, Train Loss : 2.7723610401153564, Test Loss : 1.3866345882415771\n",
      "-- Epoch 850, Train Loss : 2.7723591327667236, Test Loss : 1.3866353034973145\n",
      "-- Epoch 900, Train Loss : 2.7723594903945923, Test Loss : 1.3866347074508667\n",
      "-- Epoch 950, Train Loss : 2.772355556488037, Test Loss : 1.38663649559021\n",
      "-- Epoch 1000, Train Loss : 2.772354483604431, Test Loss : 1.3866376876831055\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 40.11 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([327])\n",
      "327 vs 327\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 0 %\n",
      "- Recall : 0.0 %\n",
      "- F1 : 0\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 25.076 %\n",
      "- Recall : 100.0 %\n",
      "- F1 : 0.40098\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 0 %\n",
      "- Recall : 0.0 %\n",
      "- F1 : 0\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 0 %\n",
      "- Recall : 0.0 %\n",
      "- F1 : 0\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 25.076 %\n",
      "- Precision : 6.269 %\n",
      "- Recall : 25.0 %\n",
      "- F1 : 0.10024\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Twitter15_4LayerNet_BERT_with_Bigram Validation, 25.076, 6.269, 25.0, 0.10024, 0, 0.0, 0, 25.076, 100.0, 0.40098, 0, 0.0, 0, 0, 0.0, 0, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([146])\n",
      "146 vs 146\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 0 %\n",
      "- Recall : 0.0 %\n",
      "- F1 : 0\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 23.288 %\n",
      "- Recall : 100.0 %\n",
      "- F1 : 0.37778\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 0 %\n",
      "- Recall : 0.0 %\n",
      "- F1 : 0\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 0 %\n",
      "- Recall : 0.0 %\n",
      "- F1 : 0\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 23.288 %\n",
      "- Precision : 5.822 %\n",
      "- Recall : 25.0 %\n",
      "- F1 : 0.09445\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Twitter15_4LayerNet_BERT_with_Bigram Test, 23.288, 5.822, 25.0, 0.09445, 0, 0.0, 0, 23.288, 100.0, 0.37778, 0, 0.0, 0, 0, 0.0, 0, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "start = time.time()\n",
    "model_name = f\"Twitter15_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55461251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
