{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Twitter15-Multi\"\n",
    "unique_name = \"DistilBERT_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "bigram_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Twitter15_DistilBERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>691809004356501505</td>\n",
       "      <td>america is a nation of second chances â€”@potus ...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>2</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693204708933160960</td>\n",
       "      <td>brandon marshall visits and offers advice, sup...</td>\n",
       "      <td>non-rumor</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "      <td>testting</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>551099691702956032</td>\n",
       "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillaryclinto...   \n",
       "1  714598641827246081  an open letter to trump voters from his top st...   \n",
       "2  691809004356501505  america is a nation of second chances â€”@potus ...   \n",
       "3  693204708933160960  brandon marshall visits and offers advice, sup...   \n",
       "4  551099691702956032  rip elly may clampett: so sad to learn #beverl...   \n",
       "\n",
       "        label       tvt  cv_fold        tt        tvt2      tvt2_1  \\\n",
       "0  unverified  training        1  training    training  validation   \n",
       "1  unverified  training        1      test    training    testting   \n",
       "2   non-rumor  training        2  training  validation  validation   \n",
       "3   non-rumor  training        1  training    testting    testting   \n",
       "4        true  training        3  training  validation    training   \n",
       "\n",
       "       tvt2_2    tvt2_3  \n",
       "0    training  training  \n",
       "1    training  training  \n",
       "2  validation  testting  \n",
       "3    training  training  \n",
       "4  validation  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/twitter15_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unverified', 'non-rumor', 'true', 'false']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = data['label'].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 2, 1, 0, 2, 0, 3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d['label'])\n",
    "    labs = [1 if idx == lab else 0 for idx in range(len(labels_str))]\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#ferguson pd', 'bathroom policy', 'institutional racism', 'want to', 'bag charge', 'ios 8', 'can be', 'clinton campaign', 'new transgender', 'protest at']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_terms = []\n",
    "with open(\"../../data/processed/twitter15-multi_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        vector_terms.append(t.strip())\n",
    "\n",
    "print(vector_terms[:10])\n",
    "len(vector_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2unigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(text)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def text2trigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', 'â€˜', 'â€™']]\n",
    "    \n",
    "    trigrams = nltk.trigrams(text)\n",
    "    trigrams = map(' '.join, trigrams)\n",
    "    trigrams = [bgr for bgr in trigrams]\n",
    "    \n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def custom_vectors_generation(texts, vector_terms):\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "        trigrams = text2trigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(vector_terms) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in vector_terms:\n",
    "                idx = vector_terms.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        for tgr in trigrams:\n",
    "            if tgr in vector_terms:\n",
    "                idx = vector_terms.index(tgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        vectors.append(init_vec)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 1519)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "terms_vectors = custom_vectors_generation(texts, vector_terms)\n",
    "\n",
    "vectors = np.concatenate([vectors, terms_vectors], axis=1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1004, 1519)\n",
      "(355, 1519)\n",
      "(131, 1519)\n",
      "(1004,)\n",
      "(355,)\n",
      "(131,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, n_output)\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 84.225\n",
      "Saving after new best accuracy : 84.507\n",
      "Saving after new best accuracy : 85.352\n",
      "-- Epoch 50, Train Loss : 0.005442950874567032, Test Loss : 0.619323194026947\n",
      "-- Epoch 100, Train Loss : 0.0014330092235468328, Test Loss : 0.7185494303703308\n",
      "-- Epoch 150, Train Loss : 0.0006420315767172724, Test Loss : 0.7803620100021362\n",
      "-- Epoch 200, Train Loss : 0.0003663020033854991, Test Loss : 0.8254488110542297\n",
      "-- Epoch 250, Train Loss : 0.00023665945627726614, Test Loss : 0.861081063747406\n",
      "-- Epoch 300, Train Loss : 0.00016515135939698666, Test Loss : 0.8905848264694214\n",
      "-- Epoch 350, Train Loss : 0.0001215495794895105, Test Loss : 0.9158496260643005\n",
      "-- Epoch 400, Train Loss : 9.304423656431027e-05, Test Loss : 0.9381166100502014\n",
      "-- Epoch 450, Train Loss : 7.336263661272824e-05, Test Loss : 0.9579034447669983\n",
      "-- Epoch 500, Train Loss : 5.921524279983714e-05, Test Loss : 0.9758502840995789\n",
      "-- Epoch 550, Train Loss : 4.867879943049047e-05, Test Loss : 0.9923242926597595\n",
      "-- Epoch 600, Train Loss : 4.038974475406576e-05, Test Loss : 1.0080602169036865\n",
      "-- Epoch 650, Train Loss : 3.384902993275318e-05, Test Loss : 1.0232738256454468\n",
      "-- Epoch 700, Train Loss : 2.8779882086382713e-05, Test Loss : 1.0372177362442017\n",
      "-- Epoch 750, Train Loss : 2.474454595358111e-05, Test Loss : 1.0501617193222046\n",
      "-- Epoch 800, Train Loss : 2.1463566554302815e-05, Test Loss : 1.0623252391815186\n",
      "-- Epoch 850, Train Loss : 1.8765767890727147e-05, Test Loss : 1.073861837387085\n",
      "-- Epoch 900, Train Loss : 1.650308331591077e-05, Test Loss : 1.084856390953064\n",
      "-- Epoch 950, Train Loss : 1.460569592381944e-05, Test Loss : 1.0953694581985474\n",
      "-- Epoch 1000, Train Loss : 1.2988771231903229e-05, Test Loss : 1.1054375171661377\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 41.5 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : (355,)\n",
      "355 vs 355\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 91.667 %\n",
      "- Recall : 70.513 %\n",
      "- F1 : 0.7971\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 76.531 %\n",
      "- Recall : 86.207 %\n",
      "- F1 : 0.81081\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 91.209 %\n",
      "- Recall : 89.247 %\n",
      "- F1 : 0.90217\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 84.906 %\n",
      "- Recall : 92.784 %\n",
      "- F1 : 0.8867\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 85.352 %\n",
      "- Precision : 86.078 %\n",
      "- Recall : 84.688 %\n",
      "- F1 : 0.85377\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Twitter15-Multi_4LayerNet_DistilBERT_Finetuned_with_TopTermsVectors Validation, 85.352, 86.078, 84.688, 0.85377, 91.667, 70.513, 0.7971, 76.531, 86.207, 0.81081, 91.209, 89.247, 0.90217, 84.906, 92.784, 0.8867, \n",
      "\n",
      "Test Set\n",
      "Predictions : (131,)\n",
      "131 vs 131\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 83.333 %\n",
      "- Recall : 83.333 %\n",
      "- F1 : 0.83333\n",
      "\n",
      "Class non-rumor Evaluation\n",
      "- Precision : 79.412 %\n",
      "- Recall : 87.097 %\n",
      "- F1 : 0.83077\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 93.548 %\n",
      "- Recall : 85.294 %\n",
      "- F1 : 0.89231\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 80.0 %\n",
      "- Recall : 80.0 %\n",
      "- F1 : 0.8\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 83.969 %\n",
      "- Precision : 84.073 %\n",
      "- Recall : 83.931 %\n",
      "- F1 : 0.84002\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,unverified,,,non-rumor,,,true,,,false,,,\n",
      "Twitter15-Multi_4LayerNet_DistilBERT_Finetuned_with_TopTermsVectors Test, 83.969, 84.073, 83.931, 0.84002, 83.333, 83.333, 0.83333, 79.412, 87.097, 0.83077, 93.548, 85.294, 0.89231, 80.0, 80.0, 0.8, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "preds = preds.cpu().numpy()\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "preds = preds.cpu().numpy()\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55461251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
